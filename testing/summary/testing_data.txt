	Motivation: Plant phenomics, the collection of large-scale plant phenotype data, is growing exponentially.
	The resources have become essential component of modern plant science.
	Such complex datasets are critical for understanding the mechanisms governing energy intake and storage in plants, and this is essential for improving crop productivity.
	However, a major issue facing these efforts is the determination of the quality of phenotypic data.
	Automated methods are needed to identify and characterize alterations caused by system errors, all of which are difficult to remove in the data collection step and distinguish them from more interesting cases of altered biological responses.
	Results: As a step towards solving this problem, we have developed a coarse-to-refined model called dynamic filter to identify abnormalities in plant photosynthesis phenotype data by comparing light responses of photosynthesis using a simplified kinetic model of photosynthesis.
	Dynamic filter employs an expectation-maximization process to adjust the kinetic model in coarse and refined regions to identify both abnormalities and biological outliers.
	The experimental results show that our algorithm can effectively identify most of the abnormalities in both real and synthetic datasets.
	Availability and implementation: Software available at www.msu.edu/%7Ejinchen/DynamicFilter Contact: jinchen@msu.edu or kramerd8@cns.msu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Pathway Commons (http://www.pathwaycommons .org) is a collection of publicly available pathway data from multiple organisms.
	Pathway Commons provides a web-based interface that enables biologists to browse and search a comprehensive collection of pathways from multiple sources represented in a common language, a download site that provides integrated bulk sets of pathway information in standard or convenient formats and a web service that software developers can use to conveniently query and access all data.
	Database providers can share their pathway data via a common repository.
	Pathways include biochemical reactions, complex assembly, transport and catalysis events and physical interactions involving proteins, DNA, RNA, small molecules and complexes.
	Pathway Commons aims to collect and integrate all public pathway data available in standard formats.
	Pathway Commons currently contains data from nine databases with over 1400 pathways and 687 000 interactions and will be continually expanded and updated.
	The International Society for Computational Biology (ISCB) is dedicated to advancing human knowledge at the intersection of computation and life sciences.
	On behalf of the ISCB members, this public policy statement expresses strong support for open access, reuse, integration, and distillation of the publicly-funded archival scientific and technical research literature, and for the infrastructure to achieve that goal.
	Knowledge is the fruit of the research endeavor, and the archival scientific and technical research literature is its practical expression and means of communication.
	Shared knowledge multiplies in utility because every new scientific discovery is built upon previous scientific knowledge.
	Access to knowledge is access to the power to solve new problems and make informed decisions.
	Free, open, public, online access to the archival scientific and technical research literature will empower citizens and scientists to solve more problems and make better, more informed decisions.
	Attribution to the original authors will maintain consistency and accountability within the knowledgebase.
	Computational reuse, integration, and distillation of that literature will produce new and as yet unforeseen knowledge.
	We strongly encourage open software, data, and databases, issues which are not addressed here.
	A prior ISCB public policy statement on sharing software provides very clear support for Open Source/Open Access (http://www.iscb.org/iscb-policy-statements/software_sharing).We support open database access, standards, and interoperability.
	We also recognize that databases are complex dynamic entities, with ongoing roles and needs that cannot be treated properly within this statement.
	In contrast, the publicly-funded archival research literature, addressed here, is the static historical record of publicly-funded research outcomes.
	ISCB supports many of the principles set forth in other open access policies and statements, including the 'Budapest Open Access Initiative,' the 'Bethesda Declaration on Open Access Publishing,' the Bulletin of the World Health Organization 'Equitable Access to Scientific and Technical Information for Health,' the U.S. National Academies of Sciences report on 'Sharing Publication-Related Data and Materials: Responsibilities of Authorship in the Life Sciences,' the Organisation for Economic Co-Operation and Development 'Principles and Guidelines for Access to Research Data from Public Funding,' and the 'Berlin Declaration on Open Access to Knowledge in the Sciences and Humanities.'
	The public policy statement put forward here builds upon these principles to elucidate in more detail the public policy position of ISCB and its members on this important issue in scientific dissemination.
	Motivation: In genetic science, large-scale international research collaborations represent a growing trend.
	These collaborations have demanding and challenging database, storage, retrieval and communication needs.
	These studies typically involve demographic and clinical data, in addition to the results from numerous genomic studies (omics studies) such as gene expression, eQTL, genomewide association and methylation studies, which present numerous challenges, thus the need for data integration platforms that can handle these complex data structures.
	Inefficient methods of data transfer and access control still plague research collaboration.
	As science becomes more and more collaborative in nature, the need for a system that adequately manages data sharing becomes paramount.
	Results: Biology-Related Information Storage Kit (BRISK) is a package of several web-based data management tools that provide a cohesive data integration and management platform.
	It was specifically designed to provide the architecture necessary to promote collaboration and expedite data sharing between scientists.
	Availability and Implementation: The software, documentation, Java source code and demo are available at http://genapha.icapture .ubc.ca/brisk/index.jsp.
	BRISK was developed in Java, and tested on an Apache Tomcat 6 server with a MySQL database.
	Contact: denise.daley@hli.ubc.ca
	Motivation: A number of studies of individual proteins have shown that post-translational modifications (PTMs) are associated with structural rearrangements of their target proteins.
	Although such studies provide critical insights into the mechanics behind the dynamic regulation of protein function, they usually feature examples with relatively large conformational changes.
	However, with the steady growth of Protein Data Bank (PDB) and available PTM sites, it is now possible to more systematically characterize the role of PTMs as conformational switches.
	In this study, we ask (1) what is the expected extent of structural change upon PTM, (2) how often are those changes in fact substantial, (3) whether the structural impact is spatially localized or global and (4) whether different PTMs have different signatures.
	Results: We exploit redundancy in PDB and, using root-mean-square deviation, study the conformational heterogeneity of groups of protein structures corresponding to identical sequences in their unmodified and modified forms.
	We primarily focus on the two most abundant PTMs in PDB, glycosylation and phosphorylation, but show that acetylation and methylation have similar tendencies.
	Our results provide evidence that PTMs induce conformational changes at both local and global level.
	However, the proportion of large changes is unexpectedly small; only 7% of glycosylated and 13% of phosphorylated proteins undergo global changes 42 AËš.
	Further analysis suggests that phosphorylation stabilizes protein structure by reducing global conformational heterogeneity by 25%.
	Overall, these results suggest a subtle but common role of allostery in the mechanisms through which PTMs affect regulatory and signaling pathways.
	Contact: predrag@indiana.edu Supplementary Information: Supplementary data are available at Bioinformatics online.
	Motivation: With 48 million new cases in 2010, particularly documented in developing countries, tuberculosis (TB) is still a highly present pandemic and often terminal.
	This is also due to the emergence of antibiotic-resistant strains (MDR-TB and XDR-TB) of the primary causative TB agent Mycobacterium tuberculosis (MTB).
	Efforts to develop new effective drugs against MTB are restrained by the unique and largely impermeable composition of the mycobacterial cell wall.
	Results: Based on a database of antimycobacterial substances (CDD TB), 3815 compounds were classified as active and thus permeable.
	A data mining approach was conducted to gather the physico-chemical similarities of these substances and delimit them from a generic dataset of drug-like molecules.
	On the basis of the differences in these datasets, a regression model was generated and implemented into the online tool MycPermCheck to predict the permeability probability of small organic compounds.
	Discussion: Given the current lack of precise molecular criteria determining mycobacterial permeability, MycPermCheck represents an unprecedented prediction tool intended to support antimycobacterial drug discovery.
	It follows a novel knowledge-driven approach to estimate the permeability probability of small organic compounds.
	As such, MycPermCheck can be used intuitively as an additional selection criterion for potential new inhibitors against MTB.
	Based on the validation results, its performance is expected to be of high practical value for virtual screening purposes.
	Availability: The online tool is freely accessible under the URL http://www.mycpermcheck.aksotriffer.pharmazie.uni-wuerzburg.de Contact: sotriffer@uni-wuerzburg.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We present a tool called MRSD (Metabolic Route Search and Design) to search and design routes based on the weighted compound transform diagraph.
	The search submodule returns routes between a source and product compound within seconds in the network of one or multiple organisms based on data from KEGG.
	The design submodule designs a route from an appointed compound in an interactive mode.
	The two complementary functions, Metabolic Route Search and Design, can be broadly used in biosynthesis, bio-pharmaceuticals and the other related fields.
	Availability: bioinfo.ustc.edu.cn/softwares/MRSD/ Contact: hrzheng@ustc.edu.cn Supplementary information: Supplementary data are available at the Bioinformatics online.
	Summary: Pyrosequencing technologies are frequently used for sequencing the 16S ribosomal RNA marker gene for profiling microbial communities.
	Clustering of the produced reads is an important but time-consuming task.
	We present Dynamic Seedbased Clustering (DySC), a new tool based on the greedy clustering approach that uses a dynamic seeding strategy.
	Evaluations based on the normalized mutual information (NMI) criterion show that DySC produces higher quality clusters than UCLUST and CD-HIT at a comparable runtime.
	Availability and implementation: DySC, implemented in C, is available at http://code.google.com/p/dysc/ under GNU GPL license.Contact: bertil.schmidt@uni-mainz.de Supplementary Information: Supplementary data are available at Bioinformatics online.
	Supplementary information: Supplementary data are available at Bioinformatics online.
	Contact: iainios@hotmail.com
	Motivation: Polypharmacology (the ability of a single drug to affect multiple targets) is a key feature that may explain part of the decreasing success of conventional drug discovery strategies driven by the quest for drugs to act selectively on a single target.
	Most drug targets are proteins that are composed of domains (their structural and functional building blocks).
	Results: In this work, we model drug-domain networks to explore the role of protein domains as drug targets and to explain drug polypharmacology in terms of the interactions between drugs and protein domains.
	We find that drugs are organized around a privileged set of druggable domains.
	Conclusions: Protein domains are a good proxy for drug targets, and drug polypharmacology emerges as a consequence of the multidomain composition of proteins.
	Contact: amoyag@uma.es Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Advances in high-throughput sequencing technologies now allow for large-scale characterization of B cell immunoglobulin (Ig) repertoires.
	The high germline and somatic diversity of the Ig repertoire presents challenges for biologically meaningful analysis, which requires specialized computational methods.
	We have developed a suite of utilities, Change-O, which provides tools for advanced analyses of large-scale Ig repertoire sequencing data.
	Change-O includes tools for determining the complete set of Ig variable region gene segment alleles carried by an individual (including novel alleles), partitioning of Ig sequences into clonal populations, creating lineage trees, inferring somatic hypermutation targeting models, measuring repertoire diversity, quantifying selection pressure, and calculating sequence chemical properties.
	All Change-O tools utilize a common data format, which enables the seamless integration of multiple analyses into a single workflow.
	Availability and implementation: Change-O is freely available for non-commercial use and may be downloaded from http://clip.med.yale.edu/changeo.Contact: steven.kleinstein@yale.edu
	Motivation: There are a number of algorithms to infer causal regulatory networks from time series (gene expression) data.
	Here we analyse the phenomena of regulator interference, where regulators with similar dynamics mutually suppress both the probability of regulating a target and the associated link strength; for instance, interference between two identical strong regulators reduces link probabilities by 50%.
	Results: We construct a robust method to define an interferencecorrected causal network based on an analysis of the conditional link probabilities that recovers links lost through interference.
	On a large real network (Streptomyces coelicolor, phosphate depletion), we demonstrate that significant interference can occur between regulators with a correlation as low as 0.865, losing an estimated 34% of links by interference.
	However, levels of interference cannot be predicted from the correlation between regulators alone and are data specific.
	Validating against known networks, we show that high numbers of functional links are lost by regulator interference.
	Performance against other methods on DREAM4 data is excellent.
	Availability and implementation: The method is implemented in R and is publicly available as the NIACS package at http://www2.warwick.ac.uk/fac/sci/systemsbiology/research/software.
	Contact: N.J.Burroughs@warwick.ac.uk Supplementary information: Supplementary materials are available at Bioinformatics online.
	Motivation: Advances in sequencing technology have led to an exponential growth of genomics data, yet it remains a formidable challenge to interpret such data for identifying disease genes and drug targets.
	There has been increasing interest in adopting a systems approach that incorporates prior knowledge such as gene networks and genotype-phenotype associations.
	The majority of such knowledge resides in text such as journal publications, which has been undergoing its own exponential growth.
	It has thus become a significant bottleneck to identify relevant knowledge for genomic interpretation as well as to keep up with new genomics findings.
	Results: In the Literome project, we have developed an automatic curation system to extract genomic knowledge from PubMed articles and made this knowledge available in the cloud with a Web site to facilitate browsing, searching and reasoning.
	Currently, Literome focuses on two types of knowledge most pertinent to genomic medicine: directed genic interactions such as pathways and genotypephenotype associations.
	Users can search for interacting genes and the nature of the interactions, as well as diseases and drugs associated with a single nucleotide polymorphism or gene.
	Users can also search for indirect connections between two entities, e.g.
	a gene and a disease might be linked because an interacting gene is associated with a related disease.
	Availability and implementation: Literome is freely available at literome.azurewebsites.net.
	Download for non-commercial use is available via Web services.
	Contact: hoifung@microsoft.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: MyBioNet is a web-based application for biological network analysis, which provides user-friendly web interfaces to visualize, edit and merge biological networks.
	In addition, MyBioNet integrated KEGG metabolic network data from 1366 organisms and allows users to search and navigate interesting networks.
	Availability and Implementation: All KEGG metabolic network data are organized and stored in the MySQL database.
	MyBioNet is implemented in Flex/Actionscript and PHP languages and deployed on an Apache web server.
	MyBioNet is accessible through all the Flash-embedded browsers at http://bis.zju.edu.cn/mybionet/.Contact: mchen@zju.edu.cn
	Summary: JEPETTO (Java Enrichment of Pathways Extended To TOpology) is a Cytoscape 3.x plugin performing integrative human gene set analysis.
	It identifies functional associations between genes and known cellular pathways, and processes using protein interaction networks and topological analysis.
	The plugin integrates information from three separate web servers we published previously, specializing in enrichment analysis, pathways expansion and topological matching.
	This integration substantially simplifies the analysis of user gene sets and the interpretation of the results.
	We demonstrate the utility of the JEPETTO plugin on a set of misregulated genes associated with Alzheimer's disease.
	Availability: Source code and binaries are freely available for download at http://apps.cytoscape.org/apps/jepetto, implemented in Java and multi-platform.
	Installable directly via Cytoscape plugin manager.
	Released under the GNU General Public Licence.
	Contact: jepetto.plugin@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Argonaute-interacting WG/GW proteins are characterized by the presence of repeated sequence motifs containing glycine (G) and tryptophan (W).
	The motifs seem to be remarkably adaptive to amino acid substitutions and their sequences show non-contiguity.
	Our previous approach to the detection of GW domains, based on scoring their gross amino acid composition, allowed annotation of several novel proteins involved in gene silencing.
	The accumulation of new experimental data and more advanced applications revealed some deficiency of the algorithm in prediction selectivity.
	Additionally, W-motifs, though critical in gene regulation, have not yet been annotated in any available online resources.
	Results: We present an improved set of computational tools allowing efficient management and annotation of W-based motifs involved in gene silencing.
	The new prediction algorithms provide novel functionalities by annotation of the W-containing domains at the local sequence motif level rather than by overall compositional properties.
	This approach represents a significant improvement over the previous method in terms of prediction sensitivity and selectivity.
	Application of the algorithm allowed annotation of a comprehensive list of putative Argonaute-interacting proteins across eukaryotes.
	An in-depth characterization of the domains' properties indicates its intrinsic disordered character.
	In addition, we created a knowledge-based portal (whub) that provides access to tools and information on RNAi-related tryptophan-containing motifs.
	Availability and implementation: The web portal and tools are freely available at http://www.comgen.pl/whub.Contact: wmk@amu.edu.pl Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Protein interaction network-based pathway analysis (PINBPA) for genome-wide association studies (GWAS) has been developed as a Cytoscape app, to enable analysis of GWAS data in a network fashion.
	Users can easily import GWAS summary-level data, draw Manhattan plots, define blocks, prioritize genes with random walk with restart, detect enriched subnetworks and test the significance of subnetworks via a user-friendly interface.
	Availability and implementation: PINBPA app is freely available in Cytoscape app store.
	Contact: pmousavi@cs.queensu.ca and sebaran@cgl.ucsf.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Genes with indispensable functions are identified as essential; however, the traditional gene-level studies of essentiality have several limitations.
	In this study, we characterized gene essentiality from a new perspective of protein domains, the independent structural or functional units of a polypeptide chain.
	Results: To identify such essential domains, we have developed an Expectation-Maximization (EM) algorithm-based Essential Domain Prediction (EDP) Model.
	With simulated datasets, the model provided convergent results given different initial values and offered accurate predictions even with noise.
	We then applied the EDP model to six microbial species and predicted 1879 domains to be essential in at least one species, ranging 10-23% in each species.
	The predicted essential domains were more conserved than either non-essential domains or essential genes.
	Comparing essential domains in prokaryotes and eukaryotes revealed an evolutionary distance consistent with that inferred from ribosomal RNA.
	When utilizing these essential domains to reproduce the annotation of essential genes, we received accurate results that suggest protein domains are more basic units for the essentiality of genes.
	Furthermore, we presented several examples to illustrate how the combination of essential and non-essential domains can lead to genes with divergent essentiality.
	In summary, we have described the first systematic analysis on gene essentiality on the level of domains.
	Contact: huilu.bioinfo@gmail.com or Long.Lu@cchmc.org Supplementary Information: Supplementary data are available at Bioinformatics online.
	Summary:We announce the release of kSNP3.0, a program for SNP identification and phylogenetic analysis without genome alignment or the requirement for reference genomes.
	kSNP3.0 is a significantly improved version of kSNP v2.
	Availability and implementation: kSNP3.0 is implemented as a package of stand-alone executables for Linux and Mac OS X under the open-source BSD license.
	The executable packages, source code and a full User Guide are freely available at https://sourceforge.net/projects/ksnp/files/Contact: barryghall@gmail.com
	Summary: We present ClicO Free Service, an online web-service based on Circos, which provides a user-friendly, interactive web-based interface with configurable features to generate Circos circular plots.
	Availability and implementation: Online web-service is freely available at http://clicofs.codoncloud.com Contact: soonjoo.yap@codongenomics.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: CompleteMOTIFs (cMOTIFs) is an integrated web tool developed to facilitate systematic discovery of overrepresented transcription factor binding motifs from high-throughput chromatin immunoprecipitation experiments.
	Comprehensive annotations and Boolean logic operations on multiple peak locations enable users to focus on genomic regions of interest for de novo motif discovery using tools such as MEME, Weeder and ChIPMunk.
	The pipeline incorporates a scanning tool for known motifs from TRANSFAC and JASPAR databases, and performs an enrichment test using local or precalculated background models that significantly improve the motif scanning result.
	Furthermore, using the cMOTIFs pipeline, we demonstrated that multiple transcription factors could cooperatively bind to the upstream of important stem cell differentiation regulators.
	Availability: http://cmotifs.tchlab.org Contact: sekwon.kong@childrens.harvard.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: A basic problem of broad public and scientific interest is to use the DNA of an individual to infer the genomic ancestries of the parents.
	In particular, we are often interested in the fraction of each parent's genome that comes from specific ancestries (e.g.
	European, African, Native American, etc).
	This has many applications ranging from understanding the inheritance of ancestry-related risks and traits to quantifying human assortative mating patterns.
	Results: We model the problem of parental genomic ancestry inference as a pooled semi-Markov process.
	We develop a general mathematical framework for pooled semi-Markov processes and construct efficient inference algorithms for these models.
	Applying our inference algorithm to genotype data from 231 Mexican trios and 258 Puerto Rican trios where we have the true genomic ancestry of each parent, we demonstrate that our method accurately infers parameters of the semi-Markov processes and parents' genomic ancestries.
	We additionally validated the method on simulations.
	Our model of pooled semi-Markov process and inference algorithms may be of independent interest in other settings in genomics and machine learning.
	Contact: jazo@microsoft.com
	Motivation: cis-regulatory DNA sequence elements, such as enhancers and silencers, function to control the spatial and temporal expression of their target genes.
	Although the overall levels of gene expression in large cell populations seem to be precisely controlled, transcription of individual genes in single cells is extremely variable in real time.
	It is, therefore, important to understand how these cis-regulatory elements function to dynamically control transcription at single-cell resolution.
	Recently, statistical methods have been proposed to back calculate the rates involved in mRNA transcription using parameter estimation of a mathematical model of transcription and translation.
	However, a major complication in these approaches is that some of the parameters, particularly those corresponding to the gene copy number and transcription rate, cannot be distinguished; therefore, these methods cannot be used when the copy number is unknown.
	Results: Here, we develop a hierarchical Bayesian model to estimate biokinetic parameters from live cell enhancer-promoter reporter measurements performed on a population of single cells.
	This allows us to investigate transcriptional dynamics when the copy number is variable across the population.
	We validate our method using synthetic data and then apply it to quantify the function of two known developmental enhancers in real time and in single cells.
	Availability: Supporting information is submitted with the article.
	Contact: d.j.woodcock@warwick.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Meta-analysis of summary statistics is an essential approach to guarantee the success of genome-wide association studies (GWAS).
	Application of the fixed or random effects model to single-marker association tests is a standard practice.
	More complex methods of meta-analysis involving multiple parameters have not been used frequently, a gap that could be explained by the lack of a respective meta-analysis pipeline.
	Meta-analysis based on combining p-values can be applied to any association test.
	However, to be powerful, meta-analysis methods for high-dimensional models should incorporate additional information such as study-specific properties of parameter estimates, their effect directions, standard errors and covariance structure.
	Results: We modified 'method for the synthesis of linear regression slopes' recently proposed in the educational sciences to the case of multiple logistic regression, and implemented it in a meta-analysis tool called METAINTER.
	The software handles models with an arbitrary number of parameters, and can directly be applied to analyze the results of single-SNP tests, global haplotype tests, tests for and under genegene or gene-environment interaction.
	Via simulations for two-single nucleotide polymorphisms (SNP) models we have shown that the proposed meta-analysis method has correct type I error rate.
	Moreover, power estimates come close to that of the joint analysis of the entire sample.
	We conducted a real data analysis of six GWAS of type 2 diabetes, available from dbGaP (http://www.ncbi.nlm.nih.gov/gap).
	For each study, a genome-wide interaction analysis of all SNP pairs was performed by logistic regression tests.
	The results were then metaanalyzed with METAINTER.
	Availability: The software is freely available and distributed under the conditions specified on http://metainter.meb.uni-bonn.de Contact: vait@imbie.meb.uni-bonn.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: With the rapid development of DNA sequencing technology, increasing bacteria genome data enable the biologists to dig the evolutionary and genetic information of prokaryotic species from pan-genome sight.
	Therefore, the high-efficiency pipelines for pan-genome analysis are mostly needed.
	We have developed a new pan-genome analysis pipeline (PGAP), which can perform five analytic functions with only one command, including cluster analysis of functional genes, pan-genome profile analysis, genetic variation analysis of functional genes, species evolution analysis and function enrichment analysis of gene clusters.
	PGAP's performance has been evaluated on 11 Streptococcus pyogenes strains.
	Availability: PGAP is developed with Perl script on the Linux Platform and the package is freely available from http://pgap.sf.net.Contact: junyu@big.ac.cn; xiaojingfa@big.ac.cn Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Gut microbiota can be classified at multiple taxonomy levels.
	Strategies to use changes in microbiota composition to effect health improvements require knowing at which taxonomy level interventions should be aimed.
	Identifying these important levels is difficult, however, because most statistical methods only consider when the microbiota are classified at one taxonomy level, not multiple.
	Results: Using L1 and L2 regularizations, we developed a new variable selection method that identifies important features at multiple taxonomy levels.
	The regularization parameters are chosen by a new, data-adaptive, repeated cross-validation approach, which performed well.
	In simulation studies, our method outperformed competing methods: it more often selected significant variables, and had small false discovery rates and acceptable false-positive rates.
	Applying our method to gut microbiota data, we found which taxonomic levels were most altered by specific interventions or physiological status.
	Availability: The new approach is implemented in an R package, which is freely available from the corresponding author.
	Contact: tpgarcia@srph.tamhsc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Often competing hypotheses for biochemical networks exist in the form of different mathematical models with unknown parameters.
	Considering available experimental data, it is then desired to reject model hypotheses that are inconsistent with the data, or to estimate the unknown parameters.
	However, these tasks are complicated because experimental data are typically sparse, uncertain, and are frequently only available in form of qualitative if-then observations.
	ADMIT (Analysis, Design and Model Invalidation Toolbox) is a MatLabTM-based tool for guaranteed model invalidation, state and parameter estimation.
	The toolbox allows the integration of quantitative measurement data, a priori knowledge of parameters and states, and qualitative information on the dynamic or steady-state behavior.
	A constraint satisfaction problem is automatically generated and algorithms are implemented for solving the desired estimation, invalidation or analysis tasks.
	The implemented methods built on convex relaxation and optimization and therefore provide guaranteed estimation results and certificates for invalidity.
	Availability: ADMIT, tutorials and illustrative examples are available free of charge for non-commercial use at http://ifatwww.et.unimagdeburg.de/syst/ADMIT/ Contact: stefan.streif@ovgu.de Received on September 30, 2011; revised on March 13, 2012; accepted on March 17, 2012 MAIN FEATURES
	Summary: Here we present PREDDIMER, a web tool for prediction of dimer structure of transmembrane (TM) helices.
	PREDDIMER allows (i) reconstruction of a number of dimer structures for given sequence(s) of TM protein fragments, (ii) ranking and filtering of predicted structures according to respective values of a scoring function, (iii) visualization of predicted 3D dimer structures and (iv) visualization of surface hydrophobicity of TM helices and their contacting (interface) regions represented as 2D maps.
	Results: We implemented online the original PREDDIMER algorithm and benchmarked the server on 11 TM sequences, whose 3D dimer conformations were obtained previously by nuclear magnetic resonance spectroscopy.
	In the most of tested cases backbone rootmean-square deviations of closest predicted conformations from the experimental reference are below 3 AËš .
	A randomization test displays good anticorrelation ( 0.82) between values of the scoring function and statistical significance of the prediction 'by chance'.
	Going beyond a single dimer conformation, our web tool predicts an ensemble of possible conformations, which may be useful for explanation of a functioning of bitopic membrane proteins, e.g.
	receptor tyrosine kinases.
	Availability and implementation: PREDDIMER can be accessed for free on the web at http://model.nmr.ru/preddimer/Contact: newant@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: In recent years, the gulf between the mass of accumulating-research data and the massive literature describing and analyzing those data has widened.
	The need for intelligent tools to bridge this gap, to rescue the knowledge being systematically isolated in literature and data silos, is now widely acknowledged.
	Results: To this end, we have developed Utopia Documents, a novel PDF reader that semantically integrates visualization and dataanalysis tools with published research articles.
	In a successful pilot with editors of the Biochemical Journal (BJ), the system has been used to transform static document features into objects that can be linked, annotated, visualized and analyzed interactively (http://www.biochemj.org/bj/424/3/).
	Utopia Documents is now used routinely by BJ editors to mark up article content prior to publication.
	Recent additions include integration of various textmining and biodatabase plugins, demonstrating the system's ability to seamlessly integrate on-line content with PDF articles.
	Availability: http://getutopia.com Contact: teresa.k.attwood@manchester.ac.uk
	Motivation: The recently proposed Systems Biology Graphical Notation (SBGN) provides a standard for the visual representation of biochemical and cellular processes.
	It aims to support more efficient and accurate communication of biological knowledge between different research communities in the life sciences.
	However, to increase the use of SBGN, tools for editing, validating and translating SBGN maps are desirable.
	Results: We present SBGN-ED, a tool which allows the creation of all three types of SBGN maps from scratch or the editing of existing maps, the validation of these maps for syntactical and semantical correctness, the translation of networks from the KEGG and MetaCrop databases into SBGN and the export of SBGN maps into several file and image formats.
	Availability: SBGN-ED is freely available from http://vanted.ipkgatersleben.de/addons/sbgn-ed.
	The web site contains also tutorials and example files.
	Contact: schreibe@ipk-gatersleben.de
	Summary: Herein, we present CONSRANK, a web tool for analyzing, comparing and ranking protein-protein and protein-nucleic acid docking models, based on the conservation of interresidue contacts and its visualization in 2D and 3D interactive contact maps.
	Availability and implementation: CONSRANK is accessible as a public web tool at https://www.molnac.unisa.it/BioTools/consrank/.
	Contact: romina.oliva@uniparthenope.it
	Motivation: Microscopy advances have enabled the acquisition of large-scale biological images that capture whole tissues in situ.
	This in turn has fostered the study of spatial relationships between cells and various biological structures, which has proved enormously beneficial toward understanding organ and organism function.
	However, the unique nature of biological images and tissues precludes the application of many existing spatial mining and quantification methods necessary to make inferences about the data.
	Especially difficult is attempting to quantify the spatial correlation between heterogeneous structures and point objects, which often occurs in many biological tissues.
	Results: We develop a method to quantify the spatial correlation between a continuous structure and point data in large (17 500 17 500 pixel) biological images.
	We use this method to study the spatial relationship between the vasculature and a type of cell in the retina called astrocytes.
	We use a geodesic feature space based on vascular structures and embed astrocytes into the space by spatial sampling.
	We then propose a quantification method in this feature space that enables us to empirically demonstrate that the spatial distribution of astrocytes is often correlated with vascular structure.
	Additionally, these patterns are conserved in the retina after injury.
	These results prove the long-assumed patterns of astrocyte spatial distribution and provide a novel methodology for conducting other spatial studies of similar tissue and structures.
	Availability: The Matlab code for the method described in this article can be found at http://www.cs.ucsb.edu/ dbl/software.php.Contact: bruttenberg@cra.com or ambuj@cs.ucsb.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Conserved intron positions in eukaryotic genes can be used to reconstruct phylogenetic trees, to resolve ambiguous subfamily relationships in protein families and to infer the history of gene families.
	This version of GenePainter facilitates working with large datasets through options to select specific subsets for analysis and visualization, and through providing exhaustive statistics.
	GenePainter's application in phylogenetic analyses is considerably extended by the newly implemented integration of the exon-intron pattern conservation with phylogenetic trees.
	Availability and implementation: The software along with detailed documentation is available at http://www.motorprotein.de/genepainter and as Supplementary Material.Contact: mako@nmr.mpibpc.mpg.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The development of glycomics technologies in recent years has produced a sufficient amount of data to begin analyzing the glycan structures present in various organisms and tissues.
	In particular, glycan profiling using mass spectrometry (MS) and tandem MS has generated a large amount of data that are waiting to be analyzed.
	The Consortium for Functional Glycomics (CFG) has provided a web resource for obtaining such glycan profiling data easily.
	Although an interactive spectrum viewer is provided on the website as a Java applet, it is not necessarily easy to search for particular glycans or to find commonalities between different tissues in a single organism, for example.
	Therefore, to allow users to better take advantage of the valuable glycome data that can be obtained from mass spectra and other leading technologies, we have developed a tool called Glycome Atlas which is pre-loaded with the data from the CFG and is also able to visualize local glycan profiling data for human and mouse.
	Results: We have developed a tool to allow users to visualize and perform queries of glycome data.
	This tool, called GlycomeAtlas, is pre-loaded with glycome data as provided by the CFG.
	Moreover, users can load their own local glycome data into this tool to visualize and perform queries on their own data.
	Availability: This tool is available at the following URL: http://www .rings.t.soka.ac.jp/GlycomeAtlas/GUI.html.
	Contact: kkiyoko@soka.ac.jp Text versions of the profiling data were obtained from the CFG website for each wild-type tissue sample in human and mouse.
	These data are stored in a MySQL database on the RINGS resource (Akune et al., 2010) at http://www.rings.t.soka.ac.jp/.GlycomeAtlas was built using Adobe Flash Professional CS4, using Adobe Flex and Flash Builder 4.
	ActionScript 3.0 was used to implement the web interface functionality, and Java Server Pages (JSP) was used to interact with the database.
	Summary: GPViz is a versatile Java-based software for dynamic gene-centered visualization of genomic regions and/or variants.
	User-defined data can be loaded in common formats as resulting from analysis workflows used in sequencing applications and studied in the context of the gene, the corresponding transcript isoforms, proteins and their domains or other protein features.
	Both the genomic regions and variants can be also defined interactively.
	Various gene filter options are provided to enable an intersection of variants, genomic regions and affected protein features.
	Finally, by using GPViz, we identified differentially expressed exons, which could indicate alternative splicing events, and found somatic variants in different cancer types affecting metabolic proteins.
	GPViz is freely available at http://icbi.at/gpviz (released under GNU general public license), is based on Java 7 and can be used as a stand-alone or Web Start application.
	Availability: http://icbi.at/gpviz Contact: hubert.hackl@i-med.ac.at Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Bacterial resistance to antibiotics, particularly plasmid-encoded resistance to beta lactam drugs, poses an increasing threat to human health.
	Point mutations to beta-lactamase enzymes can greatly alter the level of resistance conferred, but predicting the effects of such mutations has been challenging due to the large combinatorial space involved and the subtle relationships of distant residues to catalytic function.
	Therefore we desire an information-theoretic metric to sensitively and robustly detect both local and distant residues that affect substrate conformation and catalytic activity.
	Results: Here, we report the use of positional mutual information in multiple microsecond-length molecular dynamics (MD) simulations to predict residues linked to catalytic activity of the CTX-M9 beta lactamase.
	We find that motions of the bound drug are relatively isolated from motions of the protein as a whole, which we interpret in the context of prior theories of catalysis.
	In order to robustly identify residues that are weakly coupled to drug motions but nonetheless affect catalysis, we utilize an excess mutual information metric.
	We predict 31 such residues for the cephalosporin antibiotic cefotaxime.
	Nine of these have previously been tested experimentally, and all decrease both enzyme rate constants and empirical drug resistance.
	We prospectively validate our method by testing eight high-scoring mutations and eight low-scoring controls in bacteria.
	Six of eight predicted mutations decrease cefotaxime resistance greater than 2-fold, while only one control shows such an effect.
	The ability to prospectively predict new variants affecting bacterial drug resistance is of great interest to clinical and epidemiological surveillance.
	Availability and implementation: Excess mutual information code is available at https://github.com/kassonlab/positionalmi Contact: kasson@virginia.edu
	Motivation: Multiple sequence alignment (MSA) is important work, but bottlenecks arise in the massive MSA of homologous DNA or genome sequences.
	Most of the available state-of-the-art software tools cannot address large-scale datasets, or they run rather slowly.
	The similarity of homologous DNA sequences is often ignored.
	Lack of parallelization is still a challenge for MSA research.
	Results: We developed two software tools to address the DNA MSA problem.
	The first employed trie trees to accelerate the centre star MSA strategy.
	The expected time complexity was decreased to linear time from square time.
	To address large-scale data, parallelism was applied using the hadoop platform.
	Experiments demonstrated the performance of our proposed methods, including their running time, sum-of-pairs scores and scalability.
	Moreover, we supplied two massive DNA/ RNA MSA datasets for further testing and research.
	Availability and implementation: The codes, tools and data are accessible free of charge at http://datamining.xmu.edu.cn/software/halign/.
	Contact: zouquan@nclab.net or ghwang@hit.edu.cn
	Rhea (http://www.ebi.ac.uk/rhea) is a comprehensive resource of expert-curated biochemical reactions.
	Rhea provides a non-redundant set of chemical transformations for use in a broad spectrum of applications, including metabolic network reconstruction and pathway inference.
	Rhea includes enzyme-catalyzed reactions (covering the IUBMB Enzyme Nomenclature list), transport reactions and spontaneously occurring reactions.
	Rhea reactions are described using chemical species from the Chemical Entities of Biological Interest ontology (ChEBI) and are stoichiometrically balanced for mass and charge.
	They are extensively manually curated with links to source literature and other public resources on metabolism including enzyme and pathway databases.
	This cross-referencing facilitates the mapping and reconciliation of common reactions and compounds between distinct resources, which is a common first step in the reconstruction of genome scale metabolic networks and models.
	Motivation: Modelling the 3D structures of proteins can often be enhanced if more than one fold template is used during the modelling process.
	However, in many cases, this may also result in poorer model quality for a given target or alignment method.
	There is a need for modelling protocols that can both consistently and significantly improve 3D models and provide an indication of when models might not benefit from the use of multiple target-template alignments.
	Here, we investigate the use of both global and local model quality prediction scores produced by ModFOLDclust2, to improve the selection of target-template alignments for the construction of multiple-template models.
	Additionally, we evaluate clustering the resulting population of multi- and single-template models for the improvement of our IntFOLD-TS tertiary structure prediction method.
	Results: We find that using accurate local model quality scores to guide alignment selection is the most consistent way to significantly improve models for each of the sequence to structure alignment methods tested.
	In addition, using accurate global model quality for re-ranking alignments, prior to selection, further improves the majority of multi-template modelling methods tested.
	Furthermore, subsequent clustering of the resulting population of multipletemplate models significantly improves the quality of selected models compared with the previous version of our tertiary structure prediction method, IntFOLD-TS.
	Availability and implementation: Source code and binaries can be freely downloaded from http://www.reading.ac.uk/bioinf/downloads/.
	Contact: l.j.mcguffin@reading.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	http://www.reading.ac.uk/bioinf/MTM_suppl_ info.pdf
	Summary: GlycoPattern is Web-based bioinformatics resource to support the analysis of glycan array data for the Consortium for Functional Glycomics.
	This resource includes algorithms and tools to discover structural motifs, a heatmap visualization to compare multiple experiments, hierarchical clustering of Glycan Binding Proteins with respect to their binding motifs and a structural search feature on the experimental data.
	Availability and implementation: GlycoPattern is freely available on the Web at http://glycopattern.emory.edu with all major browsers supported.
	Contact: sanjay.agravat@emory.edu
	Motivation: Gene networks have been used widely in gene function prediction algorithms, many based on complex extensions of the 'guilt by association' principle.
	We sought to provide a unified explanation for the performance of gene function prediction algorithms in exploiting network structure and thereby simplify future analysis.
	Results: We use co-expression networks to show that most exploited network structure simply reconstructs the original correlation matrices from which the co-expression network was obtained.
	We show the same principle works in predicting gene function in protein interaction networks and that these methods perform comparably to much more sophisticated gene function prediction algorithms.
	Availability and implementation: Data and algorithm implementation are fully described and available at http://www .chibi.ubc.ca/extended.
	Programs are provided in Matlab m-code.
	Contact: paul@chibi.ubc.ca Supplementary information: Supplementary data are available at Bioinformatics online.
	1 INTRODUCTION Motivation: Nonlinear small datasets, which are characterized by 1.1 The machine learning perspective low numbers of samples and very high numbers of measures, occur frequently in computational biology, and pose problems in their Visualization and discrimination as well as supervised and investigation.
	Unsupervised hybrid-two-phase (H2P) procedures- unsupervised classifications are widely employed in computational specifically dimension reduction (DR), coupled with clustering- biology for the investigation and analysis of patterns hidden in wetprovide valuable assistance, not only for unsupervised data lab data.
	In the literature, 'supervised classification' is frequently classification, but also for visualization of the patterns hidden in simplified into 'classification', and 'unsupervised classification' into high-dimensional feature space.
	'clustering' and this may give rise to misunderstanding.
	To avoid Methods: 'Minimum Curvilinearity' (MC) is a principle that-for terminological ambiguity, 'classification' is adopted throughout this small datasets-suggests the approximation of curvilinear sample article to describe the general task of sample group attribution, while distances in the feature space by pair-wise distances over their the issue of whether such attribution is supervised or unsupervised minimum spanning tree (MST), and thus avoids the introduction of will be specified as and when necessary.
	any tuning parameter.
	MC is used to design two novel forms of Supervised methods for feature selection and classification nonlinear machine learning (NML): Minimum Curvilinear embedding present several pitfalls (Smialowski et al., 2009), and small (MCE) for DR, and Minimum Curvilinear affinity propagation (MCAP) datasets make analysis problematic (Martella, 2006).
	Complications for clustering.
	particularly intensify when samples are nonlinearly related in Results: Compared with several other unsupervised and supervised the high-dimensional feature space obtained from high-throughput algorithms, MCE and MCAP, whether individually or combined in genomic and proteomic measures.
	When the aim is to classify a low H2P, overcome the limits of classical approaches.
	High performance number of samples characterized by a very large number of genes, was attained in the visualization and classification of: (i) pain patients problems with parameter estimation may arise, and dimensional (proteomic measurements) in peripheral neuropathy; (ii) human organ reduction followed by clustering (Martella, 2006) is a valuable tissues (genomic transcription factor measurements) on the basis of response to this scenario.
	Principal component analysis (PCA) their embryological origin.
	has often been employed (Martella, 2006) in combination with a Conclusion: MC provides a valuable framework to estimate clustering algorithm that groups homogeneous classes on the basis nonlinear distances in small datasets.
	Its extension to large datasets of principal components, but this approach is insufficiently powerful is prefigured for novel NMLs.
	Classification of neuropathic pain to deal with nonlinear datasets.
	In this article, we describe the use of by proteomic profiles offers new insights for future molecular and nonlinear hybrid-two-phase (H2P) unsupervised machine learning systems biology characterization of pain.
	Improvements in tissue (ML) methodologies-specifically dimension reduction (DR) in embryological classification refine results obtained in an earlier conjunction with clustering-for the concurrent visualization and study, and suggest a possible reinterpretation of skin attribution as classification of biological samples.
	Our aim is to address the issue mesodermal.
	of nonlinearity and to improve the classification accuracy of recently Availability: https://sites.google.com/site/carlovittoriocannistraci/home proposed small nonlinear datasets.
	The methodological innovation Contact: kalokagathos.agon@gmail.com; massimo.alessio@hsr.it we introduce is a principle called 'Minimum Curvilinearity' (MC), Supplementary information: Supplementary data are available at which is used as framework for two novel forms of nonlinear Bioinformatics online.
	ML (NML): Minimum Curvilinear embedding (MCE) for DR and Minimum Curvilinear affinity propagation (MCAP) for clustering.
	For small datasets, the 'MC' principle suggests the estimation of curvilinear (geodesic) distances between sample data points as pairwise distances over their minimum spanning tree (MST) constructed âˆ—To whom correspondence should be addressed.
	in feature space.
	Motivation: Exploring the genetic basis of heritable traits remains one of the central challenges in biomedical research.
	In traits with simple Mendelian architectures, single polymorphic loci explain a significant fraction of the phenotypic variability.
	However, many traits of interest seem to be subject to multifactorial control by groups of genetic loci.
	Accurate detection of such multivariate associations is non-trivial and often compromised by limited statistical power.
	At the same time, confounding influences, such as population structure, cause spurious association signals that result in false-positive findings.
	Results: We propose linear mixed models LMM-Lasso, a mixed model that allows for both multi-locus mapping and correction for confounding effects.
	Our approach is simple and free of tuning parameters; it effectively controls for population structure and scales to genome-wide datasets.
	LMM-Lasso simultaneously discovers likely causal variants and allows for multi-marker-based phenotype prediction from genotype.
	We demonstrate the practical use of LMM-Lasso in genome-wide association studies in Arabidopsis thaliana and linkage mapping in mouse, where our method achieves significantly more accurate phenotype prediction for 91% of the considered phenotypes.
	At the same time, our model dissects the phenotypic variability into components that result from individual single nucleotide polymorphism effects and population structure.
	Enrichment of known candidate genes suggests that the individual associations retrieved by LMM-Lasso are likely to be genuine.
	Availability: Code available under http://webdav.tuebingen.mpg.de/u/karsten/Forschung/research.html.
	Contact: rakitsch@tuebingen.mpg.de, ippert@microsoft.com or stegle@ebi.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Analyzing genome wide association data in the context of biological pathways helps us understand how genetic variation influences phenotype and increases power to find associations.
	However, the utility of pathway-based analysis tools is hampered by undercuration and reliance on a distribution of signal across all of the genes in a pathway.
	Methods that combine genome wide association results with genetic networks to infer the key phenotype-modulating subnetworks combat these issues, but have primarily been limited to network definitions with yes/ no labels for gene-gene interactions.
	A recent method (EW_dmGWAS) incorporates a biological network with weighted edge probability by requiring a secondary phenotype-specific expression dataset.
	In this article, we combine an algorithm for weighted-edge module searching and a probabilistic interaction network in order to develop a method, STAMS, for recovering modules of genes with strong associations to the phenotype and probable biologic coherence.
	Our method builds on EW_dmGWAS but does not require a secondary expression dataset and performs better in six test cases.
	Results: We show that our algorithm improves over EW_dmGWAS and standard gene-based analysis by measuring precision and recall of each method on separately identified associations.
	In the Wellcome Trust Rheumatoid Arthritis study, STAMS-identified modules were more enriched for separately identified associations than EW_dmGWAS (STAMS P-value 3.0 10 4; EW_dmGWASP-value Â¼ 0.8).
	We demonstrate that the area under the Precision-Recall curve is 5.9 times higher with STAMS than EW_dmGWAS run on the Wellcome Trust Type 1 Diabetes data.
	Availability and Implementation: STAMS is implemented as an R package and is freely available at https://simtk.org/projects/stams.Contact: rbaltman@stanford.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: MODalign is an interactive web-based tool aimed at helping protein structure modelers to inspect and manually modify the alignment between the sequences of a target protein and of its template(s).
	It interactively computes, displays and, upon modification of the target-template alignment, updates the multiple sequence alignments of the two protein families, their conservation score, secondary structure and solvent accessibility values, and local quality scores of the implied three-dimensional model(s).
	Although it has been designed to simplify the target-template alignment step in modeling, it is suitable for all cases where a sequence alignment needs to be inspected in the context of other biological information.
	Availability and implementation: Freely available on the web at http://modorama.biocomputing.it/modalign.
	Website implemented in HTML and JavaScript with all major browsers supported.
	Contact: jan.kosinski@uniroma1.it
	Summary: Progress in high-throughput genomic technologies has led to the development of a variety of resources that link genes to functional information contained in the biomedical literature.
	However, tools attempting to link small molecules to normal and diseased physiology and published data relevant to biologists and clinical investigators, are still lacking.
	With metabolomics rapidly emerging as a new omics field, the task of annotating small molecule metabolites becomes highly relevant.
	Our tool Metab2MeSH uses a statistical approach to reliably and automatically annotate compounds with concepts defined in Medical Subject Headings, and the National Library of Medicine's controlled vocabulary for biomedical concepts.
	These annotations provide links from compounds to biomedical literature and complement existing resources such as PubChem and the Human Metabolome Database.
	Availability: http://metab2mesh.ncibi.org Contact: akarnovs@umich.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: When analyzing solid-state nuclear magnetic resonance (NMR) spectra of proteins, assignment of resonances to nuclei and derivation of restraints for 3D structure calculations are challenging and time-consuming processes.
	Simulated spectra that have been calculated based on, for example, chemical shift predictions and structural models can be of considerable help.
	Existing solutions are typically limited in the type of experiment they can consider and difficult to adapt to different settings.
	Results: Here, we present Peakr, a software to simulate solid-state NMR spectra of proteins.
	It can generate simulated spectra based on numerous common types of internuclear correlations relevant for assignment and structure elucidation, can compare simulated and experimental spectra and produces lists and visualizations useful for analyzing measured spectra.
	Compared with other solutions, it is fast, versatile and user friendly.
	Availability and implementation: Peakr is maintained under the GPL license and can be accessed at http://www.peakr.org.
	The source code can be obtained on request from the authors.
	Contact: robert.schneider@ibs.fr or mako@nmr.mpibpc.mpg.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Computational prediction of compound-protein interactions (CPIs) is of great importance for drug design and development, as genome-scale experimental validation of CPIs is not only time-consuming but also prohibitively expensive.
	With the availability of an increasing number of validated interactions, the performance of computational prediction approaches is severely impended by the lack of reliable negative CPI samples.
	A systematic method of screening reliable negative sample becomes critical to improving the performance of in silico prediction methods.
	Results: This article aims at building up a set of highly credible negative samples of CPIs via an in silico screening method.
	As most existing computational models assume that similar compounds are likely to interact with similar target proteins and achieve remarkable performance, it is rational to identify potential negative samples based on the converse negative proposition that the proteins dissimilar to every known/predicted target of a compound are not much likely to be targeted by the compound and vice versa.
	We integrated various resources, including chemical structures, chemical expression profiles and side effects of compounds, amino acid sequences, protein-protein interaction network and functional annotations of proteins, into a systematic screening framework.
	We first tested the screened negative samples on six classical classifiers, and all these classifiers achieved remarkably higher performance on our negative samples than on randomly generated negative samples for both human and Caenorhabditis elegans.
	We then verified the negative samples on three existing prediction models, including bipartite local model, Gaussian kernel profile and Bayesian matrix factorization, and found that the performances of these models are also significantly improved on the screened negative samples.
	Moreover, we validated the screened negative samples on a drug bioactivity dataset.
	Finally, we derived two sets of new interactions by training an support vector machine classifier on the positive interactions annotated in DrugBank and our screened negative interactions.
	The screened negative samples and the predicted interactions provide the research community with a useful resource for identifying new drug targets and a helpful supplement to the current curated compound-protein databases.
	Availability: Supplementary files are available at: http://admis.fudan.edu.cn/negative-cpi/.Contact: sgzhou@fudan.edu.cn Supplementary Information: Supplementary data are available at Bioinformatics online.
	Motivation: Riboswitches are short sequences of messenger RNA that can change their structural conformation to regulate the expression of adjacent genes.
	Computational prediction of putative riboswitches can provide direction to molecular biologists studying riboswitch-mediated gene expression.
	Results: The Denison Riboswitch Detector (DRD) is a new computational tool with a Web interface that can quickly identify putative riboswitches in DNA sequences on the scale of bacterial genomes.
	Riboswitch descriptions are easily modifiable and new ones are easily created.
	The underlying algorithm converts the problem to a 'heaviest path' problem on a multipartite graph, which is then solved using efficient dynamic programming.
	We show that DRD can achieve 88-99% sensitivity and 499.99% specificity on 13 riboswitch families.
	Availability and implementation: DRD is available at http://drd.denison.edu.
	Contact: havill@denison.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Antigenic cartography is a useful technique to visualize and minimize errors in immunological data by projecting antigens to 2D or 3D cartography.
	However, a 2D cartography may not be sufficient to capture the antigenic relationship from high-dimensional immunological data.
	AntigenMap 3D presents an online, interactive, and robust 3D antigenic cartography construction and visualization resource.
	AntigenMap 3D can be applied to identify antigenic variants and vaccine strain candidates for pathogens with rapid antigenic variations, such as influenza A virus.
	Availability and implementation: http://sysbio.cvm.msstate.edu/AntigenMap3D Contact: wan@cvm.msstate.edu; wanhenry@yahoo.com AntigenMap 3D is written in Java and PHP and uses Jmol (jmol.sourceforge.net) (Herraez, 2006) to display the 3D graph by MC-MDS (Cai et al., 2010).
	The front-end uses the XHTML 1.0 and CSS 3 standards to ensure a consistent display across different platforms.
	PHP is used to generate the dynamic pages and for data handling.
	The computational backend implementing the MC-MDS algorithm is written in
	The mission of the Universal Protein Resource (UniProt) (http://www.uniprot.org) is to provide the scientific community with a comprehensive, highquality and freely accessible resource of protein sequences and functional annotation.
	It integrates, interprets and standardizes data from literature and numerous resources to achieve the most comprehensive catalog possible of protein information.
	The central activities are the biocuration of the UniProt Knowledgebase and the dissemination of these data through our Web site and web services.
	UniProt is produced by the UniProt Consortium, which consists of groups from the European Bioinformatics Institute (EBI), the SIB Swiss Institute of Bioinformatics (SIB) and the Protein Information Resource (PIR).
	UniProt is updated and distributed every 4 weeks and can be accessed online for searches or downloads.
	Motivation: DIYABC is a software package for a comprehensive analysis of population history using approximate Bayesian computation on DNA polymorphism data.
	Version 2.0 implements a number of new features and analytical methods.
	It allows (i) the analysis of single nucleotide polymorphism data at large number of loci, apart from microsatellite and DNA sequence data, (ii) efficient Bayesian model choice using linear discriminant analysis on summary statistics and (iii) the serial launching of multiple post-processing analyses.
	DIYABC v2.0 also includes a user-friendly graphical interface with various new options.
	It can be run on three operating systems: GNU/Linux, Microsoft Windows and Apple Os X.
	Availability: Freely available with a detailed notice document and example projects to academic users at http://www1.montpellier.inra.fr/CBGP/diyabc Contact: estoup@supagro.inra.fr Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Identifying, amongst millions of publications available in MEDLINE, those that are relevant to specific microRNAs (miRNAs) of interest based on keyword search faces major obstacles.
	References to miRNA names in the literature often deviate from standard nomenclature for various reasons, since even the official nomenclature evolves.
	For instance, a single miRNA name may identify two completely different molecules or two different names may refer to the same molecule.
	mirPub is a database with a powerful and intuitive interface, which facilitates searching for miRNA literature, addressing the aforementioned issues.
	To provide effective search services, mirPub applies text mining techniques on MEDLINE, integrates data from several curated databases and exploits data from its user community following a crowdsourcing approach.
	Other key features include an interactive visualization service that illustrates intuitively the evolution of miRNA data, tag clouds summarizing the relevance of publications to particular diseases, cell types or tissues and access to TarBase 6.0 data to oversee genes related to miRNA publications.
	Availability and Implementation: mirPub is freely available at http://www.microrna.gr/mirpub/.Contact: vergoulis@imis.athena-innovation.gr or dalamag@imis.athena-innovation.gr Supplementary information: Supplementary data are available at Bioinformatics online.
	The EMBL-EBI provides access to various mainstream sequence analysis applications.
	These include sequence similarity search services such as BLAST, FASTA, InterProScan and multiple sequence alignment tools such as ClustalW, T-Coffee and MUSCLE.
	Through the sequence similarity search services, the users can search mainstream sequence databases such as EMBL-Bank and UniProt, and more than 2000 completed genomes and proteomes.
	We present here a new framework aimed at both novice as well as expert users that exposes novel methods of obtaining annotations and visualizing sequence analysis results through one uniform and consistent interface.
	These services are available over the web and via Web Services interfaces for users who require systematic access or want to interface with customized pipe-lines and workflows using common programming languages.
	The framework features novel result visualizations and integration of domain and functional predictions for protein database searches.
	It is available at http://www .ebi.ac.uk/Tools/sss for sequence similarity searches and at http://www.ebi.ac.uk/Tools/msa for multiple sequence alignments.
	Motivation: Real time quantitative polymerase chain reaction (qPCR) is an important tool in quantitative studies of DNA and RNA molecules; especially in transcriptome studies, where different primer combinations allow identification of specific transcripts such as splice variants or precursor messenger RNA.
	Several softwares that implement various rules for optimal primer design are available.
	Nevertheless, as designing qPCR primers needs to be done manually, the repeated task is tedious, time consuming and prone to errors.
	Results: We used a set of rules to automatically design all possible exon-exon and intron-exon junctions in the human and mouse transcriptomes.
	The resulting database is included as a track in the UCSC genome browser, making it widely accessible and easy to use.
	Availability: The database is available from the UCSC genome browser (http://genome.ucsc.edu/), track name 'Whole Transcriptome qPCR Primers' for the hg19 (Human) and mm10 (Mouse) genome versions.
	Batch query is available in the following: http://www.weiz mann.ac.il/complex/compphys/software/Amit/primers/batch_query_ qpcr_primers.htm Contact: amit.zeisel@weizmann.ac.il or eytan.domany@weizmann.
	ac.il Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Ultra-deep sampling of small RNA libraries by nextgeneration sequencing has provided rich information on the microRNA (miRNA) transcriptome of various plant species.
	However, few computational tools have been developed to effectively deconvolute the complex information.
	Results: We sought to employ the signature distribution of small RNA reads along the miRNA precursor as a model in plants to profile expression of known miRNA genes and to identify novel ones.
	A freely available package, miRDeep-P, was developed by modifying miRDeep, which is based on a probabilistic model of miRNA biogenesis in animals, with a plant-specific scoring system and filtering criteria.
	We have tested miRDeep-P on eight small RNA libraries derived from three plants.
	Our results demonstrate miRDeep-P as an effective and easy-to-use tool for characterizing the miRNA transcriptome in plants.
	Availability: http://faculty.virginia.edu/lilab/miRDP/Contact: ll4jn@virginia.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Funding sources were omitted in the article initially published.
	The authors acknowledge the funding by 'Basic Science Research Program' through the NRF of Korea funded by MSIP (NRF-2013R1A1A3005259), 'Next-Generation Information Computing Development Program' through the NRF of Korea funded by MOE (2012M3C4A7033344), and the ICT R&D program of MSIP/IITP (14-824-09-014).The authors apologize for this error.
	Motivation: Many practical tasks in biomedicine require accessing specific types of information in scientific literature; e.g.
	information about the methods, results or conclusions of the study in question.
	Several approaches have been developed to identify such information in scientific journal articles.
	The best of these have yielded promising results and proved useful for biomedical text mining tasks.
	However, relying on fully supervised machine learning (ML) and a large body of annotated data, existing approaches are expensive to develop and port to different tasks.
	A potential solution to this problem is to employ weakly supervised learning instead.
	In this article, we investigate a weakly supervised approach to identifying information structure according to a scheme called Argumentative Zoning (AZ).
	We apply four weakly supervised classifiers to biomedical abstracts and evaluate their performance both directly and in a real-life scenario in the context of cancer risk assessment.
	Results: Our best weakly supervised classifier (based on the combination of active learning and self-training) performs well on the task, outperforming our best supervised classifier: it yields a high accuracy of 81% when just 10% of the labeled data is used for training.
	When cancer risk assessors are presented with the resulting annotated abstracts, they find relevant information in them significantly faster than when presented with unannotated abstracts.
	These results suggest that weakly supervised learning could be used to improve the practical usefulness of information structure for real-life tasks in biomedicine.
	Availability: The annotated dataset, classifiers and the user test for cancer risk assessment are available online at http://www.cl.cam.ac.uk/~yg244/11bioinfo.html.Contact: anna.korhonen@cl.cam.ac.uk
	Motivation: Analyzing data from multi-platform genomics experiments combined with patients' clinical outcomes helps us understand the complex biological processes that characterize a disease, as well as how these processes relate to the development of the disease.
	Current data integration approaches are limited in that they do not consider the fundamental biological relationships that exist among the data obtained from different platforms.
	Statistical Model: We propose an integrative Bayesian analysis of genomics data (iBAG) framework for identifying important genes/ biomarkers that are associated with clinical outcome.
	This framework uses hierarchical modeling to combine the data obtained from multiple platforms into one model.
	Results: We assess the performance of our methods using several synthetic and real examples.
	Simulations show our integrative methods to have higher power to detect disease-related genes than non-integrative methods.
	Using the Cancer Genome Atlas glioblastoma dataset, we apply the iBAG model to integrate gene expression and methylation data to study their associations with patient survival.
	Our proposed method discovers multiple methylation-regulated genes that are related to patient survival, most of which have important biological functions in other diseases but have not been previously studied in glioblastoma.
	Availability: http://odin.mdacc.tmc.edu/ vbaladan/.Contact: veera@mdanderson.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Quality assessment of protein structures is an important part of experimental structure validation and plays a crucial role in protein structure prediction, where the predicted models may contain substantial errors.
	Most current scoring functions are primarily designed to rank alternative models of the same sequence supporting model selection, whereas the prediction of the absolute quality of an individual protein model has received little attention in the field.
	However, reliable absolute quality estimates are crucial to assess the suitability of a model for specific biomedical applications.
	Results: In this work, we present a new absolute measure for the quality of protein models, which provides an estimate of the 'degree of nativeness' of the structural features observed in a model and describes the likelihood that a given model is of comparable quality to experimental structures.
	Model quality estimates based on the QMEAN scoring function were normalized with respect to the number of interactions.
	The resulting scoring function is independent of the size of the protein and may therefore be used to assess both monomers and entire oligomeric assemblies.
	Model quality scores for individual models are then expressed as 'Z-scores' in comparison to scores obtained for high-resolution crystal structures.
	We demonstrate the ability of the newly introduced QMEAN Z-score to detect experimentally solved protein structures containing significant errors, as well as to evaluate theoretical protein models.
	In a comprehensive QMEAN Z-score analysis of all experimental structures in the PDB, membrane proteins accumulate on one side of the score spectrum and thermostable proteins on the other.
	Proteins from the thermophilic organism Thermatoga maritima received significantly higher QMEAN Z-scores in a pairwise comparison with their homologous mesophilic counterparts, underlining the significance of the QMEAN Z-score as an estimate of protein stability.
	Availability: The Z-score calculation has been integrated in the QMEAN server available at: http://swissmodel.expasy.org/qmean.Contact: torsten.schwede@unibas.ch Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Targeting peptides are the most important signal controlling the import of nuclear encoded proteins into mitochondria and plastids.
	In the lack of experimental information, their prediction is an essential step when proteomes are annotated for inferring both the localization and the sequence of mature proteins.
	Results: We developed TPpred a new predictor of organelle-targeting peptides based on Grammatical-Restrained Hidden Conditional Random Fields.
	TPpred is trained on a non-redundant dataset of proteins where the presence of a target peptide was experimentally validated, comprising 297 sequences.
	When tested on the 297 positive and some other 8010 negative examples, TPpred outperformed available methods in both accuracy and Matthews correlation index (96% and 0.58, respectively).
	Given its very low-false-positive rate (3.0%), TPpred is, therefore, well suited for large-scale analyses at the proteome level.
	We predicted that from 4 to 9% of the sequences of human, Arabidopsis thaliana and yeast proteomes contain targeting peptides and are, therefore, likely to be localized in mitochondria and plastids.
	TPpred predictions correlate to a good extent with the experimental annotation of the subcellular localization, when available.
	TPpred was also trained and tested to predict the cleavage site of the organelle-targeting peptide: on this task, the average error of TPpred on mitochondrial and plastidic proteins is 7 and 15 residues, respectively.
	This value is lower than the error reported by other methods currently available.
	Availability: The TPpred datasets are available at http://biocomp.unibo.it/ valentina/TPpred/.
	TPpred is available on request from the authors.
	Contact: gigi@biocomp.unibo.it Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Methods for detecting positive selection relied on finding evidence of long haplotypes to identify candidate regions under selection.
	However, these methods generally do not identify the length and form of the selected haplotype.
	Results: We present HapFinder, a method which can find the common longest haplotype under three different settings from a database, which is relevant in the analysis of positive selection in population genetics and also in medical genetics for finding the likely haplotype form carrying the causal allele at the functional polymorphism.
	Availability: A java program, implementing the methods described in HapFinder, together with R scripts and datasets for producing the figures presented in this article are publicly available at http://www.nus-cme.org.sg/sgvp/software/hapfinder.html.
	The site also hosts an online browser for finding haplotypes from the International HapMap Project and the Singapore Genome Variation Project.
	Contact: g0801900@nus.edu.sg; statyy@nus.edu.sg
	Motivation: MicroRNAs (miRNAs) are major regulators of gene expression in plants and animals.
	They recognize their target messenger RNAs (mRNAs) by sequence complementarity and guide them to cleavage or translational arrest.
	So far, the prediction of plant miRNA-target pairs generally relies on the use of empirical parameters deduced from known miRNA-target interactions.
	Results: We developed comTAR, a web tool for the prediction of miRNA targets that is mainly based on the conservation of the potential regulation in different species.
	We used data generated from a pipeline applied to transcript datasets of 33 angiosperms that was used to build a database of potential miRNA targets of different plant species.
	The database contains information describing each miRNA-target pair, their function and evolutionary conservation, while the results are displayed in a user-friendly interface.
	The tool also allows the search using new miRNAs.
	Availability and implementation: The Web site is free to all users, with no login requirements, at http://rnabiology.ibr-conicet.gov.ar/comtar.
	Contact: palatnik@ibr-conicet.gov.ar or chorostecki@ibr-conicet.gov.
	ar
	Summary: Waggawagga is a web-based tool for the comparative visualization of coiled-coil predictions and the detection of stable single a-helices (SAH domains).
	Overview schemes show the predicted coiled-coil regions found in the query sequence and provide sliders, which can be used to select segments for detailed helical wheel and helical net views.
	A window-based score has been developed to predict SAH domains.
	Export to several bitmap and vector graphics formats is supported.
	Availability and implementation: http://waggawagga.motorprotein.de Contact: mako@nmr.mpibpc.mpg.de VC The Author 2014.
	Published by Oxford University Press.
	All rights reserved.
	For Permissions, please e-mail: journals.permissions@oup.com
	The regulation of transcription of eukaryotic genes is a very complex process, which involves interactions between transcription factors (TFs) and DNA, as well as other epigenetic factors like histone modifications, DNA methylation, and so on, which nowadays can be studied and characterized with techniques like ChIP-Seq.
	Cscan is a web resource that includes a large collection of genome-wide ChIP-Seq experiments performed on TFs, histone modifications, RNA polymerases and others.
	Enriched peak regions from the ChIP-Seq experiments are crossed with the genomic coordinates of a set of input genes, to identify which of the experiments present a statistically significant number of peaks within the input genes' loci.
	The input can be a cluster of co-expressed genes, or any other set of genes sharing a common regulatory profile.
	Users can thus single out which TFs are likely to be common regulators of the genes, and their respective correlations.
	Also, by examining results on promoter activation, transcription, histone modifications, polymerase binding and so on, users can investigate the effect of the TFs (activation or repression of transcription) as well as of the cell or tissue specificity of the genes' regulation and expression.
	The web interface is free for use, and there is no login requirement.
	Available at: http://www.beaconlab.it/cscan.
	Motivation: Although chromatin immunoprecipitation coupled with high-throughput sequencing (ChIP-seq) or tiling array hybridization (ChIP-chip) is increasingly used to map genome-wide-binding sites of transcription factors (TFs), it still remains difficult to generate a quality ChIPx (i.e.
	ChIP-seq or ChIP-chip) dataset because of the tremendous amount of effort required to develop effective antibodies and efficient protocols.
	Moreover, most laboratories are unable to easily obtain ChIPx data for one or more TF(s) in more than a handful of biological contexts.
	Thus, standard ChIPx analyses primarily focus on analyzing data from one experiment, and the discoveries are restricted to a specific biological context.
	Results: We propose to enrich this existing data analysis paradigm by developing a novel approach, ChIP-PED, which superimposes ChIPx data on large amounts of publicly available human and mouse gene expression data containing a diverse collection of cell types, tissues and disease conditions to discover new biological contexts with potential TF regulatory activities.
	We demonstrate ChIP-PED using a number of examples, including a novel discovery that MYC, a human TF, plays an important functional role in pediatric Ewing sarcoma cell lines.
	These examples show that ChIP-PED increases the value of ChIPx data by allowing one to expand the scope of possible discoveries made from a ChIPx experiment.
	Availability: http://www.biostat.jhsph.edu/ gewu/ChIPPED/Contact: hji@jhsph.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: SPEPlip is a neural network-based method, trained and tested on a set of experimentally derived signal peptides from eukaryotes and prokaryotes.
	SPEPlip identifies the presence of sorting signals and predicts their cleavage sites.
	The accuracy in cross-validation is similar to that of other available programs: the rate of false positives is 4 and 6%, for prokaryotes and eukaryotes respectively and that of false negatives is 3% in both cases.
	When a set of 409 prokaryotic lipoproteins is predicted, SPEPlip predicts 97% of the chains in the signal peptide class.
	However, by integrating SPEPlip with a regular expression search utility based on the PROSITE pattern, we can successfully discriminate signal peptide-containing chains from lipoproteins.
	We propose the method for detecting and discriminating signal peptides containing chains and lipoproteins.
	Availability: It can be accessed through the web page at http://gpcr.biocomp.unibo.it/predictors/Contact: piero@biocomp.unibo.it Table 1.
	Cross-validation SPEP accuracy on the Mennea data set
	Motivation: Atomic resolution modeling of large multimolecular assemblies is a key task in Structural Cell Biology.
	Experimental techniques can provide atomic resolution structures of single proteins and small complexes, or low resolution data of large multimolecular complexes.
	Results: We present a novel integrative computational modeling method, which integrates both low and high resolution experimental data.
	The algorithm accepts as input atomic resolution structures of the individual subunits obtained from X-ray, NMR or homology modeling, and interaction data between the subunits obtained from mass spectrometry.
	The optimal assembly of the individual subunits is formulated as an Integer Linear Programming task.
	The method was tested on several representative complexes, both in the bound and unbound cases.
	It placed correctly most of the subunits of multimolecular complexes of up to 16 subunits and significantly outperformed the CombDock and Haddock multimolecular docking methods.
	Availability and implementation: http://bioinfo3d.cs.tau.ac.il/DockStar Contact: naamaamir@mail.tau.ac.il or wolfson@tau.ac.il Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: KEGG pathway database is a collection of manually drawn pathway maps accompanied with KGML format files intended for use in automatic analysis.
	KGML files, however, do not contain the required information for complete reproduction of all the events indicated in the static image of a pathway map.
	Several parsers and editors of KEGG pathways exist for processing KGML files.
	We introduce KEGGParser-a MATLAB based tool for KEGG pathway parsing, semiautomatic fixing, editing, visualization and analysis in MATLAB environment.
	It also works with Scilab.
	Availability and implementation: The source code is available at http://www.mathworks.com/matlabcentral/fileexchange/37561.Contact: aarakelyan@sci.am Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Most current stable isotope-based methodologies are targeted and focus only on the well-described aspects of metabolic networks.
	Here, we present NTFD (non-targeted tracer fate detection), a software for the non-targeted analysis of all detectable compounds derived from a stable isotope-labeled tracer present in a GC/MS dataset.
	In contrast to traditional metabolic flux analysis approaches, NTFD does not depend on any a priori knowledge or library information.
	To obtain dynamic information on metabolic pathway activity, NTFD determines mass isotopomer distributions for all detected and labeled compounds.
	These data provide information on relative fluxes in a metabolic network.
	The graphical user interface allows users to import GC/MS data in netCDF format and export all information into a tab-separated format.
	Availability: NTFD is CÃ¾Ã¾- and Qt4-based, and it is freely available under an open-source license.
	Pre-compiled packages for the installation on Debian- and Redhat-based Linux distributions, as well as Windows operating systems, along with example data, are provided for download at http://ntfd.mit.edu/.Contact: gregstep@mit.edu
	We conducted a reanalysis of genome-wide histone H3 tail methylation data in mammalian pluripotent and differentiated cells.
	We show that the promoters marked with histone H3 lysine 27 trimethylation (H3K27me3) tend to have more exonic positions in the promoter regions.
	However, this is not due to any preferential marking on exons over introns by H3K27me3.
	The relationship is also independent the status of histone H3 lysine 4 trimethylation (H3K4me3) mark, CpG content and the platforms used in the highthroughput profiling of histone modifications.
	It provides evidence for the link between histone modifications and transcribed exons in promoter regions.
	Contact: liang.chen@usc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We present easyFRAP, a versatile tool that assists quantitative and qualitative analysis of fluorescence recovery after photobleaching (FRAP) data.
	The user can handle simultaneously large data sets of raw data, visualize fluorescence recovery curves, exclude low quality data, perform data normalization, extract quantitative parameters, perform batch analysis and save the resulting data and figures for further use.
	Our tool is implemented as a single-screen Graphical User Interface (GUI) and is highly interactive, as it permits parameterization and visual data quality assessment at various points during the analysis.
	Availability: easyFRAP is free software, available under the General Public License (GPL).
	Executable and source files, supplementary material and sample data sets can be downloaded at: ccl.med.upatras.gr/easyfrap.html.
	Contact: lygerou@med.upatras.gr; rapsoman@upatras.gr Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Bpipe is a simple, dedicated programming language for defining and executing bioinformatics pipelines.
	It specializes in enabling users to turn existing pipelines based on shell scripts or command line tools into highly flexible, adaptable and maintainable workflows with a minimum of effort.
	Bpipe ensures that pipelines execute in a controlled and repeatable fashion and keeps audit trails and logs to ensure that experimental results are reproducible.
	Requiring only Java as a dependency, Bpipe is fully self-contained and cross-platform, making it very easy to adopt and deploy into existing environments.
	Availability and implementation: Bpipe is freely available from http://bpipe.org under a BSD License.Contact: simon.sadedin@mcri.edu.au Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Here, we describe a tool suite that functions on all of the commonly known FASTQ format variants and provides a pipeline for manipulating next generation sequencing data taken from a sequencing machine all the way through the quality filtering steps.
	Availability and Implementation: This open-source toolset was implemented in Python and has been integrated into the online data analysis platform Galaxy (public web access: http://usegalaxy.org; download: http://getgalaxy.org).
	Two short movies that highlight the functionality of tools described in this manuscript as well as results from testing components of this tool suite against a set of previously published files are available at http://usegalaxy.org/u/dan/p/fastq Contact: james.taylor@emory.edu; anton@bx.psu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: High-throughput sequencing (HTS) technologies are transforming the study of genomic variation.
	The various HTS technologies have different sequencing biases and error rates, and while most HTS technologies sequence the residues of the genome directly, generating base calls for each position, the Applied Biosystem's SOLiD platform generates dibase-coded (color space) sequences.
	While combining data from the various platforms should increase the accuracy of variation detection, to date there are only a few tools that can identify variants from color space data, and none that can analyze color space and regular (letter space) data together.
	Results: We present VARiD-a probabilistic method for variation detection from both letter- and color-space reads simultaneously.
	VARiD is based on a hidden Markov model and uses the forward-backward algorithm to accurately identify heterozygous, homozygous and tri-allelic SNPs, as well as micro-indels.
	Our analysis shows that VARiD performs better than the AB SOLiD toolset at detecting variants from color-space data alone, and improves the calls dramatically when letter- and color-space reads are combined.
	Availability: The toolset is freely available at http://compbio.cs.utoronto.ca/varid Contact: varid@cs.toronto.edu
	Summary: The CluePedia Cytoscape plugin is a search tool for new markers potentially associated to pathways.
	CluePedia calculates linear and non-linear statistical dependencies from experimental data.
	Genes, proteins and miRNAs can be connected based on in silico and/or experimental information and integrated into a ClueGO network of terms/pathways.
	Interrelations within each pathway can be investigated, and new potential associations may be revealed through gene/protein/miRNA enrichments.
	A pathway-like visualization can be created using the Cerebral plugin layout.
	Combining all these features is essential for data interpretation and the generation of new hypotheses.
	The CluePedia Cytoscape plugin is user-friendly and has an expressive and intuitive visualization.
	Availability: http://www.ici.upmc.fr/cluepedia/ and via the Cytoscape plugin manager.
	The user manual is available at the CluePedia website.
	Contact: bernhard.mlecnik@crc.jussieu.fr or jerome.galon@crc.juss ieu.fr Supplementary information: Supplementary data are available at Bioinformatics online.
	We introduce BAR-PLUS (BAR+), a web server for functional and structural annotation of protein sequences.
	BAR+ is based on a large-scale genome cross comparison and a non-hierarchical clustering procedure characterized by a metric that ensures a reliable transfer of features within clusters.
	In this version, the method takes advantage of a largescale pairwise sequence comparison of 13 495 736 protein chains also including 988 complete proteomes.
	Available sequence annotation is derived from UniProtKB, GO, Pfam and PDB.
	When PDB templates are present within a cluster (with or without their SCOP classification), profile Hidden Markov Models (HMMs) are computed on the basis of sequence to structure alignment and are cluster-associated (Cluster-HMM).
	Therefrom, a library of 10 858 HMMs is made available for aligning even distantly related sequences for structural modelling.
	The server also provides pairwise query sequence-structural target alignments computed from the correspondent Cluster-HMM.
	BAR+ in its present version allows three main categories of annotation: PDB [with or without SCOP (*)] and GO and/or Pfam; PDB (*) without GO and/or Pfam; GO and/or Pfam without PDB (*) and no annotation.
	Each category can further comprise clusters where GO and Pfam functional annotations are or are not statistically significant.
	BAR+ is available at http://bar.biocomp.unibo.it/bar2.0.
	RepeatsDB (http://repeatsdb.bio.unipd.it/) is a database of annotated tandem repeat protein structures.
	Tandem repeats pose a difficult problem for the analysis of protein structures, as the underlying sequence can be highly degenerate.
	Several repeat types haven been studied over the years, but their annotation was done in a case-by-case basis, thus making large-scale analysis difficult.
	We developed RepeatsDB to fill this gap.
	Using state-of-the-art repeat detection methods and manual curation, we systematically annotated the Protein Data Bank, predicting 10 745 repeat structures.
	In all, 2797 structures were classified according to a recently proposed classification schema, which was expanded to accommodate new findings.
	In addition, detailed annotations were performed in a subset of 321 proteins.
	These annotations feature information on start and end positions for the repeat regions and units.
	RepeatsDB is an ongoing effort to systematically classify and annotate structural protein repeats in a consistent way.
	It provides users with the possibility to access and download high-quality datasets either interactively or programmatically through web services.
	Motivation: There is a need for effective automated methods for profiling dynamic cell-cell interactions with single-cell resolution from high-throughput time-lapse imaging data, especially, the interactions between immune effector cells and tumor cells in adoptive immunotherapy.
	Results: Fluorescently labeled human T cells, natural killer cells (NK), and various target cells (NALM6, K562, EL4) were co-incubated on polydimethylsiloxane arrays of sub-nanoliter wells (nanowells), and imaged using multi-channel time-lapse microscopy.
	The proposed cell segmentation and tracking algorithms account for cell variability and exploit the nanowell confinement property to increase the yield of correctly analyzed nanowells from 45% (existing algorithms) to 98% for wells containing one effector and a single target, enabling automated quantification of cell locations, morphologies, movements, interactions, and deaths without the need for manual proofreading.
	Automated analysis of recordings from 12 different experiments demonstrated automated nanowell delineation accuracy >99%, automated cell segmentation accuracy >95%, and automated cell tracking accuracy of 90%, with default parameters, despite variations in illumination, staining, imaging noise, cell morphology, and cell clustering.
	An example analysis revealed that NK cells efficiently discriminate between live and dead targets by altering the duration of conjugation.
	The data also demonstrated that cytotoxic cells display higher motility than non-killers, both before and during contact.
	Contact: broysam@central.uh.edu or nvaradar@central.uh.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Genome-wide pervasive transcription is widespread in eukaryotes, revealing an extensive array of antisense transcription that involves hundreds of previously unknown non-coding RNAs.
	Individual cases have shown that antisense transcription influences sense transcription, however, genome-wide mechanisms of how antisense transcription regulates sense transcription remain to be elucidated.
	Results: Here, we performed a systematic analysis of sense-antisense transcription and nucleosome occupancy in yeast.
	We found that antisense transcription is associated with nucleosome occupancy in sense promoters.
	Using RNA polymerase II inactivation data as a reasonable approximation to antisense transcription inactivation data, we further showed that antisense transcripts increase nucleosome occupancy in sense promoter regions they overlap, and reduce nucleosome occupancy in sense promoter regions around their transcription termination sites.
	These results reveal the previously unappreciated roles of antisense transcription in directing nucleosome occupancy in sense promoters.
	Our findings will have implications in understanding regulatory functions of antisense transcription.
	Contact: zhimdai@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Detecting single-nucleotide polymorphism (SNP) in pooled sequencing data is more challenging than in individual sequencing because of sampling variations across pools.
	To effectively differentiate SNP signal from sequencing error, appropriate estimation of the sequencing error is necessary.
	In this article, we propose an empirical Bayes mixture (EBM) model for SNP detection and allele frequency estimation in pooled sequencing data.
	Results: The proposed model reliably learns the error distribution by pooling information across pools and genomic positions.
	In addition, the proposed EBM model builds in characteristics unique to the pooled sequencing data, boosting the sensitivity of SNP detection.
	For large-scale inference in SNP detection, the EBM model provides a flexible and robust way for estimation and control of local false discovery rate.
	We demonstrate the performance of the proposed method through simulation studies and real data application.
	Availability: Implementation of this method is available at https://sites .google.com/site/zhouby98 Contact: baiyu.zhou@einstein.yu.edu The Author 2012.
	Published by Oxford University Press.
	All rights reserved.
	For Permissions, please e-mail: journals.permissions@oup.com
	Motivation: In modern sequencing studies, one can improve the confidence of genotype calls by phasing haplotypes using information from an external reference panel of fully typed unrelated individuals.
	However, the computational demands are so high that they prohibit researchers with limited computational resources from haplotyping large-scale sequence data.
	Results: Our graphics processing unit based software delivers haplotyping and imputation accuracies comparable to competing programs at a fraction of the computational cost and peak memory demand.
	Availability: Mendel-GPU, our OpenCL software, runs on Linux platforms and is portable across AMD and nVidia GPUs.
	Users can download both code and documentation at http://code.google.com/p/mendel-gpu/.
	Contact: gary.k.chen@usc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: WebProtege is an open-source Web application for editing OWL 2 ontologies.
	It contains several features to aid collaboration, including support for the discussion of issues, change notification and revision-based change tracking.
	WebProtege also features a simple user interface, which is geared towards editing the kinds of class descriptions and annotations that are prevalent throughout biomedical ontologies.
	Moreover, it is possible to configure the user interface using views that are optimized for editing Open Biomedical Ontology (OBO) class descriptions and metadata.
	Some of these views are shown in the Supplementary Material and can be seen in WebProtege itself by configuring the project as an OBO project.
	Availability and implementation: WebProtege is freely available for use on the Web at http://webprotege.stanford.edu.
	It is implemented in Java and JavaScript using the OWL API and the Google Web Toolkit.
	All major browsers are supported.
	For users who do not wish to host their ontologies on the Stanford servers, WebProtege is available as a Web app that can be run locally using a Servlet container such as Tomcat.
	Binaries, source code and documentation are available under an open-source license at http://protegewiki.stanford.edu/wiki/WebProtege.
	Contact: matthew.horridge@stanford.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	MobiDB (http://mobidb.bio.unipd.it/) is a database of intrinsically disordered and mobile proteins.
	Intrinsically disordered regions are key for the function of numerous proteins.
	Here we provide a new version of MobiDB, a centralized source aimed at providing the most complete picture on different flavors of disorder in protein structures covering all UniProt sequences (currently over 80 million).
	The database features three levels of annotation: manually curated, indirect and predicted.
	Manually curated data is extracted from the DisProt database.
	Indirect data is inferred from PDB structures that are considered an indication of intrinsic disorder.
	The 10 predictors currently included (three ESpritz flavors, two IUPred flavors, two DisEMBL flavors, GlobPlot, VSL2b and JRONN) enable MobiDB to provide disorder annotations for every protein in absence of more reliable data.
	The new version also features a consensus annotation and classification for long disordered regions.
	In order to complement the disorder annotations, MobiDB features additional annotations from external sources.
	Annotations from the UniProt database include post-translational modifications and linear motifs.
	Pfam annotations are displayed in graphical form and are link-enabled, allowing the user to visit the corresponding Pfam page for further information.
	Experimental protein-protein interactions from STRING are also classified for disorder content.
	Summary: The biomedical literature is a knowledge-rich resource and an important foundation for future research.
	With over 24 million articles in PubMed and an increasing growth rate, research in automated text processing is becoming increasingly important.
	We report here our recently developed web-based text mining services for biomedical concept recognition and normalization.
	Unlike most text-mining software tools, our web services integrate several state-of-the-art entity tagging systems (DNorm, GNormPlus, SR4GN, tmChem and tmVar) and offer a batch-processing mode able to process arbitrary text input (e.g.
	scholarly publications, patents and medical records) in multiple formats (e.g.
	BioC).
	We support multiple standards to make our service interoperable and allow simpler integration with other text-processing pipelines.
	To maximize scalability, we have preprocessed all PubMed articles, and use a computer cluster for processing large requests of arbitrary text.
	Availability and implementation: Our text-mining web service is freely available at http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/tmTools/#curl Contact: Zhiyong.Lu@nih.gov
	Motivation: Paired-end sequencing allows circumventing the shortness of the reads produced by second generation sequencers and is essential for de novo assembly of genomes.
	However, obtaining a finished genome from short reads is still an open challenge.
	We present an algorithm that exploits the pairing information issued from inserts of potentially any length.
	The method determines paths through an overlaps graph by using a constrained search tree.
	We also present a method that automatically determines suited overlaps cutoffs according to the contextual coverage, reducing thus the need for manual parameterization.
	Finally, we introduce an interactive mode that allows querying an assembly at targeted regions.
	Results: We assess our methods by assembling two Staphylococcus aureus strains that were sequenced on the Illumina platform.
	Using 100 bp paired-end reads and minimal manual curation, we produce a finished genome sequence for the previously undescribed isolate SGH-10-168.
	Availability and implementation: The presented algorithms are implemented in the standalone Edena software, freely available under the General Public License (GPLv3) at www.genomic.ch/edena.php.
	Contact: david.hernandez@genomic.ch Supplementary Information: Supplementary data are available at Bioinformatics online.
	Summary: Assessing and improving the safety of chemicals and the efficacy of drugs depends on an understanding of the biodistribution, clearance and biological effects of the chemical(s) of interest.
	A promising methodology for the prediction of these phenomena is physiologically based pharmacokinetic/pharmacodynamic modeling, which centers on the prediction of chemical absorption, distribution, metabolism and excretion (pharmacokinetics) and the biological effects (pharmacodynamics) of the chemical on the organism.
	Strengths of this methodology include modeling across multiple scales of biological organization and facilitate the extrapolation of results across routes of exposure, dosing levels and species.
	It is also useful as the foundation for tools to (i) predict biomarker levels (concentrations of chemical species found in the body that indicate exposure to a foreign chemical), given a chemical dose or exposure; (ii) reconstruct a dose, given the levels of relevant biomarkers; and (iii) estimate population variability.
	Despite the importance and promise of physiologically based pharmacokinetic /pharmacodynamics-based approaches to forward and reverse dosimetry, there is currently a lack of user-friendly, freely available implementations that are accessible and useful to a broad range of users.
	DoseSim was developed to begin to fill this gap.
	Availability: The application is available under the GNU General Public License from http://scb.colostate.edu/dosesim.html.Contact: brad.reisfeld@colostate.edu
	Motivation: We investigate the problem of exact repeat detection on large genomic sequences.
	Most existing approaches based on suffix trees and suffix arrays (SAs) are limited either to small sequences or those that are memory resident.
	We introduce RepMaestro, a software that adapts existing in-memory-enhanced SA algorithms to enable them to scale efficiently to large sequences that are disk resident.
	Supermaximal repeats, maximal unique matches (MuMs) and pairwise branching tandem repeats have been used to demonstrate the practicality of our approach; the first such study to use an enhanced SA to detect these repeats in large genome sequences.
	Results: The detection of supermaximal repeats was observed to be up to two times faster than Vmatch, but more importantly, was shown to scale efficiently to large genome sequences that Vmatch could not process due to memory constraints (4 GB).
	Similar results were observed for the detection of MuMs, with RepMaestro shown to scale well and also perform up to six times faster than Vmatch.
	For tandem repeats, RepMaestro was found to be slower but could nonetheless scale to large disk-resident sequences.
	These results are a significant advance in the quest of scalable repeat detection.
	Software availability: RepMaestro is available at http://www.naskitis.com Contact: askitisn@gmail.com; sinhar@unimelb.edu.au Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: The new version of the TRITON program provides userfriendly graphical tools for modeling protein mutants using the external program MODELLER and for docking ligands into the mutants using the external program AutoDock.
	TRITON can now be used to design ligand-binding proteins, to study protein-ligand binding mechanisms or simply to dock any ligand to a protein.
	Availability: Executable files of TRITON are available free of charge for academic users at http://ncbr.chemi.muni.cz/triton/Contact: triton@chemi.muni.cz Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Animal models are important tools in drug discovery and for understanding human biology in general.
	However, many drugs that initially show promising results in rodents fail in later stages of clinical trials.
	Understanding the commonalities and differences between human and rat cell signaling networks can lead to better experimental designs, improved allocation of resources and ultimately better drugs.
	Results: The sbv IMPROVER Species-Specific Network Inference challenge was designed to use the power of the crowds to build two species-specific cell signaling networks given phosphoproteomics, transcriptomics and cytokine data generated from NHBE and NRBE cells exposed to various stimuli.
	A common literature-inspired reference network with 220 nodes and 501 edges was also provided as prior knowledge from which challenge participants could add or remove edges but not nodes.
	Such a large network inference challenge not based on synthetic simulations but on real data presented unique difficulties in scoring and interpreting the results.
	Because any prior knowledge about the networks was already provided to the participants for reference, novel ways for scoring and aggregating the results were developed.
	Two human and rat consensus networks were obtained by combining all the inferred networks.
	Further analysis showed that major signaling pathways were conserved between the two species with only isolated components diverging, as in the case of ribosomal S6 kinase RPS6KA1.
	Overall, the consensus between inferred edges was relatively high with the exception of the downstream targets of transcription factors, which seemed more difficult to predict.
	Contact: ebilal@us.ibm.com or gustavo@us.ibm.com.
	Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Network-level visualization of functional data is a key aspect of both analysis and understanding of biological systems.
	In a continuing effort to create clear and integrated visualizations that facilitate the gathering of novel biological insights despite the overwhelming complexity of data, we present here the GrAph LANdscape VisualizaTion (GALANT), a Cytoscape plugin that builds functional landscapes onto biological networks.
	By using GALANT, it is possible to project any type of numerical data onto a network to create a smoothed data map resembling the network layout.
	As a Cytoscape plugin, GALANT is further improved by the functionalities of Cytoscape, the popular bioinformatics package for biological network visualization and data integration.
	Availability: http://www.lbbc.ibb.unesp.br/galant.Contact: esther@ibb.unesp.br Supplementary Information: Supplementary data are available at Bioinformatics online.
	Summary: SPARKY (Goddard and Kneller, SPARKY 3) remains the most popular software program for NMR data analysis, despite the fact that development of the package by its originators ceased in 2001.
	We have taken over the development of this package and describe NMRFAM-SPARKY, which implements new functions reflecting advances in the biomolecular NMR field.
	NMRFAMSPARKY has been repackaged with current versions of Python and Tcl/Tk, which support new tools for NMR peak simulation and graphical assignment determination.
	These tools, along with chemical shift predictions from the PACSY database, greatly accelerate protein side chain assignments.
	NMRFAM-SPARKY supports automated data format interconversion for interfacing with a variety of web servers including, PECAN , PINE, TALOS-N, CS-Rosetta, SHIFTX2 and PONDEROSA-C/S.
	Availability and implementation: The software package, along with binary and source codes, if desired, can be downloaded freely from http://pine.nmrfam.wisc.edu/download_packages.html.Instruction manuals and video tutorials can be found at http://www.nmrfam.wisc.edu/nmrfamsparky-distribution.htm.
	Contact: whlee@nmrfam.wisc.edu or markley@nmrfam.wisc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Unipro UGENE is a multiplatform open-source software with the main goal of assisting molecular biologists without much expertise in bioinformatics to manage, analyze and visualize their data.
	UGENE integrates widely used bioinformatics tools within a common user interface.
	The toolkit supports multiple biological data formats and allows the retrieval of data from remote data sources.
	It provides visualization modules for biological objects such as annotated genome sequences, Next Generation Sequencing (NGS) assembly data, multiple sequence alignments, phylogenetic trees and 3D structures.
	Most of the integrated algorithms are tuned for maximum performance by the usage of multithreading and special processor instructions.
	UGENE includes a visual environment for creating reusable workflows that can be launched on local resources or in a High Performance Computing (HPC) environment.
	UGENE is written in C++ using the Qt framework.
	The built-in plugin system and structured UGENE API make it possible to extend the toolkit with new functionality.
	Availability and implementation: UGENE binaries are freely available for MS Windows, Linux and Mac OS X at http://ugene.unipro.ru/download.html.
	UGENE code is licensed under the GPLv2; the information about the code licensing and copyright of integrated tools can be found in the LICENSE.3rd_party file provided with the source bundle.
	Contact: ugene@unipro.ru Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Networks are vital to computational systems biology research, but visualizing them is a challenge.
	For networks larger than 100 nodes and 200 links, ball-and-stick diagrams fail to convey much information.
	To address this, we developed Network2Canvas (N2C), a web application that provides an alternative way to view networks.
	N2C visualizes networks by placing nodes on a square toroidal canvas.
	The network nodes are clustered on the canvas using simulated annealing to maximize local connections where a node's brightness is made proportional to its local fitness.
	The interactive canvas is implemented in HyperText Markup Language (HTML)5 with the JavaScript library Data-Driven Documents (D3).
	We applied N2C to visualize 30 canvases made from human and mouse gene-set libraries and 6 canvases made from the Food and Drug Administration (FDA)approved drug-set libraries.
	Given lists of genes or drugs, enriched terms are highlighted on the canvases, and their degree of clustering is computed.
	Because N2C produces visual patterns of enriched terms on canvases, a trained eye can detect signatures instantly.
	In summary, N2C provides a new flexible method to visualize large networks and can be used to perform and visualize gene-set and drug-set enrichment analyses.
	Availability: N2C is freely available at http://www.maayanlab.net/N2C and is open source.
	Contact: avi.maayan@mssm.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	The IRESite (http://www.iresite.org) presents carefully curated experimental evidence of many eukaryotic viral and cellular internal ribosome entry site (IRES) regions.
	At the time of submission, IRESite stored `600 records.
	The IRESite gradually evolved into a robust tool providing (i) biologically meaningful information regarding the IRESs and their experimental background (including annotation of IRES secondary structures and IRES transacting factors) as well as (ii) thorough concluding remarks to stored database entries and regularly updated evaluation of the reported IRES function.
	A substantial portion of the IRESite data results purely from in-house bioinformatic analyses of currently available sequences, in silico attempts to repeat published cloning experiments, DNA sequencing and restriction endonuclease verification of received plasmid DNA.
	We also present a newly implemented tool for displaying RNA secondary structures and for searching through the structures currently stored in the database.
	The supplementary material contains an updated list of reported IRESs.
	The International Society for Computational Biology (ISCB; http://www.iscb.org) honors a scientist each year for their outstanding achievements.
	The ISCB Overton Prize honors an early or mid-career scientist who has already made significant and enduring contributions to the field of computational biology.
	Dr Goncalo Abecasis of the University of Michigan is the 2013 recipient of the Overton Prize.
	Dr Abecasis was selected the by ISCB's awards committee, which is chaired by Dr Alfonso Valencia of the Spanish National Cancer Research Center (CNIO) in Madrid.
	Dr Abecasis will receive his award and deliver keynote address at the ISCB's 21st annual Intelligent Systems for Molecular Biology (ISMB) meeting.
	This meeting is being held jointly with the 12th European Conference on Computational Biology and will take place in Berlin, Germany on July 21-23, 2013 (http://www.iscb.org/ismbeccb2013).
	Motivation: Spatial learning is one of the most widely studied cognitive domains in neuroscience.
	The Morris water maze and the Barnes maze are the most commonly used techniques to assess spatial learning and memory in rodents.
	Despite the fact that these tasks are well-validated paradigms for testing spatial learning abilities, manual categorization of performance into behavioral strategies is subject to individual interpretation, and thus to bias.
	We have previously described an unbiased machine-learning algorithm to classify spatial strategies in the Morris water maze.
	Results: Here, we offer a support vector machine-based, automated, Barnes-maze unbiased strategy (BUNS) classification algorithm, as well as a cognitive score scale that can be used for memory acquisition, reversal training and probe trials.
	The BUNS algorithm can greatly benefit Barnes maze users as it provides a standardized method of strategy classification and cognitive scoring scale, which cannot be derived from typical Barnes maze data analysis.
	Availability and Implementation: Freely available on the web at http://okunlab.wix.com/okunlab as a MATLAB application.
	Contact: eitan.okun@biu.ac.il Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: RIP-chip is a high-throughput method to identify mRNAs that are targeted by RNA-binding proteins.
	The protein of interest is immunoprecipitated, and the identity and relative amount of mRNA associated with it is measured on microarrays.
	Even if a variety of methods is available to analyse microarray data, e.g.
	to detect differentially regulated genes, the additional experimental steps in RIP-chip require specialized methods.
	Here, we focus on two aspects of RIP-chip data: First, the efficiency of the immunoprecipitation step performed in the RIP-chip protocol varies in between different experiments introducing bias not existing in standard microarray experiments.
	This requires an additional normalization step to compare different samples and even technical replicates.
	Second, in contrast to standard differential gene expression experiments, the distribution of measurements is not normal.
	We exploit this fact to define a set of biologically relevant genes in a statistically meaningful way.
	Results: Here, we propose two methods to analyse RIP-chip data: We model the measurement distribution as a gaussian mixture distribution, which allows us to compute false discovery rates (FDRs) for any cut-off.
	Thus, cut-offs can be chosen for any desired FDR.
	Furthermore, we use principal component analysis to determine the normalization factors necessary to remove immunoprecipitation bias.
	Both methods are evaluated on a large RIP-chip dataset measuring targets of Ago2, the major component of the microRNA guided RNA-induced silencing complex (RISC).
	Using published HITS-CLIP experiments performed with the same cell line as used for RIP-chip, we show that the mixture modelling approach is a necessary step to remove background, which computed FDRs are valid, and that the additional normalization is a necessary step to make experiments comparable.
	Availability: An R implementation of REA is available on the project website (http://www.bio.ifi.lmu.de/REA) and as supplementary data file.
	Contact: florian.erhard@bio.ifi.lmu.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Prediction of interactions between protein residues (contact map prediction) can facilitate various aspects of 3D structure modeling.
	However, the accuracy of ab initio contact prediction is still limited.
	As structural genomics initiatives move ahead, solved structures of homologous proteins can be used as multiple templates to improve contact prediction of the major conformation of an unsolved target protein.
	Furthermore, multiple templates may provide a wider view of the protein's conformational space.
	However, successful usage of multiple structural templates is not straightforward, due to their variable relevance to the target protein, and because of data redundancy issues.
	Results: We present here an algorithm that addresses these two limitations in the use of multiple structure templates.
	First, the algorithm unites contact maps extracted from templates sharing high sequence similarity with each other in a fashion that acknowledges the possibility of multiple conformations.
	Next, it weights the resulting united maps in inverse proportion to their evolutionary distance from the target protein.
	Testing this algorithm against CASP8 targets resulted in high precision contact maps.
	Remarkably, based solely on structural data of remote homologues, our algorithm identified residue-residue interactions that account for all the known conformations of calmodulin, a multifaceted protein.
	Therefore, employing multiple templates, which improves prediction of contact maps, can also be used to reveal novel conformations.
	As multiple templates will soon be available for most proteins, our scheme suggests an effective procedure for their optimal consideration.
	Availability: A Perl script implementing the WMC algorithm described in this article is freely available for academic use at http://tau.ac.il/~haimash/WMC.Contact: kliger@compugen.co.il Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: RNA family models group nucleotide sequences that share a common biological function.
	These models can be used to find new sequences belonging to the same family.
	To succeed in this task, a model needs to exhibit high sensitivity as well as high specificity.
	As model construction is guided by a manual process, a number of problems can occur, such as the introduction of more than one model for the same family or poorly constructed models.
	We explore the Rfam database to discover such problems.
	Results: Our main contribution is in the definition of the discriminatory power of RNA family models, together with a first algorithm for its computation.
	In addition, we present calculations across the whole Rfam database that show several families lacking high specificity when compared to other families.
	We give a list of these clusters of families and provide a tentative explanation.
	Our program can be used to: (i) make sure that new models are not equivalent to any model already present in the database; and (ii) new models are not simply submodels of existing families.
	Availability: www.tbi.univie.ac.at/software/cmcompare/.
	The code is licensed under the GPLv3.
	Results for the whole Rfam database and supporting scripts are available together with the software.
	Contact: choener@tbi.univie.ac.at
	Motivation: Recent advances in technology have dramatically increased the availability of protein-protein interaction (PPI) data and stimulated the development of many methods for improving the systems level understanding the cell.
	However, those efforts have been significantly hindered by the high level of noise, sparseness and highly skewed degree distribution of PPI networks.
	Here, we present a novel algorithm to reduce the noise present in PPI networks.
	The key idea of our algorithm is that two proteins sharing some higher-order topological similarities, measured by a novel random walk-based procedure, are likely interacting with each other and may belong to the same protein complex.
	Results: Applying our algorithm to a yeast PPI network, we found that the edges in the reconstructed network have higher biological relevance than in the original network, assessed by multiple types of information, including gene ontology, gene expression, essentiality, conservation between species and known protein complexes.
	Comparison with existing methods shows that the network reconstructed by our method has the highest quality.
	Using two independent graph clustering algorithms, we found that the reconstructed network has resulted in significantly improved prediction accuracy of protein complexes.
	Furthermore, our method is applicable to PPI networks obtained with different experimental systems, such as affinity purification, yeast two-hybrid (Y2H) and protein-fragment complementation assay (PCA), and evidence shows that the predicted edges are likely bona fide physical interactions.
	Finally, an application to a human PPI network increased the coverage of the network by at least 100%.
	Availability: www.cs.utsa.edu/ jruan/RWS/.
	Contact: Jianhua.Ruan@utsa.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: In chromatin immunoprecipitation followed by highthroughput sequencing (ChIP-seq) and other short-read sequencing experiments, a considerable fraction of the short reads align to multiple locations on the reference genome (multi-reads).
	Inferring the origin of multi-reads is critical for accurately mapping reads to repetitive regions.
	Current state-of-the-art multi-read allocation algorithms rely on the read counts in the local neighborhood of the alignment locations and ignore the variation in the copy numbers of these regions.
	Copy-number variation (CNV) can directly affect the read densities and, therefore, bias allocation of multi-reads.
	Results: We propose cnvCSEM (CNV-guided ChIP-Seq by expectation-maximization algorithm), a flexible framework that incorporates CNV in multi-read allocation.
	cnvCSEM eliminates the CNV bias in multi-read allocation by initializing the read allocation algorithm with CNV-aware initial values.
	Our data-driven simulations illustrate that cnvCSEM leads to higher read coverage with satisfactory accuracy and lower loss in read-depth recovery (estimation).
	We evaluate the biological relevance of the cnvCSEM-allocated reads and the resultant peaks with the analysis of several ENCODE ChIPseq datasets.
	Availability and implementation: Available at http://www.stat.wisc.edu/ qizhang/ Contact: qizhang@stat.wisc.edu or keles@stat.wisc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Comparing transcriptomic data with proteomic data to identify protein-coding sequences is a long-standing challenge in molecular biology, one that is exacerbated by the increasing size of high-throughput datasets.
	To address this challenge, and thereby to improve the quality of genome annotation and understanding of genome biology, we have developed an integrated suite of programs, called Pinstripe.
	We demonstrate its application, utility and discovery power using transcriptomic and proteomic data from publicly available datasets.
	Results: To demonstrate the efficacy of Pinstripe for large-scale analysis, we applied Pinstripe's reverse peptide mapping pipeline to a transcript library including de novo assembled transcriptomes from the human Illumina Body Atlas (IBA2) and GENCODE v10 gene annotations, and the EBI Proteomics Identifications Database (PRIDE) peptide database.
	This analysis identified 736 canonical open reading frames (ORFs) supported by three or more PRIDE peptide fragments that are positioned outside any known coding DNA sequence (CDS).
	Because of the unfiltered nature of the PRIDE database and high probability of false discovery, we further refined this list using independent evidence for translation, including the presence of a Kozak sequence or functional domains, synonymous/non-synonymous substitution ratios and ORF length.
	Using this integrative approach, we observed evidence of translation from a previously unknown let7e primary transcript, the archetypical lncRNA H19, and a homolog of RD3.
	Reciprocally, by exclusion of transcripts with mapped peptides or significant ORFs (480 codon), we identify 32 187 loci with RNAs longer than 2000 nt that are unlikely to encode proteins.
	Availability and implementation: Pinstripe (pinstripe.matticklab.com) is freely available as source code or a Mono binary.
	Pinstripe is written in C# and runs under the Mono framework on Linux or Mac OS X, and both under Mono and .Net under Windows.
	Summary: We propose a three-step periodicity detection algorithm named LSPR.
	Our method first preprocesses the raw time-series by removing the linear trend and filtering noise.
	In the second step, LSPR employs a Lomb-Scargle periodogram to estimate the periodicity in the time-series.
	Finally, harmonic regression is applied to model the cyclic components.
	Inferred periodic transcripts are selected by a false discovery rate procedure.
	We have applied LSPR to unevenly sampled synthetic data and two Arabidopsis diurnal expression datasets, and compared its performance with the existing well-established algorithms.
	Results show that LSPR is capable of identifying periodic transcripts more accurately than existing algorithms.
	Availability: LSPR algorithm is implemented as MATLAB software and is available at http://bioinformatics.cau.edu.cn/LSPR Contact: zhensu@cau.edu.cn Supplementary information: Supplementary data are available at Bioinformatics online.
	Phospho3D is a database of three-dimensional (3D) structures of phosphorylation sites (P-sites) derived from the Phospho.ELM database, which also collects information on the residues surrounding the P-site in space (3D zones).
	The database also provides the results of a large-scale structural comparison of the 3D zones versus a representative dataset of structures, thus associating to each P-site a number of structurally similar sites.
	The new version of Phospho3D presents an 11-fold increase in the number of 3D sites and incorporates several additional features, including new structural descriptors, the possibility of selecting nonredundant sets of 3D structures and the availability for download of non-redundant sets of structurally annotated P-sites.
	Moreover, it features P3Dscan, a new functionality that allows the user to submit a protein structure and scan it against the 3D zones collected in the Phospho3D database.
	Phospho3D version 2.0 is available at: http://www.phospho3d .org/.
	Motivation: Protein sequence and structure representation and manipulation require dedicated software libraries to support methods of increasing complexity.
	Here, we describe the VIrtual Constrution TOol for pRoteins (Victor) CÃ¾Ã¾ library, an open source platform dedicated to enabling inexperienced users to develop advanced tools and gathering contributions from the community.
	The provided application examples cover statistical energy potentials, profile-profile sequence alignments and ab initio loop modeling.
	Victor was used over the last 15 years in several publications and optimized for efficiency.
	It is provided as a GitHub repository with source files and unit tests, plus extensive online documentation, including a Wiki with help files and tutorials, examples and Doxygen documentation.
	Availability and implementation: The CÃ¾Ã¾ library and online documentation, distributed under a GPL license are available from URL: http://protein.bio.unipd.it/victor/.Contact: silvio.tosatto@unipd.it
	Motivation: Molecular recognition features (MoRFs) are short binding regions located within longer intrinsically disordered regions that bind to protein partners via disorder-to-order transitions.
	MoRFs are implicated in important processes including signaling and regulation.
	However, only a limited number of experimentally validated MoRFs is known, which motivates development of computational methods that predict MoRFs from protein chains.
	Results: We introduce a new MoRF predictor, MoRFpred, which identifies all MoRF types (Î±, Î², coil and complex).
	We develop a comprehensive dataset of annotated MoRFs to build and empirically compare our method.
	MoRFpred utilizes a novel design in which annotations generated by sequence alignment are fused with predictions generated by a Support Vector Machine (SVM), which uses a custom designed set of sequence-derived features.
	The features provide information about evolutionary profiles, selected physiochemical properties of amino acids, and predicted disorder, solvent accessibility and B-factors.
	Empirical evaluation on several datasets shows that MoRFpred outperforms related methods: Î±-MoRF-Pred that predicts Î±-MoRFs and ANCHOR which finds disordered regions that become ordered when bound to a globular partner.
	We show that our predicted (new) MoRF regions have non-random sequence similarity with native MoRFs.
	We use this observation along with the fact that predictions with higher probability are more accurate to identify putative MoRF regions.
	We also identify a few sequence-derived hallmarks of MoRFs.
	They are characterized by dips in the disorder predictions and higher hydrophobicity and stability when compared to adjacent (in the chain) residues.
	Availability: http://biomine.ece.ualberta.ca/MoRFpred/; http://biomine.ece.ualberta.ca/MoRFpred/Supplement.pdf Contact: lkurgan@ece.ualberta.ca Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Here we introduce ccSOL omics, a webserver for largescale calculations of protein solubility.
	Our method allows (i) proteome-wide predictions; (ii) identification of soluble fragments within each sequences; (iii) exhaustive single-point mutation analysis.
	Results: Using coil/disorder, hydrophobicity, hydrophilicity, -sheet and -helix propensities, we built a predictor of protein solubility.
	Our approach shows an accuracy of 79% on the training set (36 990 Target Track entries).
	Validation on three independent sets indicates that ccSOL omics discriminates soluble and insoluble proteins with an accuracy of 74% on 31 760 proteins sharing 530% sequence similarity.
	Availability and implementation: ccSOL omics can be freely accessed on the web at http://s.tartaglialab.com/page/ccsol_group.Documentation and tutorial are available at http://s.tartaglialab.com/static_files/shared/tutorial_ccsol_omics.html.
	Contact: gian.tartaglia@crg.es Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Information about RNA-protein interactions is a vital pre-requisite to tackle the dissection of RNA regulatory processes.
	Despite the recent advances of the experimental techniques, the currently available RNA interactome involves a small portion of the known RNA binding proteins.
	The importance of determining RNA-protein interactions, coupled with the scarcity of the available information, calls for in silico prediction of such interactions.
	Results: We present RNAcommender, a recommender system capable of suggesting RNA targets to unexplored RNA binding proteins, by propagating the available interaction information taking into account the protein domain composition and the RNA predicted secondary structure.
	Our results show that RNAcommender is able to successfully suggest RNA interactors for RNA binding proteins using little or no interaction evidence.
	RNAcommender was tested on a large dataset of human RBP-RNA interactions, showing a good ranking performance (average AUC ROC of 0.75) and significant enrichment of correct recommendations for 75% of the tested RBPs.
	RNAcommender can be a valid tool to assist researchers in identifying potential interacting candidates for the majority of RBPs with uncharacterized binding preferences.
	Availability and Implementation: The software is freely available at http://rnacommender.disi.unitn.it.
	Contact: gianluca.corrado@unitn.it or andrea.passerini@unitn.it Supplementary information: Supplementary data are available at Bioinformatics online.
	10 The Protein Model Database (PMDB) is a public resource aimed at storing manually built 3D models of proteins.
	The database is designed to provide access to models published in the scientific literature, together with validating experimental data.
	It is a rela15 tional database and it currently contains .74 000 models for 240 proteins.
	The system is accessible at http://www.caspur.it/PMDB and allows predictors to submit models along with related supporting evidence and users to download them through a simple 20 and intuitive interface.
	Users can navigate in the database and retrieve models referring to the same target protein or to different regions of the same protein.
	Each model is assigned a unique identifier that allows interested users to directly access the data.
	Motivation: The Physiome Model Repository 2 (PMR2) software was created as part of the IUPS Physiome Project (Hunter and Borg, 2003), and today it serves as the foundation for the CellML model repository.
	Key advantages brought to the end user by PMR2 include: facilities for model exchange, enhanced collaboration and a detailed change history for each model.
	Availability: PMR2 is available under an open source license at http://www.cellml.org/tools/pmr/; a fully functional instance of this software can be accessed at http://models.physiomeproject.org/.Contact: tommy.yu@auckland.ac.nz
	Motivation: The lack of reliable, comprehensive gold standards complicates the development of many bioinformatics tools, particularly for the analysis of expression data and biological networks.
	Simulation approaches can provide provisional gold standards, such as regulatory networks, for the assessment of network inference methods.
	However, this just defers the problem, as it is difficult to assess how closely simulators emulate the properties of real data.
	Results: In analogy to Turing's test discriminating humans and computers based on responses to questions, we systematically compare real and artificial systems based on their gene expression output.
	Different expression data analysis techniques such as clustering are applied to both types of datasets.
	We define and extract distributions of properties from the results, for instance, distributions of cluster quality measures or transcription factor activity patterns.
	Distributions of properties are represented as histograms to enable the comparison of artificial and real datasets.
	We examine three frequently used simulators that generate expression data from parameterized regulatory networks.
	We identify features distinguishing real from artificial datasets that suggest how simulators could be adapted to better emulate real datasets and, thus, become more suitable for the evaluation of data analysis tools.
	Availability: See http://www2.bio.ifi.lmu.de/ kueffner/attfad/ and the supplement for precomputed analyses; other compendia can be analyzed via the CRAN package attfad.
	The full datasets can be obtained from http://www2.bio.ifi.lmu.de/ kueffner/attfad/data.tar.gz.Contact: robert.kueffner@bio.ifi.lmu.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Identification of expression Quantitative Trait Loci (eQTL), the genetic loci that contribute to heritable variation in gene expression, can be obstructed by factors that produce variation in expression profiles if these factors are unmeasured or hidden from direct analysis.
	Methods: We have developed a method for Hidden Expression Factor analysis (HEFT) that identifies individual and pleiotropic effects of eQTL in the presence of hidden factors.
	The HEFT model is a combined multivariate regression and factor analysis, where the complete likelihood of the model is used to derive a ridge estimator for simultaneous factor learning and detection of eQTL.
	HEFT requires no preestimation of hidden factor effects; it provides P-values and is extremely fast, requiring just a few hours to complete an eQTL analysis of thousands of expression variables when analyzing hundreds of thousands of single nucleotide polymorphisms on a standard 8 core 2.6 G desktop.
	Results: By analyzing simulated data, we demonstrate that HEFT can correct for an unknown number of hidden factors and significantly outperforms all related hidden factor methods for eQTL analysis when there are eQTL with univariate and multivariate (pleiotropic) effects.
	To demonstrate a real-world application, we applied HEFT to identify eQTL affecting gene expression in the human lung for a study that included presumptive hidden factors.
	HEFT identified all of the cis-eQTL found by other hidden factor methods and 91 additional cis-eQTL.
	HEFT also identified a number of eQTLs with direct relevance to lung disease that could not be found without a hidden factor analysis, including cis-eQTL for GTF2H1 and MTRR, genes that have been independently associated with lung cancer.
	Availability: Software is available at http://mezeylab.cb.bscb.cornell.edu/Software.aspx.
	Supplementary information: Supplementary data are available at Bioinformatics online.
	Contact: jgm45@cornell.edu
	Motivation: The application of next-generation sequencing (NGS) technologies to RNAs directly extracted from a community of organisms yields a mixture of fragments characterizing both coding and non-coding types of RNAs.
	The task to distinguish among these and to further categorize the families of messenger RNAs and ribosomal RNAs (rRNAs) is an important step for examining gene expression patterns of an interactive environment and the phylogenetic classification of the constituting species.
	Results: We present SortMeRNA, a new software designed to rapidly filter rRNA fragments from metatranscriptomic data.
	It is capable of handling large sets of reads and sorting out all fragments matching to the rRNA database with high sensitivity and low running time.
	Availability: http://bioinfo.lifl.fr/RNA/sortmerna Contact: evguenia.kopylova@lifl.fr Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Predicting the structure of protein loops is very challenging, mainly because they are not necessarily subject to strong evolutionary pressure.
	This implies that, unlike the rest of the protein, standard homology modeling techniques are not very effective in modeling their structure.
	However, loops are often involved in protein function, hence inferring their structure is important for predicting protein structure as well as function.
	Results: We describe a method, LoopIng, based on the Random Forest automated learning technique, which, given a target loop, selects a structural template for it from a database of loop candidates.
	Compared to the most recently available methods, LoopIng is able to achieve similar accuracy for short loops (4-10 residues) and significant enhancements for long loops (11-20 residues).
	The quality of the predictions is robust to errors that unavoidably affect the stem regions when these are modeled.
	The method returns a confidence score for the predicted template loops and has the advantage of being very fast (on average: 1 min/loop).
	Availability and implementation: www.biocomputing.it/looping Contact: anna.tramontano@uniroma1.it Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Most proteins consist of multiple domains, independent structural and evolutionary units that are often reshuffled in genomic rearrangements to form new protein architectures.
	Template-based modeling methods can often detect homologous templates for individual domains, but templates that could be used to model the entire query protein are often not available.
	Results: We have developed a fast docking algorithm ab initio domain assembly (AIDA) for assembling multi-domain protein structures, guided by the ab initio folding potential.
	This approach can be extended to discontinuous domains (i.e.
	domains with 'inserted' domains).
	When tested on experimentally solved structures of multi-domain proteins, the relative domain positions were accurately found among top 5000 models in 86% of cases.
	AIDA server can use domain assignments provided by the user or predict them from the provided sequence.
	The latter approach is particularly useful for automated protein structure prediction servers.
	The blind test consisting of 95 CASP10 targets shows that domain boundaries could be successfully determined for 97% of targets.
	Availability and implementation: The AIDA package as well as the benchmark sets used here are available for download at http://ffas.burnham.org/AIDA/.Contact: adam@sanfordburnham.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: A new edition of the DelPhi web server, DelPhi web server v2, is released to include atomic presentation of geometrical figures.
	These geometrical objects can be used to model nano-size objects together with real biological macromolecules.
	The position and size of the object can be manipulated by the user in real time until desired results are achieved.
	The server fixes structural defects, adds hydrogen atoms and calculates electrostatic energies and the corresponding electrostatic potential and ionic distributions.
	Availability and implementation: The web server follows a clientserver architecture built on PHP and HTML and utilizes DelPhi software.
	The computation is carried out on supercomputer cluster and results are given back to the user via http protocol, including the ability to visualize the structure and corresponding electrostatic potential via Jmol implementation.
	The DelPhi web server is available from http://compbio.clemson.edu/delphi_webserver.Contact: nsmith@clemson.edu, ealexov@clemson.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Many analyses in modern biological research are based on comparisons between biological sequences, resulting in functional, evolutionary and structural inferences.
	When large numbers of sequences are compared, heuristics are often used resulting in a certain lack of accuracy.
	In order to improve and validate results of such comparisons, we have performed radical all-against-all comparisons of 4 million protein sequences belonging to the RefSeq database, using an implementation of the Smith-Waterman algorithm.
	This extremely intensive computational approach was made possible with the help of World Community Gridâ„¢, through the Genome Comparison Project.
	The resulting database, ProteinWorldDB, which contains coordinates of pairwise protein alignments and their respective scores, is now made available.
	Users can download, compare and analyze the results, filtered by genomes, protein functions or clusters.
	ProteinWorldDB is integrated with annotations derived from Swiss-Prot, Pfam, KEGG, NCBI Taxonomy database and gene ontology.
	The database is a unique and valuable asset, representing a major effort to create a reliable and consistent dataset of cross-comparisons of the whole protein content encoded in hundreds of completely sequenced genomes using a rigorous dynamic programming approach.
	Availability: The database can be accessed through http://proteinworlddb.org Contact: otto@fiocruz.br
	Motivation: In rapidly evolving pathogens, including viruses and some bacteria, genetic change can accumulate over short time-frames.
	Accordingly, their sampling times can be used to calibrate molecular clocks, allowing estimation of evolutionary rates.
	Methods for estimating rates from time-structured data vary in how they treat phylogenetic uncertainty and rate variation among lineages.
	We compiled 81 virus data sets and estimated nucleotide substitution rates using root-to-tip regression, least-squares dating and Bayesian inference.
	Results: Although estimates from these three methods were often congruent, this largely relied on the choice of clock model.
	In particular, relaxed-clock models tended to produce higher rate estimates than methods that assume constant rates.
	Discrepancies in rate estimates were also associated with high among-lineage rate variation, and phylogenetic and temporal clustering.
	These results provide insights into the factors that affect the reliability of rate estimates from timestructured sequence data, emphasizing the importance of clock-model testing.
	Contact: sduchene@unimelb.edu.au or garzonsebastian@hotmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	ChEBI (http://www.ebi.ac.uk/chebi) is a database and ontology of chemical entities of biological interest.
	Over the past few years, ChEBI has continued to grow steadily in content, and has added several new features.
	In addition to incorporating all userrequested compounds, our annotation efforts have emphasized immunology, natural products and metabolites in many species.
	All database entries are now 'is_a' classified within the ontology, meaning that all of the chemicals are available to semantic reasoning tools that harness the classification hierarchy.
	We have completely aligned the ontology with the Open Biomedical Ontologies (OBO) Foundryrecommended upper level Basic Formal Ontology.
	Furthermore, we have aligned our chemical classification with the classification of chemical-involving processes in the Gene Ontology (GO), and as a result of this effort, the majority of chemicalinvolving processes in GO are now defined in terms of the ChEBI entities that participate in them.
	This effort necessitated incorporating many additional biologically relevant compounds.
	We have incorporated additional data types including reference citations, and the species and component for metabolites.
	Finally, our website and web services have had several enhancements, most notably the provision of a dynamic new interactive graph-based ontology visualization.
	Summary: The Mirrortree server allows to graphically and interactively study the co-evolution of two protein families, and investigate their possible interactions and functional relationships in a taxonomic context.
	The server includes the possibility of starting from single sequences and hence it can be used by non-expert users.
	Availability and Implementation: The web server is freely available at http://csbg.cnb.csic.es/mtserver.
	It was tested in the main web browsers.
	Adobe Flash Player is required at the client side to perform the interactive assessment of co-evolution.
	Contact: pazos@cnb.csic.es Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Horizontal gene transfer (HGT) is a fundamental mechanism that enables organisms such as bacteria to directly transfer genetic material between distant species.
	This way, bacteria can acquire new traits such as antibiotic resistance or pathogenic toxins.
	Current bioinformatics approaches focus on the detection of past HGT events by exploring phylogenetic trees or genome composition inconsistencies.
	However, these techniques normally require the availability of finished and fully annotated genomes and of sufficiently large deviations that allow detection and are thus not widely applicable.
	Especially in outbreak scenarios with HGT-mediated emergence of new pathogens, like the enterohemorrhagic Escherichia coli outbreak in Germany 2011, there is need for fast and precise HGT detection.
	Next-generation sequencing (NGS) technologies facilitate rapid analysis of unknown pathogens but, to the best of our knowledge, so far no approach detects HGTs directly from NGS reads.
	Results: We present Daisy, a novel mapping-based tool for HGT detection.
	Daisy determines HGT boundaries with split-read mapping and evaluates candidate regions relying on read pair and coverage information.
	Daisy successfully detects HGT regions with base pair resolution in both simulated and real data, and outperforms alternative approaches using a genome assembly of the reads.
	We see our approach as a powerful complement for a comprehensive analysis of HGT in the context of NGS data.
	Availability and Implementation: Daisy is freely available from http://github.com/ktrappe/daisy.Contact: renardb@rki.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Lysine acetylation is a post-translational protein modification and a primary regulatory mechanism that controls many cell signaling processes.
	Lysine acetylation sites are recognized by acetyltransferases and deacetylases through sequence patterns (motifs).
	Recently, we used high-resolution mass spectrometry to identify 3600 lysine acetylation sites on 1750 human proteins covering most of the previously annotated sites and providing the most comprehensive acetylome so far.
	This dataset should provide an excellent source to train support vector machines (SVMs) allowing the high accuracy in silico prediction of acetylated lysine residues.
	Results: We developed a SVM to predict acetylated residues.
	The precision of our acetylation site predictor is 78% at 78% recall on input data containing equal numbers of modified and non-modified residues.
	Availability: The online predictor is available at http://www.phosida.com Contact: mmann@biochem.mpg.de
	BioModels (http://www.ebi.ac.uk/biomodels/) is a repository of mathematical models of biological processes.
	A large set of models is curated to verify both correspondence to the biological process that the model seeks to represent, and reproducibility of the simulation results as described in the corresponding peer-reviewed publication.
	Many models submitted to the database are annotated, crossreferencing its components to external resources such as database records, and terms from controlled vocabularies and ontologies.
	BioModels comprises two main branches: one is composed of models derived from literature, while the second is generated through automated processes.
	BioModels currently hosts over 1200 models derived directly from the literature, as well as in excess of 140 000 models automatically generated from pathway resources.
	This represents an approximate 60-fold growth for literature-based model numbers alone, since BioModels' first release a decade ago.
	This article describes updates to the resource over this period, which include changes to the user interface, the annotation profiles of models in the curation pipeline, major infrastructure changes, ability to perform online simulations and the availability of model content in Linked Data form.
	We also outline planned improvements to cope with a diverse array of new challenges.
	The Molecular INTeraction Database (MINT, http://mint.bio.uniroma2.it/mint/) is a public repository for protein-protein interactions (PPI) reported in peer-reviewed journals.
	The database grows steadily over the years and at September 2011 contains approximately 235 000 binary interactions captured from over 4750 publications.
	The web interface allows the users to search, visualize and download interactions data.
	MINT is one of the members of the International Molecular Exchange consortium (IMEx) and adopts the Molecular Interaction Ontology of the Proteomics Standard Initiative (PSI-MI) standards for curation and data exchange.
	MINT data are freely accessible and downloadable at http://mint.bio.uniroma2.it/mint/download.do.
	We report here the growth of the database, the major changes in curation policy and a new algorithm to assign a confidence to each interaction.
	Motivation: The recognition of translation initiation sites and stop codons is a fundamental part of any gene recognition program.
	Currently, the most successful methods use powerful classifiers, such as support vector machines with various string kernels.
	These methods all use two classes, one of positive instances and another one of negative instances that are constructed using sequences from the whole genome.
	However, the features of the negative sequences differ depending on the position of the negative samples in the gene.
	There are differences depending on whether they are from exons, introns, intergenic regions or any other functional part of the genome.
	Thus, the positive class is fairly homogeneous, as all its sequences come from the same part of the gene, but the negative class is composed of different instances.
	The classifier suffers from this problem.
	In this article, we propose the training of different classifiers with different negative, more homogeneous, classes and the combination of these classifiers for improved accuracy.
	Results: The proposed method achieves better accuracy than the best state-of-the-art method, both in terms of the geometric mean of the specificity and sensitivity and the area under the receiver operating characteristic and precision recall curves.
	The method is tested on the whole human genome.
	The results for recognizing both translation initiation sites and stop codons indicated improvements in the rates of both false-negative results (FN) and false-positive results (FP).
	On an average, for translation initiation site recognition, the falsenegative ratio was reduced by 30.2% and the FP ratio decreased by 10.9%.
	For stop codon prediction, FP were reduced by 41.4% and FN by 31.7%.
	Availability and implementation: The source code is licensed under the General Public License and is thus freely available.
	The datasets and source code can be obtained from http://cib.uco.es/site-recognition.
	Contact: npedrajas@uco.es
	Motivation: Understanding the architecture and function of RNA molecules requires methods for comparing and analyzing their 3D structures.
	Although a structural alignment of short RNAs is achievable in a reasonable amount of time, large structures represent much bigger challenge.
	However, the growth of the number of large RNAs deposited in the PDB database calls for the development of fast and accurate methods for analyzing their structures, as well as for rapid similarity searches in databases.
	Results: In this article a novel algorithm for an RNA structural comparison SETTER (SEcondary sTructure-based TERtiary Structure Similarity Algorithm) is introduced.
	SETTER uses a pairwise comparison method based on 3D similarity of the so-called generalized secondary structure units.
	For each pair of structures, SETTER produces a distance score and an indication of its statistical significance.
	SETTER can be used both for the structural alignments of structures that are already known to be homologous, as well as for 3D structure similarity searches and functional annotation.
	The algorithm presented is both accurate and fast and does not impose limits on the size of aligned RNA structures.
	Availability: The SETTER program, as well as all datasets, is freely available from http://siret.cz/hoksza/projects/setter/.Contact: hoksza@ksi.mff.cuni.cz, or svozild@vscht.cz Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The SEABED web server integrates a variety of docking and QSAR techniques in a user-friendly environment.
	SEABED goes beyond the basic docking and QSAR web tools and implements extended functionalities like receptor preparation, library editing, flexible ensemble docking, hybrid docking/QSAR experiments or virtual screening on protein mutants.
	SEABED is not a monolithic workflow tool but Software as a Service platform.
	Availability and implementation: SEABED is a free web server available at http://www.bsc.es/SEABED.
	No registration is required.
	Contact: ramon.goni@bsc.es Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Metagenome analysis requires tools that can estimate the taxonomic abundances in anonymous sequence data over the whole range of biological entities.
	Because there is usually no prior knowledge about the data composition, not only all domains of life but also viruses have to be included in taxonomic profiling.
	Such a full-range approach, however, is difficult to realize owing to the limited coverage of available reference data.
	In particular, archaea and viruses are generally not well represented by current genome databases.
	Results: We introduce a novel approach to taxonomic profiling of metagenomes that is based on mixture model analysis of protein signatures.
	Our results on simulated and real data reveal the difficulties of the existing methods when measuring achaeal or viral abundances and show the overall good profiling performance of the protein-based mixture model.
	As an application example, we provide a large-scale analysis of data from the Human Microbiome Project.
	This demonstrates the utility of our method as a first instance profiling tool for a fast estimate of the community structure.
	Availability: http://gobics.de/TaxyPro.Contact: pmeinic@gwdg.de Supplementary information: Supplementary Material is available at Bioinformatics online.
	Motivation: Histone modifications are a key epigenetic mechanism to activate or repress the transcription of genes.
	Datasets of matched transcription data and histone modification data obtained by ChIP-seq exist, but methods for integrative analysis of both data types are still rare.
	Here, we present a novel bioinformatics approach to detect genes that show different transcript abundances between two conditions putatively caused by alterations in histone modification.
	Results: We introduce a correlation measure for integrative analysis of ChIP-seq and gene transcription data measured by RNA sequencing or microarrays and demonstrate that a proper normalization of ChIPseq data is crucial.
	We suggest applying Bayesian mixture models of different types of distributions to further study the distribution of the correlation measure.
	The implicit classification of the mixture models is used to detect genes with differences between two conditions in both gene transcription and histone modification.
	The method is applied to different datasets, and its superiority to a naive separate analysis of both data types is demonstrated.
	Availability and implementation: R/Bioconductor package epigenomix.
	Contact: h.klein@uni-muenster.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Progress in 3D electron microscopy (EM) imaging has greatly facilitated neuroscience research in high-throughput data acquisition.
	Correspondingly, high-throughput automated image analysis methods are necessary to work on par with the speed of data being produced.
	One such example is the need for automated EM image segmentation for neurite reconstruction.
	However, the efficiency and reliability of current methods are still lagging far behind human performance.
	Results: Here, we propose DeepEM3D, a deep learning method for segmenting 3D anisotropic brain electron microscopy images.
	In this method, the deep learning model can efficiently build feature representation and incorporate sufficient multi-scale contextual information.
	We propose employing a combination of novel boundary map generation methods with optimized model ensembles to address the inherent challenges of segmenting anisotropic images.
	We evaluated our method by participating in the 3D segmentation of neurites in EM images (SNEMI3D) challenge.
	Our submission is ranked #1 on the current leaderboard as of Oct 15, 2016.
	More importantly, our result was very close to human-level performance in terms of the challenge evaluation metric: namely, a Rand error of 0.06015 versus the human value of 0.05998.
	Availability and Implementation: The code is available at https://github.com/divelab/deepem3d/Contact: sji@eecs.wsu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Haplotypes, defined as the sequence of alleles on one chromosome, are crucial for many genetic analyses.
	As experimental determination of haplotypes is extremely expensive, haplotypes are traditionally inferred using computational approaches from genotype data, i.e.
	the mixture of the genetic information from both haplotypes.
	Best performing approaches for haplotype inference rely on Hidden Markov Models, with the underlying assumption that the haplotypes of a given individual can be represented as a mosaic of segments from other haplotypes in the same population.
	Such algorithms use this model to predict the most likely haplotypes that explain the observed genotype data conditional on reference panel of haplotypes.
	With rapid advances in short read sequencing technologies, sequencing is quickly establishing as a powerful approach for collecting genetic variation information.
	As opposed to traditional genotyping-array technologies that independently call genotypes at polymorphic sites, short read sequencing often collects haplotypic information; a read spanning more than one polymorphic locus (multi-single nucleotide polymorphic read) contains information on the haplotype from which the read originates.
	However, this information is generally ignored in existing approaches for haplotype phasing and genotype-calling from short read data.
	Results: In this article, we propose a novel framework for haplotype inference from short read sequencing that leverages multi-single nucleotide polymorphic reads together with a reference panel of haplotypes.
	The basis of our approach is a new probabilistic model that finds the most likely haplotype segments from the reference panel to explain the short read sequencing data for a given individual.
	We devised an efficient sampling method within a probabilistic model to achieve superior performance than existing methods.
	Using simulated sequencing reads from real individual genotypes in the HapMap data and the 1000 Genomes projects, we show that our method is highly accurate and computationally efficient.
	Our haplotype predictions improve accuracy over the basic haplotype copying model by 20% with comparable computational time, and over another recently proposed approach Hap-SeqX by 10% with significantly reduced computational time and memory usage.
	Availability: Publicly available software is available at http://genetics.cs.ucla.edu/harsh Contact: bpasaniuc@mednet.ucla.edu or eeskin@cs.ucla.edu The Author 2013.
	Published by Oxford University Press.
	All rights reserved.
	For Permissions, please e-mail: journals.permissions@oup.com
	Motivation: To further our understanding of the mechanisms underlying biochemical pathways mathematical modelling is used.
	Since many parameter values are unknown they need to be estimated using experimental observations.
	The complexity of models necessary to describe biological pathways in combination with the limited amount of quantitative data results in large parameter uncertainty which propagates into model predictions.
	Therefore prediction uncertainty analysis is an important topic that needs to be addressed in Systems Biology modelling.
	Results: We propose a strategy for model prediction uncertainty analysis by integrating profile likelihood analysis with Bayesian estimation.
	Our method is illustrated with an application to a model of the JAK-STAT signalling pathway.
	The analysis identified predictions on unobserved variables that could be made with a high level of confidence, despite that some parameters were non-identifiable.
	Availability and implementation: Source code is available at: http://bmi.bmt.tue.nl/sysbio/software/pua.html.Contact: j.vanlier@tue.nl Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Systems biology models can be used to test new hypotheses formulated on the basis of previous knowledge or new experimental data, contradictory with a previously existing model.
	New hypotheses often come in the shape of a set of possible regulatory mechanisms.
	This search is usually not limited to finding a single regulation link, but rather a combination of links subject to great uncertainty or no information about the kinetic parameters.
	Results: In this work, we combine a logic-based formalism, to describe all the possible regulatory structures for a given dynamic model of a pathway, with mixed-integer dynamic optimization (MIDO).
	This framework aims to simultaneously identify the regulatory structure (represented by binary parameters) and the real-valued parameters that are consistent with the available experimental data, resulting in a logic-based differential equation model.
	The alternative to this would be to perform real-valued parameter estimation for each possible model structure, which is not tractable for models of the size presented in this work.
	The performance of the method presented here is illustrated with several case studies: a synthetic pathway problem of signaling regulation, a twocomponent signal transduction pathway in bacterial homeostasis, and a signaling network in liver cancer cells.
	Supplementary information: Supplementary data are available at Bioinformatics online.
	Contact: julio@iim.csic.es or saezrodriguez@ebi.ac.uk
	Summary: OmicsAnalyzer is a Cytoscape plug-in for visual omicsbased network analysis that (i) integrates hetero-omics data for one or more species; (ii) performs statistical tests on the integrated datasets; and (iii) visualizes results in a network context.
	Availability: Implemented in Java, OmicsAnalyzer runs with Cytoscape 2.6 and 2.7.
	Binaries, documentation and video walkthroughs are freely available at http://vrac.iastate.edu/~jlv/omicsanalyzer/ Contact: julied@iastate.edu; netscape@iastate.edu
	Summary: Many large 'omics' datasets have been published and many more are expected in the near future.
	New analysis methods are needed for best exploitation.
	We have developed a graphical user interface (GUI) for easy data analysis.
	Our discovery of all significant substructures (DASS) approach elucidates the underlying modularity, a typical feature of complex biological data.
	It is related to biclustering and other data mining approaches.
	Importantly, DASS-GUI also allows handling of multi-sets and calculation of statistical significances.
	DASS-GUI contains tools for further analysis of the identified patterns: analysis of the pattern hierarchy, enrichment analysis, module validation, analysis of additional numerical data, easy handling of synonymous names, clustering, filtering and merging.
	Different export options allow easy usage of additional tools such as Cytoscape.
	Availability: Source code, pre-compiled binaries for different systems, a comprehensive tutorial, case studies and many additional datasets are freely available at http://www.ifr.ac.uk/dass/gui/.DASS-GUI is implemented in Qt.
	Contact: jehol@psb.vib-ugent.be; thomas.wilhelm@bbsrc.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Gene Expression Atlas (http://www.ebi.ac.uk/gxa) is an added-value database providing information about gene expression in different cell types, organism parts, developmental stages, disease states, sample treatments and other biological/ experimental conditions.
	The content of this database derives from curation, re-annotation and statistical analysis of selected data from the ArrayExpress Archive and the European Nucleotide Archive.
	A simple interface allows the user to query for differential gene expression either by gene names or attributes or by biological conditions, e.g.
	diseases, organism parts or cell types.
	Since our previous report we made 20 monthly releases and, as of Release 11.08 (August 2011), the database supports 19 species, which contains expression data measured for 19 014 biological conditions in 136 551 assays from 5598 independent studies.
	Motivation: Macromolecular structures and interactions are intrinsically heterogeneous, temporally adopting a range of configurations that can confound the analysis of data from bulk experiments.
	To obtain quantitative insights into heterogeneous systems, an ensemble-based approach can be employed, in which predicted data computed from a collection of models is compared to the observed experimental results.
	By simultaneously fitting orthogonal structural data (e.g.
	small-angle X-ray scattering, nuclear magnetic resonance residual dipolar couplings, dipolar electron-electron resonance spectra), the range and population of accessible macromolecule structures can be probed.
	Results: We have developed MESMER, software that enables the user to identify ensembles that can recapitulate experimental data by refining thousands of component collections selected from an input pool of potential structures.
	The MESMER suite includes a powerful graphical user interface (GUI) to streamline usage of the command-line tools, calculate data from structure libraries and perform analyses of conformational and structural heterogeneity.
	To allow for incorporation of other data types, modular Python plugins enable users to compute and fit data from nearly any type of quantitative experimental data.
	Results: Conformational heterogeneity in three macromolecular systems was analyzed with MESMER, demonstrating the utility of the streamlined, user-friendly software.
	Availability and implementation: https://code.google.com/p/mesmer/Contact: foster.281@osu.edu or ihms.2@osu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: SimBoolNet is an open source Cytoscape plugin that simulates the dynamics of signaling transduction using Boolean networks.
	Given a user-specified level of stimulation to signal receptors, SimBoolNet simulates the response of downstream molecules and visualizes with animation and records the dynamic changes of the network.
	It can be used to generate hypotheses and facilitate experimental studies about causal relations and crosstalk among cellular signaling pathways.
	Availability: SimBoolNet package (with manual) is freely available at http://www.ncbi.nlm.nih.gov/CBBresearch/Przytycka/SimBoolNet Contact: przytyck@ncbi.nlm.nih.gov; zhengj@ncbi.nlm.nih.gov
	Motivation: Identifying the critical state or pre-transition state just before the occurrence of a phase transition is a challenging task, because the state of the system may show little apparent change before this critical transition during the gradual parameter variations.
	Such dynamics of phase transition is generally composed of three stages, i.e.
	before-transition state, pre-transition state and after-transition state, which can be considered as three different Markov processes.
	Results: By exploring the rich dynamical information provided by high-throughput data, we present a novel computational method, i.e.
	hidden Markov model (HMM) based approach, to detect the switching point of the two Markov processes from the before-transition state (a stationary Markov process) to the pre-transition state (a time-varying Markov process), thereby identifying the pre-transition state or early-warning signals of the phase transition.
	To validate the effectiveness, we apply this method to detect the signals of the imminent phase transitions of complex systems based on the simulated datasets, and further identify the pre-transition states as well as their critical modules for three real datasets, i.e.
	the acute lung injury triggered by phosgene inhalation, MCF-7 human breast cancer caused by heregulin and HCV-induced dysplasia and hepatocellular carcinoma.
	Both functional and pathway enrichment analyses validate the computational results.
	Availability and implementation: The source code and some supporting files are available at https://github.com/rabbitpei/HMM_based-method.Contacts: lnchen@sibs.ac.cn or liyj@scut.edu.cn Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Breast cancer outcome prediction based on gene expression profiles is an important strategy for personalize patient care.
	To improve performance and consistency of discovered markers of the initial molecular classifiers, network-based outcome prediction methods (NOPs) have been proposed.
	In spite of the initial claims, recent studies revealed that neither performance nor consistency can be improved using these methods.
	NOPs typically rely on the construction of meta-genes by averaging the expression of several genes connected in a network that encodes protein interactions or pathway information.
	In this article, we expose several fundamental issues in NOPs that impede on the prediction power, consistency of discovered markers and obscures biological interpretation.
	Results: To overcome these issues, we propose FERAL, a network-based classifier that hinges upon the Sparse Group Lasso which performs simultaneous selection of marker genes and training of the prediction model.
	An important feature of FERAL, and a significant departure from existing NOPs, is that it uses multiple operators to summarize genes into meta-genes.
	This gives the classifier the opportunity to select the most relevant meta-gene for each gene set.
	Extensive evaluation revealed that the discovered markers are markedly more stable across independent datasets.
	Moreover, interpretation of the marker genes detected by FERAL reveals valuable mechanistic insight into the etiology of breast cancer.
	Availability and implementation: All code is available for download at: http://homepage.tudelft.nl/53a60/resources/FERAL/FERAL.zip.
	Contact: j.deridder@tudelft.nl Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: A complete repository of gene-gene interactions is key for understanding cellular processes, human disease and drug response.
	These gene-gene interactions include both proteinprotein interactions and transcription factor interactions.
	The majority of known interactions are found in the biomedical literature.
	Interaction databases, such as BioGRID and ChEA, annotate these gene-gene interactions; however, curation becomes difficult as the literature grows exponentially.
	DeepDive is a trained system for extracting information from a variety of sources, including text.
	In this work, we used DeepDive to extract both protein-protein and transcription factor interactions from over 100 000 full-text PLOS articles.
	Methods: We built an extractor for gene-gene interactions that identified candidate gene-gene relations within an input sentence.
	For each candidate relation, DeepDive computed a probability that the relation was a correct interaction.
	We evaluated this system against the Database of Interacting Proteins and against randomly curated extractions.
	Results: Our system achieved 76% precision and 49% recall in extracting direct and indirect interactions involving gene symbols co-occurring in a sentence.
	For randomly curated extractions, the system achieved between 62% and 83% precision based on direct or indirect interactions, as well as sentence-level and document-level precision.
	Overall, our system extracted 3356 unique gene pairs using 724 features from over 100 000 full-text articles.
	Availability and implementation: Application source code is publicly available at https://github.com/edoughty/deepdive_genegene_app Contact: russ.altman@stanford.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Evolving technology has increased the focus on genomics.
	The combination of today's advanced techniques with decades of molecular biology research has yielded huge amounts of pathway data.
	A standard, named the Systems Biology Graphical Notation (SBGN), was recently introduced to allow scientists to represent biological pathways in an unambiguous, easyto-understand and efficient manner.
	Although there are a number of automated layout algorithms for various types of biological networks, currently none specialize on process description (PD) maps as defined by SBGN.
	Results: We propose a new automated layout algorithm for PD maps drawn in SBGN.
	Our algorithm is based on a force-directed automated layout algorithm called Compound Spring Embedder (CoSE).
	On top of the existing force scheme, additional heuristics employing new types of forces and movement rules are defined to address SBGN-specific rules.
	Our algorithm is the only automatic layout algorithm that properly addresses all SBGN rules for drawing PD maps, including placement of substrates and products of process nodes on opposite sides, compact tiling of members of molecular complexes and extensively making use of nested structures (compound nodes) to properly draw cellular locations and molecular complex structures.
	As demonstrated experimentally, the algorithm results in significant improvements over use of a generic layout algorithm such as CoSE in addressing SBGN rules on top of commonly accepted graph drawing criteria.
	Availability and implementation: An implementation of our algorithm in Java is available within ChiLay library (https://github.com/iVis-at-Bilkent/chilay).Contact: ugur@cs.bilkent.edu.tr or dogrusoz@cbio.mskcc.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Read simulators combined with alignment evaluation tools provide the most straightforward way to evaluate and compare mappers.
	Simulation of reads is accompanied by information about their positions in the source genome.
	This information is then used to evaluate alignments produced by the mapper.
	Finally, reports containing statistics of successful read alignments are created.
	In default of standards for encoding read origins, every evaluation tool has to be made explicitly compatible with the simulator used to generate reads.
	Results: To solve this obstacle, we have created a generic format Read Naming Format (RNF) for assigning read names with encoded information about original positions.
	Futhermore, we have developed an associated software package RNFTools containing two principal components.
	MISHMASH applies one of popular read simulating tools (among DWGSIM, ART, MASON, CURESIM, etc.)
	and transforms the generated reads into RNF format.
	LAVENDER evaluates then a given read mapper using simulated reads in RNF format.
	A special attention is payed to mapping qualities that serve for parametrization of ROC curves, and to evaluation of the effect of read sample contamination.
	Availability and implementation: RNFTools: http://karel-brinda.github.io/rnftools Spec.
	of RNF: http://karel-brinda.github.io/rnf-spec Contact: karel.brinda@univ-mlv.fr
	Motivation: Extensive DNA sequencing of tumor and matched normal samples using exome and whole-genome sequencing technologies has enabled the discovery of recurrent genetic alterations in cancer cells, but variability in stromal contamination and subclonal heterogeneity still present a severe challenge to available detection algorithms.
	Results: Here, we describe publicly available software, Shimmer, which accurately detects somatic single-nucleotide variants using statistical hypothesis testing with multiple testing correction.
	This program produces somatic single-nucleotide variant predictions with significantly higher sensitivity and accuracy than other available software when run on highly contaminated or heterogeneous samples, and it gives comparable sensitivity and accuracy when run on samples of high purity.
	Availability: http://www.github.com/nhansen/Shimmer Contact: nhansen@mail.nih.gov Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We propose a targeted re-sequencing simulator Wessim that generates synthetic exome sequencing reads from a given sample genome.
	Wessim emulates conventional exome capture technologies, including Agilent's SureSelect and NimbleGen's SeqCap, to generate DNA fragments from genomic target regions.
	The target regions can be either specified by genomic coordinates or inferred from in silico probe hybridization.
	Coupled with existing next-generation sequencing simulators, Wessim generates a realistic artificial exome sequencing data, which is essential for developing and evaluating exome-targeted variant callers.
	Availability: Source code and the packaged version of Wessim with manuals are available at http://sak042.github.com/Wessim/.Contact: sak042@cs.ucsd.edu or vbafna@cs.ucsd.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We have developed a new software system, REgulatory Network generator with COmbinatorial control (RENCO), for automatic generation of differential equations describing pre-transcriptional combinatorics in artificial regulatory networks.
	RENCO has the following benefits: (a) it explicitly models protein-protein interactions among transcription factors, (b) it captures combinatorial control of transcription factors on target genes and (c) it produces output in Systems Biology Markup Language (SBML) format, which allows these equations to be directly imported into existing simulators.
	Explicit modeling of the protein interactions allows RENCO to incorporate greater mechanistic detail of the transcription machinery compared to existing models and can provide a better assessment of algorithms for regulatory network inference.
	Availability: RENCO is a CÃ¾Ã¾ command line program, available at http://sourceforge.net/projects/renco/Contact: terran@cs.unm.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The construction of statistics for summarizing posterior samples returned by a Bayesian phylogenetic study has so far been hindered by the poor geometric insights available into the space of phylogenetic trees, and ad hoc methods such as the derivation of a consensus tree makeup for the ill-definition of the usual concepts of posterior mean, while bootstrap methods mitigate the absence of a sound concept of variance.
	Yielding satisfactory results with sufficiently concentrated posterior distributions, such methods fall short of providing a faithful summary of posterior distributions if the data do not offer compelling evidence for a single topology.
	Results: Building upon previous work of Billera et al., summary statistics such as sample mean, median and variance are defined as the geometric median, Frechet mean and variance, respectively.
	Their computation is enabled by recently published works, and embeds an algorithm for computing shortest paths in the space of trees.
	Studying the phylogeny of a set of plants, where several tree topologies occur in the posterior sample, the posterior mean balances correctly the contributions from the different topologies, where a consensus tree would be biased.
	Comparisons of the posterior mean, median and consensus trees with the ground truth using simulated data also reveals the benefits of a sound averaging method when reconstructing phylogenetic trees.
	Availability and implementation: We provide two independent implementations of the algorithm for computing Frechet means, geometric medians and variances in the space of phylogenetic trees.
	TFBayes: https://github.com/pbenner/tfbayes, TrAP: https://github.com/bacak/TrAP.
	Contact: philipp.benner@mis.mpg.de
	Summary: In genetics, many evolutionary pathways can be modeled by the ordered accumulation of permanent changes.
	Mixture models of mutagenetic trees have been used to describe disease progression in cancer and in HIV.
	In cancer, progression is modeled by the accumulation of chromosomal gains and losses in tumor cells; in HIV, the accumulation of drug resistance-associated mutations in the viral genome is known to be associated with disease progression.
	From such evolutionary models, genetic progression scores can be derived that assign measures for the disease state to single patients.
	Rtreemix is an R package for estimating mixture models of evolutionary pathways from observed cross-sectional data and for estimating associated genetic progression scores.
	The package also provides extended functionality for estimating confidence intervals for estimated model parameters and for evaluating the stability of the estimated evolutionary mixture models.
	Availability: Rtreemix is an R package that is freely available from the Bioconductor project at http://www.bioconductor.org and runs on Linux and Windows.
	Contact: jasmina@mpi-inf.mpg.de
	Summary: We have developed Nozzle, an R package that provides an Application Programming Interface to generate HTML reports with dynamic user interface elements.
	Nozzle was designed to facilitate summarization and rapid browsing of complex results in data analysis pipelines where multiple analyses are performed frequently on big datasets.
	The package can be applied to any project where user-friendly reports need to be created.
	Availability: The R package is available on CRAN at http://cran.rproject.org/packageÂ¼Nozzle.R1.
	Examples and additional materials are available at http://gdac.broadinstitute.org/nozzle.
	The source code is also available at http://www.github.com/parklab/Nozzle.Contact: peter_park@hms.harvard.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Species trees provide insight into basic biology, including the mechanisms of evolution and how it modifies biomolecular function and structure, biodiversity and co-evolution between genes and species.
	Yet, gene trees often differ from species trees, creating challenges to species tree estimation.
	One of the most frequent causes for conflicting topologies between gene trees and species trees is incomplete lineage sorting (ILS), which is modelled by the multi-species coalescent.
	While many methods have been developed to estimate species trees from multiple genes, some which have statistical guarantees under the multi-species coalescent model, existing methods are too computationally intensive for use with genome-scale analyses or have been shown to have poor accuracy under some realistic conditions.
	Results: We present ASTRAL, a fast method for estimating species trees from multiple genes.
	ASTRAL is statistically consistent, can run on datasets with thousands of genes and has outstanding accuracyimproving on MP-EST and the population tree from BUCKy, two statistically consistent leading coalescent-based methods.
	ASTRAL is often more accurate than concatenation using maximum likelihood, except when ILS levels are low or there are too few gene trees.
	Availability and implementation: ASTRAL is available in open source form at https://github.com/smirarab/ASTRAL/.
	Datasets studied in this article are available at http://www.cs.utexas.edu/users/phylo/datasets/astral.
	Contact: warnow@illinois.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The Oxford Nanopore MinION sequencer, currently in pre-release testing through the MinION Access Programme (MAP), promises long reads in real-time from an inexpensive, compact, USB device.
	Tools have been released to extract FASTA/Q from the MinION base calling output and to provide basic yield statistics.
	However, no single tool yet exists to provide comprehensive alignment-based quality control and error profile analysis-something that is extremely important given the speed with which the platform is evolving.
	Results: NanoOK generates detailed tabular and graphical output plus an in-depth multi-page PDF report including error profile, quality and yield data.
	NanoOK is multi-reference, enabling detailed analysis of metagenomic or multiplexed samples.
	Four popular Nanopore aligners are supported and it is easily extensible to include others.
	Availability and implementation: NanoOK is an open-source software, implemented in Java with supporting R scripts.
	It has been tested on Linux and Mac OS X and can be downloaded from https://github.com/TGAC/NanoOK.
	A VirtualBox VM containing all dependencies and the DH10B read set used in this article is available from http://opendata.tgac.ac.uk/nanook/.
	A Docker image is also available from Docker Hub-see program documentation https://documentation.tgac.ac.uk/display/NANOOK.
	Contact: richard.leggett@tgac.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Due to the high complexity of metabolome, the comprehensive 2D gas chromatography time-of-flight mass spectrometry (GC GC-TOF MS) is considered as a powerful analytical platform for metabolomics study.
	However, the applications of GC GC-TOF MS in metabolomics are not popular owing to the lack of bioinformatics system for data analysis.
	Results: We developed a computational platform entitled metabolomics profiling pipeline (MetPP) for analysis of metabolomics data acquired on a GC GC-TOF MS system.
	MetPP can process peak filtering and merging, retention index matching, peak list alignment, normalization, statistical significance tests and pattern recognition, using the peak lists deconvoluted from the instrument data as its input.
	The performance of MetPP software was tested with two sets of experimental data acquired in a spike-in experiment and a biomarker discovery experiment, respectively.
	MetPP not only correctly aligned the spiked-in metabolite standards from the experimental data, but also correctly recognized their concentration difference between sample groups.
	For analysis of the biomarker discovery data, 15 metabolites were recognized with significant concentration difference between the sample groups and these results agree with the literature results of histological analysis, demonstrating the effectiveness of applying MetPP software for disease biomarker discovery.
	Availability: The source code of MetPP is available at http://metaopen.sourceforge.net Contact: xiang.zhang@louisville.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Simple tandem repeats are highly variable genetic elements and widespread in genomes of many organisms.
	Next-generation sequencing technologies have enabled a robust comparison of large numbers of simple tandem repeat loci; however, analysis of their variation using traditional sequence analysis approaches still remains limiting and problematic due to variants occurring in repeat sequences confusing alignment programs into mapping sequence reads to incorrect loci when the sequence reads are significantly different from the reference sequence.
	Results: We have developed a program, ReviSTER, which is an automated pipeline using a 'local mapping reference reconstruction method' to revise mismapped or partially misaligned reads at simple tandem repeat loci.
	RevisSTER estimates alleles of repeat loci using a local alignment method and creates temporary local mapping reference sequences, and finally remaps reads to the local mapping references.
	Using this approach, ReviSTER was able to successfully revise reads misaligned to repeat loci from both simulated data and real data.
	Availability: ReviSTER is open-source software available at http://rev ister.sourceforge.net.
	Contact: garner@vbi.vt.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Targeted interventions using RNA interference in combination with the measurement of secondary effects with DNA microarrays can be used to computationally reverse engineer features of upstream non-transcriptional signaling cascades based on the nested structure of effects.
	Results: We extend previous work by Markowetz et al., who proposed a statistical framework to score different network hypotheses.
	Our extensions go in several directions: we show how prior assumptions on the network structure can be incorporated into the scoring scheme by defining appropriate prior distributions on the network structure as well as on hyperparameters.
	An approach called module networks is introduced to scale up the original approach, which is limited to around 5 genes, to infer large-scale networks of more than 30 genes.
	Instead of the data discretization step needed in the original framework, we propose the usage of a beta-uniform mixture distribution on the P-value profile, resulting from differential gene expression calculation, to quantify effects.
	Extensive simulations on artificial data and application of our module network approach to infer the signaling network between 13 genes in the ER- pathway in human MCF-7 breast cancer cells show that our approach gives sensible results.
	Using a bootstrapping and a jackknife approach, this reconstruction is found to be statistically stable.
	Availability: The proposed method is available within the Bioconductor R-package nem.
	Contact: h.froehlich@dkfz-heidelberg.de
	Summary: MNase-Seq and ChIP-Seq have evolved as popular techniques to study chromatin and histone modification.
	Although many tools have been developed to identify enriched regions, software tools for nucleosome positioning are still limited.
	We introduce a flexible and powerful open-source R package, PING 2.0, for nucleosome positioning using MNase-Seq data or MNase- or sonicated- ChIP-Seq data combined with either single-end or paired-end sequencing.
	PING uses a model-based approach, which enables nucleosome predictions even in the presence of low read counts.
	We illustrate PING using two paired-end datasets from Saccharomyces cerevisiae and compare its performance with nucleR and ChIPseqR.
	Availability: PING 2.0 is available from the Bioconductor website at http://bioconductor.org.
	It can run on Linux, Mac and Windows.Contact: rgottard@fhcrc.org Supplementary Information: Supplementary material is available at Bioinformatics online.
	Motivation: Several algorithms exist for detecting copy number variants (CNVs) from human exome sequencing read depth, but previous tools have not been well suited for large population studies on the order of tens or hundreds of thousands of exomes.
	Their limitations include being difficult to integrate into automated variant-calling pipelines and being ill-suited for detecting common variants.
	To address these issues, we developed a new algorithm-Copy number estimation using Lattice-Aligned Mixture Models (CLAMMS)-which is highly scalable and suitable for detecting CNVs across the whole allele frequency spectrum.
	Results: In this note, we summarize the methods and intended use-case of CLAMMS, compare it to previous algorithms and briefly describe results of validation experiments.
	We evaluate the adherence of CNV calls from CLAMMS and four other algorithms to Mendelian inheritance patterns on a pedigree; we compare calls from CLAMMS and other algorithms to calls from SNP genotyping arrays for a set of 3164 samples; and we use TaqMan quantitative polymerase chain reaction to validate CNVs predicted by CLAMMS at 39 loci (95% of rare variants validate; across 19 common variant loci, the mean precision and recall are 99% and 94%, respectively).
	In the Supplementary Materials (available at the CLAMMS Github repository), we present our methods and validation results in greater detail.
	Availability and implementation: https://github.com/rgcgithub/clamms (implemented in C).Contact: jeffrey.reid@regeneron.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: One of the solutions proposed for addressing the challenge of the overwhelming abundance of genomic sequence and other biological data is the use of the Hadoop computing framework.
	Appropriate tools are needed to set up computational environments that facilitate research of novel bioinformatics methodology using Hadoop.
	Here, we present cl-dash, a complete starter kit for setting up such an environment.
	Configuring and deploying new Hadoop clusters can be done in minutes.
	Use of Amazon Web Services ensures no initial investment and minimal operation costs.
	Two sample bioinformatics applications help the researcher understand and learn the principles of implementing an algorithm using the MapReduce programming pattern.
	Availability and implementation: Source code is available at https://bitbucket.org/booz-allen-scicomp-team/cl-dash.git.
	Contact: hodor_paul@bah.com
	Motivation: As a natural consequence of being a computer-based discipline, bioinformatics has a strong focus on database and software development, but the volume and variety of resources are growing at unprecedented rates.
	An audit of database and software usage patterns could help provide an overview of developments in bioinformatics and community common practice, and comparing the links between resources through time could demonstrate both the persistence of existing software and the emergence of new tools.
	Results: We study the connections between bioinformatics resources and construct networks of database and software usage patterns, based on resource co-occurrence, that correspond to snapshots of common practice in the bioinformatics community.
	We apply our approach to pairings of phylogenetics software reported in the literature and argue that these could provide a stepping stone into the identification of scientific best practice.
	Availability and implementation: The extracted resource data, the scripts used for network generation and the resulting networks are available at http://bionerds.sourceforge.net/networks/Contact: robert.stevens@manchester.ac.uk
	Motivation: The recognition and normalization of cell line names in text is an important task in biomedical text mining research, facilitating for instance the identification of synthetically lethal genes from the literature.
	While several tools have previously been developed to address cell line recognition, it is unclear whether available systems can perform sufficiently well in realistic and broadcoverage applications such as extracting synthetically lethal genes from the cancer literature.
	In this study, we revisit the cell line name recognition task, evaluating both available systems and newly introduced methods on various resources to obtain a reliable tagger not tied to any specific subdomain.
	In support of this task, we introduce two text collections manually annotated for cell line names: the broad-coverage corpus Gellus and CLL, a focused target domain corpus.
	Results: We find that the best performance is achieved using NERsuite, a machine learning system based on Conditional Random Fields, trained on the Gellus corpus and supported with a dictionary of cell line names.
	The system achieves an F-score of 88.46% on the test set of Gellus and 85.98% on the independently annotated CLL corpus.
	It was further applied at large scale to 24 302 102 unannotated articles, resulting in the identification of 5 181 342 cell line mentions, normalized to 11 755 unique cell line database identifiers.
	Availability and implementation: The manually annotated datasets, the cell line dictionary, derived corpora, NERsuite models and the results of the large-scale run on unannotated texts are available under open licenses at http://turkunlp.github.io/Cell-line-recognition/.Contact: sukaew@utu.fi
	Motivation: Chromatin immunoprecipitation coupled to next-generation sequencing (ChIP-seq) is widely used to study the in vivo binding sites of transcription factors (TFs) and their regulatory targets.
	Recent improvements to ChIP-seq, such as increased resolution, promise deeper insights into transcriptional regulation, yet require novel computational tools to fully leverage their advantages.
	Results: To this aim, we have developed peakzilla, which can identify closely spaced TF binding sites at high resolution (i.e.
	resolves individual binding sites even if spaced closely), as we demonstrate using semisynthetic datasets, performing ChIP-seq for the TF Twist in Drosophila embryos with different experimental fragment sizes, and analyzing ChIP-exo datasets.
	We show that the increased resolution reached by peakzilla is highly relevant, as closely spaced Twist binding sites are strongly enriched in transcriptional enhancers, suggesting a signature to discriminate functional from abundant non-functional or neutral TF binding.
	Peakzilla is easy to use, as it estimates all the necessary parameters from the data and is freely available.
	Availability and implementation: The peakzilla program is available from https://github.com/steinmann/peakzilla or http://www.starklab.org/data/peakzilla/.
	Contact: stark@starklab.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Unlike DNA, RNA abundances can vary over several orders of magnitude.
	Thus, identification of RNA-protein binding sites from high-throughput sequencing data presents unique challenges.
	Although peak identification in ChIP-Seq data has been extensively explored, there are few bioinformatics tools tailored for peak calling on analogous datasets for RNA-binding proteins.
	Here we describe ASPeak (abundance sensitive peak detection algorithm), an implementation of an algorithm that we previously applied to detect peaks in exon junction complex RNA immunoprecipitation in tandem experiments.
	Our peak detection algorithm yields stringent and robust target sets enabling sensitive motif finding and downstream functional analyses.
	Availability: ASPeak is implemented in Perl as a complete pipeline that takes bedGraph files as input.
	ASPeak implementation is freely available at https://sourceforge.net/projects/as-peak under the GNU General Public License.
	ASPeak can be run on a personal computer, yet is designed to be easily parallelizable.
	ASPeak can also run on high performance computing clusters providing efficient speedup.
	The documentation and user manual can be obtained from http://master.dl.sourceforge.net/project/as-peak/manual.pdf.
	Contact: alper.kucukural@umassmed.edu or ccenik@stanford.edu
	Motivation: As the use of microarrays in human studies continues to increase, stringent quality assurance is necessary to ensure accurate experimental interpretation.
	We present a formal approach for microarray quality assessment that is based on dimension reduction of established measures of signal and noise components of expression followed by parametric multivariate outlier testing.
	Results: We applied our approach to several data resources.
	First, as a negative control, we found that the Affymetrix and Illumina contributions to MAQC data were free from outliers at a nominal outlier flagging rate of Î± = 0.01.
	Second, we created a tunable framework for artificially corrupting intensity data from the Affymetrix Latin Square spike-in experiment to allow investigation of sensitivity and specificity of quality assurance (QA) criteria.
	Third, we applied the procedure to 507 Affymetrix microarray GeneChips processed with RNA from human peripheral blood samples.
	We show that exclusion of arrays by this approach substantially increases inferential power, or the ability to detect differential expression, in large clinical studies.
	Availability: http://bioconductor.org/packages/2.3/bioc/html/array Mvout.html and http://bioconductor.org/packages/2.3/bioc/html/affyContam.html affyContam (credentials: readonly/readonly) Contact: aasare@immunetolerance.org; stvjc@channing.harvard.edu
	Motivation: Recently, mapping studies of expression quantitative loci (eQTL) (where gene expression levels are viewed as quantitative traits) have provided insight into the biology of gene regulation.
	Bayesian methods provide natural modeling frameworks for analyzing eQTL studies, where information shared across markers and/or genes can increase the power to detect eQTLs.
	Bayesian approaches tend to be computationally demanding and require specialized software.
	As a result, most eQTL studies use univariate methods treating each gene independently, leading to suboptimal results.
	Results: We present a powerful, computationally optimized and free open-source R package, iBMQ.
	Our package implements a joint hierarchical Bayesian model where all genes and SNPs are modeled concurrently.
	Model parameters are estimated using a Markov chain Monte Carlo algorithm.
	The free and widely used openMP parallel library speeds up computation.
	Using a mouse cardiac dataset, we show that iBMQ improves the detection of large trans-eQTL hotspots compared with other state-of-the-art packages for eQTL analysis.
	Availability: The R-package iBMQ is available from the Bioconductor Web site at http://bioconductor.org and runs on Linux, Windows and MAC OS X.
	It is distributed under the Artistic Licence-2.0 terms.
	Contact: christian.deschepper@ircm.qc.ca or rgottard@fhcrc.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Genomic datasets are often interpreted in the context of large-scale reference databases.
	One approach is to identify significantly overlapping gene sets, which works well for gene-centric data.
	However, many types of high-throughput data are based on genomic regions.
	Locus Overlap Analysis (LOLA) provides easy and automatable enrichment analysis for genomic region sets, thus facilitating the interpretation of functional genomics and epigenomics data.
	Availability and Implementation: R package available in Bioconductor and on the following website: http://lola.computational-epigenetics.org.Contact: nsheffield@cemm.oeaw.ac.at or cbock@cemm.oeaw.ac.at
	Motivation: The combination of liquid chromatography and mass spectrometry (LC/MS) has been widely used for large-scale comparative studies in systems biology, including proteomics, glycomics and metabolomics.
	In almost all experimental design, it is necessary to compare chromatograms across biological or technical replicates and across sample groups.
	Central to this is the peak alignment step, which is one of the most important but challenging preprocessing steps.
	Existing alignment tools do not take into account the structural dependencies between related peaks that coelute and are derived from the same metabolite or peptide.
	We propose a direct matching peak alignment method for LC/MS data that incorporates related peaks information (within each LC/MS run) and investigate its effect on alignment performance (across runs).
	The groupings of related peaks necessary for our method can be obtained from any peak clustering method and are built into a pair-wise peak similarity score function.
	The similarity score matrix produced is used by an approximation algorithm for the weighted matching problem to produce the actual alignment result.
	Results: We demonstrate that related peak information can improve alignment performance.
	The performance is evaluated on a set of benchmark datasets, where our method performs competitively compared to other popular alignment tools.
	Availability: The proposed alignment method has been implemented as a stand-alone application in Python, available for download at http://github.com/joewandy/peak-grouping-alignment.Contact: Simon.Rogers@glasgow.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Studying combinatorial patterns in cancer genomic datasets has recently emerged as a tool for identifying novel cancer driver networks.
	Approaches have been devised to quantify, for example, the tendency of a set of genes to be mutated in a 'mutually exclusive' manner.
	The significance of the proposed metrics is usually evaluated by computing P-values under appropriate null models.
	To this end, a Monte Carlo method (the switching-algorithm) is used to sample simulated datasets under a null model that preserves patient- and genewise mutation rates.
	In this method, a genomic dataset is represented as a bipartite network, to which Markov chain updates (switchingsteps) are applied.
	These steps modify the network topology, and a minimal number of them must be executed to draw simulated datasets independently under the null model.
	This number has previously been deducted empirically to be a linear function of the total number of variants, making this process computationally expensive.
	Results: We present a novel approximate lower bound for the number of switching-steps, derived analytically.
	Additionally, we have developed the R package BiRewire, including new efficient implementations of the switching-algorithm.
	We illustrate the performances of BiRewire by applying it to large real cancer genomics datasets.
	We report vast reductions in time requirement, with respect to existing implementations/bounds and equivalent P-value computations.
	Thus, we propose BiRewire to study statistical properties in genomic datasets, and other data that can be modeled as bipartite networks.
	Availability and implementation: BiRewire is available on BioConductor at http://www.bioconductor.org/packages/2.13/bioc/html/BiRewire.html Contact: iorio@ebi.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	AmiGO is a web application that allows users to query, browse and visualize ontologies and related gene product annotation (association) data.
	AmiGO can be used online at the Gene Ontology (GO) website to access the data provided by the GO Consortium1; it can also be downloaded and installed to browse local ontologies and annotations.2 AmiGO is free open source software developed and maintained by the GO Consortium.
	Availability: http://amigo.geneontology.org Download: http:// sourceforge.net/projects/geneontology/Contact: sjcarbon@berkeleybop.org
	The NCBI Gene Expression Omnibus (GEO) represents the largest public repository of microarray data.
	However, finding data in GEO can be challenging.
	We have developed GEOmetadb in an attempt to make querying the GEO metadata both easier and more powerful.
	All GEO metadata records as well as the relationships between them are parsed and stored in a local MySQL database.
	A powerful, flexible web search interface with several convenient utilities provides query capabilities not available via NCBI tools.
	In addition, a Bioconductor package, GEOmetadb that utilizes a SQLite export of the entire GEOmetadb database is also available, rendering the entire GEO database accessible with full power of SQL-based queries from within R. Availability: The web interface and SQLite databases available at http://gbnci.abcc.ncifcrf.gov/geo/.
	The Bioconductor package is available via the Bioconductor project.
	The corresponding MATLAB implementation is also available at the same website.
	Contact: yidong@mail.nih.gov
	Motivation: After more than a decade since microarrays were used to predict phenotype of biological samples, real-life applications for disease screening and identification of patients who would best benefit from treatment are still emerging.
	The interest of the scientific community in identifying best approaches to develop such prediction models was reaffirmed in a competition style international collaboration called IMPROVER Diagnostic Signature Challenge whose results we describe herein.
	Results: Fifty-four teams used public data to develop prediction models in four disease areas including multiple sclerosis, lung cancer, psoriasis and chronic obstructive pulmonary disease, and made predictions on blinded new data that we generated.
	Teams were scored using three metrics that captured various aspects of the quality of predictions, and best performers were awarded.
	This article presents the challenge results and introduces to the community the approaches of the best overall three performers, as well as an R package that implements the approach of the best overall team.
	The analyses of model performance data submitted in the challenge as well as additional simulations that we have performed revealed that (i) the quality of predictions depends more on the disease endpoint than on the particular approaches used in the challenge; (ii) the most important modeling factor (e.g.
	data preprocessing, feature selection and classifier type) is problem dependent; and (iii) for optimal results datasets and methods have to be carefully matched.
	Biomedical factors such as the disease severity and confidence in diagnostic were found to be associated with the misclassification rates across the different teams.
	Availability: The lung cancer dataset is available from Gene Expression Omnibus (accession, GSE43580).
	The maPredictDSC R package implementing the approach of the best overall team is available at www.
	bioconductor.org or http://bioinformaticsprb.med.wayne.edu/.Contact: gustavo@us.ibm.com
	Summary: The MAGE-TAB format for microarray data representation and exchange has been proposed by the microarray community to replace the more complex MAGE-ML format.
	We present a suite of tools to support MAGE-TAB generation and validation, conversion between existing formats for data exchange, visualization of the experiment designs encoded by MAGE-TAB documents and the mining of such documents for semantic content.
	Availability: Software is available from http://tab2mage.sourceforge.net/ Contact: tfrayner@gmail.com
	Summary: The assessment of data quality is a major concern in microarray analysis.
	arrayQualityMetrics is a Bioconductor package that provides a report with diagnostic plots for one or two colour microarray data.
	The quality metrics assess reproducibility, identify apparent outlier arrays and compute measures of signal-to-noise ratio.
	The tool handles most current microarray technologies and is amenable to use in automated analysis pipelines or for automatic report generation, as well as for use by individuals.
	The diagnosis of quality remains, in principle, a context-dependent judgement, but our tool provides powerful, automated, objective and comprehensive instruments on which to base a decision.
	Availability: arrayQualityMetrics is a free and open source package, under LGPL license, available from the Bioconductor project at www.bioconductor.org.
	A users guide and examples are provided with the package.
	Some examples of HTML reports generated by arrayQualityMetrics can be found at http://www.microarrayquality.org Contact: audrey@ebi.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Genome-scale metabolic models have been used extensively to investigate alterations in cellular metabolism.
	The accuracy of these models to represent cellular metabolism in specific conditions has been improved by constraining the model with omics data sources.
	However, few practical methods for integrating metabolomics data with other omics data sources into genome-scale models of metabolism have been developed.
	Results: GIM3E (Gene Inactivation Moderated by Metabolism, Metabolomics and Expression) is an algorithm that enables the development of condition-specific models based on an objective function, transcriptomics and cellular metabolomics data.
	GIM3E establishes metabolite use requirements with metabolomics data, uses modelpaired transcriptomics data to find experimentally supported solutions and provides calculations of the turnover (production/consumption) flux of metabolites.
	GIM3E was used to investigate the effects of integrating additional omics datasets to create increasingly constrained solution spaces of Salmonella Typhimurium metabolism during growth in both rich and virulence media.
	This integration proved to be informative and resulted in a requirement of additional active reactions (12 in each case) or metabolites (26 or 29, respectively).
	The addition of constraints from transcriptomics also impacted the allowed solution space, and the cellular metabolites with turnover fluxes that were necessarily altered by the change in conditions increased from 118 to 271 of 1397.
	Availability: GIM3E has been implemented in Python and requires a COBRApy 0.2.x.
	The algorithm and sample data described here are freely available at: http://opencobra.sourceforge.net/Contacts: brianjamesschmidt@gmail.com or hyduke@usu.edu Supplementary information: Supplementary information is available at Bioinformatics online.
	Motivation: Easily visualization of complex data features is a necessary step to conduct studies on next-generation sequencing (NGS) data.
	We developed STAR, an integrated web application that enables online management, visualization and track-based analysis of NGS data.
	Results: STAR is a multilayer web service system.
	On the client side, STAR leverages JavaScript, HTML5 Canvas and asynchronous communications to deliver a smoothly scrolling desktop-like graphical user interface with a suite of in-browser analysis tools that range from providing simple track configuration controls to sophisticated feature detection within datasets.
	On the server side, STAR supports private session state retention via an account management system and provides data management modules that enable collection, visualization and analysis of third-party sequencing data from the public domain with over thousands of tracks hosted to date.
	Overall, STAR represents a next-generation data exploration solution to match the requirements of NGS data, enabling both intuitive visualization and dynamic analysis of data.
	Availability and implementation: STAR browser system is freely available on the web at http://wanglab.ucsd.edu/star/browser and https://github.com/angell1117/STAR-genome-browser.Contact: wei-wang@ucsd.edu
	Motivation: The accurate detection of copy number alterations (CNAs) in human genomes is important for understanding susceptibility to cancer and mechanisms of tumor progression.
	CNA detection in tumors from single nucleotide polymorphism (SNP) genotyping arrays is a challenging problem due to phenomena such as aneuploidy, stromal contamination, genomic waves and intra-tumor heterogeneity, issues that leading methods do not optimally address.
	Results: Here we introduce methods and software (PennCNV-tumor) for fast and accurate CNA detection using signal intensity data from SNP genotyping arrays.
	We estimate stromal contamination by applying a maximum likelihood approach over multiple discrete genomic intervals.
	By conditioning on signal intensity across the genome, our method accounts for both aneuploidy and genomic waves.
	Finally, our method uses a hidden Markov model to integrate multiple sources of information, including total and allele-specific signal intensity at each SNP, as well as physical maps to make posterior inferences of CNAs.
	Using real data from cancer cell-lines and patient tumors, we demonstrate substantial improvements in accuracy and computational efficiency compared with existing methods.
	Availability: Source code, documentation and example datasets are freely available at http://sourceforge.net/projects/penncnv-2.Contact: gary.k.chen@usc.edu or kaichop@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The biological significance of genomic features is often context dependent.
	Annotating a particular dataset with existing external data can provide insight into function.
	Results: We present CruzDB, a fast and intuitive programmatic interface to the University of California, Santa Cruz (UCSC) genome browser that facilitates integrative analyses of diverse local and remotely hosted datasets.
	We showcase the syntax of CruzDB using microRNA binding sites as examples, and further demonstrate its utility with three biological discoveries.
	First, DNA replication timing is stratified in gene regions-exons tend to replicate early and introns late during S phase.
	Second, several non-coding variants associated with cognitive functions map to lincRNA transcripts of relevant function, suggesting potential function of these regulatory RNAs in neuronal diseases.
	Third, lamina-associated genomic regions are highly enriched in olfaction-related genes, indicating a role of nuclear organization in their regulation.
	Availability: CruzDB is available at https://github.com/brentp/cruzdb under the MIT open-source license.
	Contact: bpederse@gmail.com or subhajyoti.de@ucdenver.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Imaging mass spectrometry (IMS) is a maturating technique of molecular imaging.
	Confidence in the reproducible quality of IMS data is essential for its integration into routine use.
	However, the predominant method for assessing quality is visual examination, a time consuming, unstandardized and non-scalable approach.
	So far, the problem of assessing the quality has only been marginally addressed and existing measures do not account for the spatial information of IMS data.
	Importantly, no approach exists for unbiased evaluation of potential quality measures.
	Results: We propose a novel approach for evaluating potential measures by creating a goldstandard set using collective expert judgements upon which we evaluated image-based measures.
	To produce a gold standard, we engaged 80 IMS experts, each to rate the relative quality between 52 pairs of ion images from MALDI-TOF IMS datasets of rat brain coronal sections.
	Experts' optional feedback on their expertise, the task and the survey showed that (i) they had diverse backgrounds and sufficient expertise, (ii) the task was properly understood, and (iii) the survey was comprehensible.
	A moderate inter-rater agreement was achieved with Krippendorff's alpha of 0.5.
	A gold-standard set of 634 pairs of images with accompanying ratings was constructed and showed a high agreement of 0.85.
	Eight families of potential measures with a range of parameters and statistical descriptors, giving 143 in total, were evaluated.
	Both signal-to-noise and spatial chaos-based measures performed highly with a correlation of 0.7 to 0.9 with the gold standard ratings.
	Moreover, we showed that a composite measure with the linear coefficients (trained on the gold standard with regularized least squares optimization and lasso) showed a strong linear correlation of 0.94 and an accuracy of 0.98 in predicting which image in a pair was of higher quality.
	Availability and implementation: The anonymized data collected from the survey and the Matlab source code for data processing can be found at: https://github.com/alexandrovteam/IMS_quality.Contact: theodore.alexandrov@embl.de
	Motivation: The interactions between microbial colonies through chemical signaling are not well understood.
	A microbial colony can use different molecules to inhibit or accelerate the growth of other colonies.
	A better understanding of the molecules involved in these interactions could lead to advancements in health and medicine.
	Imaging mass spectrometry (IMS) applied to co-cultured microbial communities aims to capture the spatial characteristics of the colonies' molecular fingerprints.
	These data are high-dimensional and require computational analysis methods to interpret.
	Results: Here, we present a dictionary learning method that deconvolves spectra of different molecules from IMS data.
	We call this method MOLecular Dictionary Learning (MOLDL).
	Unlike standard dictionary learning methods which assume Gaussian-distributed data, our method uses the Poisson distribution to capture the count nature of the mass spectrometry data.
	Also, our method incorporates universally applicable information on common ion types of molecules in MALDI mass spectrometry.
	This greatly reduces model parameterization and increases deconvolution accuracy by eliminating spurious solutions.
	Moreover, our method leverages the spatial nature of IMS data by assuming that nearby locations share similar abundances, thus avoiding overfitting to noise.
	Tests on simulated datasets show that this method has good performance in recovering molecule dictionaries.
	We also tested our method on real data measured on a microbial community composed of two species.
	We confirmed through follow-up validation experiments that our method recovered true and complete signatures of molecules.
	These results indicate that our method can discover molecules in IMS data reliably, and hence can help advance the study of interaction of microbial colonies.
	Availability and implementation: The code used in this paper is available at: https://github.com/friz fealer/IMS_project.
	Contact: vjojic@cs.unc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Inferring structural dependencies among a protein's side chains helps us understand their coupled motions.
	It is known that coupled fluctuations can reveal pathways of communication used for information propagation in a molecule.
	Side-chain conformations are commonly represented by multivariate angular variables, but existing partial correlation methods that can be applied to this inference task are not capable of handling multivariate angular data.
	We propose a novel method to infer direct couplings from this type of data, and show that this method is useful for identifying functional regions and their interactions in allosteric proteins.
	Results: We developed a novel extension of canonical correlation analysis (CCA), which we call 'kernelized partial CCA' (or simply KPCCA), and used it to infer direct couplings between side chains, while disentangling these couplings from indirect ones.
	Using the conformational information and fluctuations of the inactive structure alone for allosteric proteins in the Ras and other Raslike families, our method identified allosterically important residues not only as strongly coupled ones but also in densely connected regions of the interaction graph formed by the inferred couplings.
	Our results were in good agreement with other empirical findings.
	By studying distinct members of the Ras, Rho and Rab sub-families, we show further that KPCCA was capable of inferring common allosteric characteristics in the small G protein super-family.
	Availability and implementation: https://github.com/lsgh/ismb15 Contact: lsoltang@uwaterloo.ca
	Motivation: The estimation of species phylogenies requires multiple loci, since different loci can have different trees due to incomplete lineage sorting, modeled by the multi-species coalescent model.
	We recently developed a coalescent-based method, ASTRAL, which is statistically consistent under the multi-species coalescent model and which is more accurate than other coalescentbased methods on the datasets we examined.
	ASTRAL runs in polynomial time, by constraining the search space using a set of allowed 'bipartitions'.
	Despite the limitation to allowed bipartitions, ASTRAL is statistically consistent.
	Results: We present a new version of ASTRAL, which we call ASTRAL-II.
	We show that ASTRAL-II has substantial advantages over ASTRAL: it is faster, can analyze much larger datasets (up to 1000 species and 1000 genes) and has substantially better accuracy under some conditions.
	ASTRAL's running time is OÃ°n2k jX j2Ãž, and ASTRAL-II's running time is OÃ°nk jX j2Ãž, where n is the number of species, k is the number of loci and X is the set of allowed bipartitions for the search space.
	Availability and implementation: ASTRAL-II is available in open source at https://github.com/smirarab/ASTRAL and datasets used are available at http://www.cs.utexas.edu/~phylo/datasets/astral2/.Contact: smirarab@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: KEGG PATHWAY is a service of Kyoto Encyclopedia of Genes and Genomes (KEGG), constructing manually curated pathway maps that represent current knowledge on biological networks in graph models.
	While valuable graph tools have been implemented in R/Bioconductor, to our knowledge there is currently no software package to parse and analyze KEGG pathways with graph theory.
	Results: We introduce the software package KEGGgraph in R and Bioconductor, an interface between KEGG pathways and graph models as well as a collection of tools for these graphs.
	Superior to existing approaches, KEGGgraph captures the pathway topology and allows further analysis or dissection of pathway graphs.
	We demonstrate the use of the package by the case study of analyzing human pancreatic cancer pathway.
	Availability: KEGGgraph is freely available at the Bioconductor web site (http://www.bioconductor.org).
	KGML files can be downloaded from KEGG FTP site (ftp://ftp.genome.jp/pub/kegg/xml).
	Contact: j.zhang@dkfz-heidelberg.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Top scoring pairs (TSPs) are pairs of genes whose relative rankings can be used to accurately classify individuals into one of two classes.
	TSPs have two main advantages over many standard classifiers used in gene expression studies: (i) a TSP is based on only two genes, which leads to easily interpretable and inexpensive diagnostic tests and (ii) TSP classifiers are based on gene rankings, so they are more robust to variation in technical factors or normalization than classifiers based on expression levels of individual genes.
	Here I describe the R package, tspair, which can be used to quickly identify and assess TSP classifiers for gene expression data.
	Availability: The R package tspair is freely available from Bioconductor: http://www.bioconductor.org Contact: jtleek@jhu.edu
	Motivation: The increasing throughput of sequencing technologies offers new applications and challenges for computational biology.
	In many of those applications, sequencing errors need to be corrected.
	This is particularly important when sequencing reads from an unknown reference such as random DNA barcodes.
	In this case, error correction can be done by performing a pairwise comparison of all the barcodes, which is a computationally complex problem.
	Results: Here, we address this challenge and describe an exact algorithm to determine which pairs of sequences lie within a given Levenshtein distance.
	For error correction or redundancy reduction purposes, matched pairs are then merged into clusters of similar sequences.
	The efficiency of starcode is attributable to the poucet search, a novel implementation of the Needleman-Wunsch algorithm performed on the nodes of a trie.
	On the task of matching random barcodes, starcode outperforms sequence clustering algorithms in both speed and precision.
	Availability and implementation: The C source code is available at http://github.com/gui11aume/starcode.
	Contact: guillaume.filion@gmail.com
	Motivation: Although R packages exist for the pre-processing of metabolomic data, they currently do not incorporate additional analysis steps of summarization, filtering and normalization of aligned data.
	We developed the MSPrep R package to complement other packages by providing these additional steps, implementing a selection of popular normalization algorithms and generating diagnostics to help guide investigators in their analyses.
	Availability: http://www.sourceforge.net/projects/msprep Contact: grant.hughes@ucdenver.edu Supplementary Information: Supplementary materials are available at Bioinformatics online.
	The Illumina Infinium HumanMethylation450 BeadChip is a new platform for high-throughput DNA methylation analysis.
	Several methods for normalization and processing of these data have been published recently.
	Here we present an integrated analysis pipeline offering a choice of the most popular normalization methods while also introducing new methods for calling differentially methylated regions and detecting copy number aberrations.
	Availability and implementation: ChAMP is implemented as a Bioconductor package in R. The package and the vignette can be downloaded at bioconductor.org Contact: tiffany.morris@ucl.ac.uk
	Motivation: The widespread adoption of RNA-seq to quantitatively measure gene expression has increased the scope of sequencing experimental designs to include time-course experiments.
	maSigPro is an R package specifically suited for the analysis of time-course gene expression data, which was developed originally for microarrays and hence was limited in its application to count data.
	Results: We have updated maSigPro to support RNA-seq time series analysis by introducing generalized linear models in the algorithm to support the modeling of count data while maintaining the traditional functionalities of the package.
	We show a good performance of the maSigPro-GLM method in several simulated time-course scenarios and in a real experimental dataset.
	Availability and implementation: The package is freely available under the LGPL license from the Bioconductor Web site (http://bioconductor.org).
	Contact: mj.nueda@ua.es or aconesa@cipf.es
	Summary: TrioVis is a visual analytics tool developed for filtering on coverage and variant frequency for genomic variants from exome sequencing of parent-child trios.
	In TrioVis, the variant data are organized by grouping each variant based on the laws of Mendelian inheritance.
	Taking three Variant Call Format files as input, TrioVis allows the user to test different coverage thresholds (i.e.
	different levels of stringency), to find the optimal threshold values tailored to their hypotheses and to gain insights into the global effects of filtering through interaction.
	Availability: Executables, source code and sample data are available at https://bitbucket.org/biovizleuven/triovis.
	Screencast is available at http://vimeo.com/user6757771/triovis.Contact: ryo.sakai@esat.kuleuven.be
	Motivation: High-throughput ChIP-seq studies typically identify thousands of peaks for a single transcription factor (TF).
	It is common for traditional motif discovery tools to predict motifs that are statistically significant against a naÄ±Â¨ve background distribution but are of questionable biological relevance.
	Results: We describe a simple yet effective algorithm for discovering differential motifs between two sequence datasets that is effective in eliminating systematic biases and scalable to large datasets.
	Tested on 207 ENCODE ChIP-seq datasets, our method identifies correct motifs in 78% of the datasets with known motifs, demonstrating improvement in both accuracy and efficiency compared with DREME, another state-of-art discriminative motif discovery tool.
	More interestingly, on the remaining more challenging datasets, we identify common technical or biological factors that compromise the motif search results and use advanced features of our tool to control for these factors.
	We also present case studies demonstrating the ability of our method to detect single base pair differences in DNA specificity of two similar TFs.
	Lastly, we demonstrate discovery of key TF motifs involved in tissue specification by examination of high-throughput DNase accessibility data.
	Availability: The motifRG package is publically available via the bioconductor repository.
	Contact: yzizhen@fhcrc.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Inferring lengths of inherited microsatellite alleles with single base pair resolution from short sequence reads is challenging due to several sources of noise caused by the repetitive nature of microsatellites and the technologies used to generate raw sequence data.
	Results: We have developed a program, GenoTan, using a discretized Gaussian mixture model combined with a rules-based approach to identify inherited variation of microsatellite loci from short sequence reads without paired-end information.
	It effectively distinguishes length variants from noise including insertion/deletion errors in homopolymer runs by addressing the bidirectional aspect of insertion and deletion errors in sequence reads.
	Here we first introduce a homopolymer decomposition method which estimates error bias toward insertion or deletion in homopolymer sequence runs.
	Combining these approaches, GenoTan was able to genotype 94.9% of microsatellite loci accurately from simulated data with 40x sequence coverage quickly while the other programs showed 590% correct calls for the same data and required 5 30 more computational time than GenoTan.
	It also showed the highest true-positive rate for real data using mixed sequence data of two Drosophila inbred lines, which was a novel validation approach for genotyping.
	Availability: GenoTan is open-source software available at http://gen otan.sourceforge.net.
	Contact: garner@vbi.vt.edu Supplementary Information: Supplementary data are available at Bioinformatics online
	Summary: The rtracklayer package supports the integration of existing genome browsers with experimental data analyses performed in R. The user may (i) transfer annotation tracks to and from a genome browser and (ii) create and manipulate browser views to focus on a particular set of annotations in a specific genomic region.
	Currently, the UCSC genome browser is supported.
	Availability: The package is freely available from http://www.bioconductor.org/.
	A quick-start vignette is included with the package.
	Contact: mflawren@fhcrc.org
	Motivation: The use of liquid chromatography coupled to mass spectrometry has enabled the high-throughput profiling of the metabolite composition of biological samples.
	However, the large amount of data obtained can be difficult to analyse and often requires computational processing to understand which metabolites are present in a sample.
	This article looks at the dual problem of annotating peaks in a sample with a metabolite, together with putatively annotating whether a metabolite is present in the sample.
	The starting point of the approach is a Bayesian clustering of peaks into groups, each corresponding to putative adducts and isotopes of a single metabolite.
	Results: The Bayesian modelling introduced here combines information from the mass-to-charge ratio, retention time and intensity of each peak, together with a model of the inter-peak dependency structure, to increase the accuracy of peak annotation.
	The results inherently contain a quantitative estimate of confidence in the peak annotations and allow an accurate trade-off between precision and recall.
	Extensive validation experiments using authentic chemical standards show that this system is able to produce more accurate putative identifications than other state-of-the-art systems, while at the same time giving a probabilistic measure of confidence in the annotations.
	Availability and implementation: The software has been implemented as part of the mzMatch metabolomics analysis pipeline, which is available for download at http://mzmatch.sourceforge.net/.Contact: Ronan.Daly@glasgow.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Interpretation and communication of genomic data require flexible and quantitative tools to analyze and visualize diverse data types, and yet, a comprehensive tool to display all common genomic data types in publication quality figures does not exist to date.
	To address this shortcoming, we present Sushi.R, an R/Bioconductor package that allows flexible integration of genomic visualizations into highly customizable, publication-ready, multi-panel figures from common genomic data formats including Browser Extensible Data (BED), bedGraph and Browser Extensible Data Paired-End (BEDPE).
	Sushi.R is open source and made publicly available through GitHub (https://github.com/dphansti/Sushi) and Bioconductor (http://bioconductor.org/packages/release/bioc/html/Sushi.html).
	Contact: mpsnyder@stanford.edu or dphansti@stanford.edu
	Summary: The Sequence Alignment/Map (SAM) format is a generic alignment format for storing read alignments against reference sequences, supporting short and long reads (up to 128 Mbp) produced by different sequencing platforms.
	It is flexible in style, compact in size, efficient in random access and is the format in which alignments from the 1000 Genomes Project are released.
	SAMtools implements various utilities for post-processing alignments in the SAM format, such as indexing, variant caller and alignment viewer, and thus provides universal tools for processing read alignments.
	Availability: http://samtools.sourceforge.net Contact: rd@sanger.ac.uk
	Motivation: Reference genome assemblies are subject to change and refinement from time to time.
	Generally, researchers need to convert the results that have been analyzed according to old assemblies to newer versions, or vice versa, to facilitate meta-analysis, direct comparison, data integration and visualization.
	Several useful conversion tools can convert genome interval files in browser extensible data or general feature format, but none have the functionality to convert files in sequence alignment map or BigWig format.
	This is a significant gap in computational genomics tools, as these formats are the ones most widely used for representing high-throughput sequencing data, such as RNA-seq, chromatin immunoprecipitation sequencing, DNA-seq, etc.
	Results: Here we developed CrossMap, a versatile and efficient tool for converting genome coordinates between assemblies.
	CrossMap supports most of the commonly used file formats, including BAM, sequence alignment map, Wiggle, BigWig, browser extensible data, general feature format, gene transfer format and variant call format.
	Availability and implementation: CrossMap is written in Python and C. Source code and a comprehensive user's manual are freely available at: http://crossmap.sourceforge.net/.Contact: Kocher.JeanPierre@mayo.edu or wang.liguo@mayo.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Due to the availability of new sequencing technologies, we are now increasingly interested in sequencing closely related strains of existing finished genomes.
	Recently a number of de novo and mapping-based assemblers have been developed to produce high quality draft genomes from new sequencing technology reads.
	New tools are necessary to take contigs from a draft assembly through to a fully contiguated genome sequence.
	ABACAS is intended as a tool to rapidly contiguate (align, order, orientate), visualize and design primers to close gaps on shotgun assembled contigs based on a reference sequence.
	The input to ABACAS is a set of contigs which will be aligned to the reference genome, ordered and orientated, visualized in the ACT comparative browser, and optimal primer sequences are automatically generated.
	Availability and Implementation: ABACAS is implemented in Perl and is freely available for download from http://abacas.sourceforge.net Contact: sa4@sanger.ac.uk
	Motivation: The creation and exchange of biologically relevant models is of great interest to many researchers.
	When multiple standards are in use, models are more readily used and re-used if there exist robust translators between the various accepted formats.
	Summary: Antimony 2.4 and JSim 2.10 provide translation capabilities from their own formats to SBML and CellML.
	All provided unique challenges, stemming from differences in each format's inherent design, in addition to differences in functionality.
	Availability and implementation: Both programs are available under BSD licenses; Antimony from http://antimony.sourceforge.net/ and JSim from http://physiome.org/jsim/.Contact: lpsmith@u.washington.edu
	Summary: ArrayExpress is one of the largest public repositories of microarray datasets.
	R/Bioconductor provides a comprehensive suite of microarray analysis and integrative bioinformatics software.
	However, easy ways for importing datasets from ArrayExpress into R/Bioconductor have been lacking.
	Here, we present such a tool that is suitable for both interactive and automated use.
	Availability: The ArrayExpress package is available from the Bioconductor project at http://www.bioconductor.org.
	A users guide and examples are provided with the package.
	Contact: audrey@ebi.ac.uk Supplementary information: Supplementary data are available Bioinformatics online.
	Summary: The ProteoWizard software project provides a modular and extensible set of open-source, cross-platform tools and libraries.
	The tools perform proteomics data analyses; the libraries enable rapid tool creation by providing a robust, pluggable development framework that simplifies and unifies data file access, and performs standard proteomics and LCMS dataset computations.
	The library contains readers and writers of the mzML data format, which has been written using modern C++ techniques and design principles and supports a variety of platforms with native compilers.
	The software has been specifically released under the Apache v2 license to ensure it can be used in both academic and commercial projects.
	In addition to the library, we also introduce a rapidly growing set of companion tools whose implementation helps to illustrate the simplicity of developing applications on top of the ProteoWizard library.
	Availability: Cross-platform software that compiles using native compilers (i.e.
	GCC on Linux, MSVC on Windows and XCode on OSX) is available for download free of charge, at http://proteowizard.sourceforge.net.
	This website also provides code examples, and documentation.
	It is our hope the ProteoWizard project will become a standard platform for proteomics development; consequently, code use, contribution and further development are strongly encouraged.
	Contact: darren@proteowizard.org; parag@ucla.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Microsatellite instability (MSI) is an important indicator of larger genome instability and has been linked to many genetic diseases, including Lynch syndrome.
	MSI status is also an independent prognostic factor for favorable survival in multiple cancer types, such as colorectal and endometrial.
	It also informs the choice of chemotherapeutic agents.
	However, the current PCR-electrophoresis-based detection procedure is laborious and time-consuming, often requiring visual inspection to categorize samples.
	We developed MSIsensor, a CÃ¾Ã¾ program for automatically detecting somatic microsatellite changes.
	It computes length distributions of microsatellites per site in paired tumor and normal sequence data, subsequently using these to statistically compare observed distributions in both samples.
	Comprehensive testing indicates MSIsensor is an efficient and effective tool for deriving MSI status from standard tumor-normal paired sequence data.
	Availability and implementation: https://github.com/ding-lab/msisensor Contact: kye@genome.wustl.edu or lding@genome.wustl.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Identifying somatic changes from tumor and matched normal sequences has become a standard approach in cancer research.
	More specifically, this requires accurate detection of somatic point mutations with low allele frequencies in impure and heterogeneous cancer samples.
	Although haplotype phasing information derived by using heterozygous germ line variants near candidate mutations would improve accuracy, no somatic mutation caller that uses such information is currently available.
	Results: We propose a Bayesian hierarchical method, termed HapMuC, in which power is increased by using available information on heterozygous germ line variants located near candidate mutations.
	We first constructed two generative models (the mutation model and the error model).
	In the generative models, we prepared candidate haplotypes, considering a heterozygous germ line variant if available, and the observed reads were realigned to the haplotypes.
	We then inferred the haplotype frequencies and computed the marginal likelihoods using a variational Bayesian algorithm.
	Finally, we derived a Bayes factor for evaluating the possibility of the existence of somatic mutations.
	We also demonstrated that our algorithm has superior specificity and sensitivity compared with existing methods, as determined based on a simulation, the TCGA Mutation Calling Benchmark 4 datasets and data from the COLO-829 cell line.
	Availability and implementation: The HapMuC source code is available from http://github.com/usuyama/hapmuc.Contact: imoto@ims.u-tokyo.ac.jp Supplementary information: Supplementary data are available at Bioinformatics online.
	HPG Aligner applies suffix arrays for DNA read mapping.
	This implementation produces a highly sensitive and extremely fast mapping of DNA reads that scales up almost linearly with read length.
	The approach presented here is faster (over 20 for long reads) and more sensitive (over 98% in a wide range of read lengths) than the current state-of-the-art mappers.
	HPG Aligner is not only an optimal alternative for current sequencers but also the only solution available to cope with longer reads and growing throughputs produced by forthcoming sequencing technologies.
	Availability and implementation: https://github.com/opencb/hpgaligner.
	Contact: jdopazo@cipf.es or imedina@ebi.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Prioritization of candidate genes emanating from large-scale screens requires integrated analyses at the genomics, molecular, network and structural biology levels.
	We have extended the Integrated Genome Browser (IGB) to facilitate these tasks.
	The graphical user interface greatly simplifies building disease networks and zooming in at atomic resolution to identify variations in molecular complexes that may affect molecular interactions in the context of genomic data.
	All results are summarized in genome tracks and can be visualized and analyzed at the transcript level.
	Availability and implementation: The MI Bundle is a plugin for the IGB.
	The plugin, help, video and tutorial are available at http://cru.genomics.iit.it/igbmibundle/ and https://github.com/CRUiit/igb-mibundle/wiki.
	The source code is released under the Apache License, Version 2.
	Contact: arnaud.ceol@iit.it Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Identifying subclonal mutations and their implications requires accurate estimation of mutant allele fractions from possibly duplicated sequencing reads.
	Removing duplicate reads assumes that polymerase chain reaction amplification from library constructions is the primary source.
	The alternative-sampling coincidence from DNA fragmentation-has not been systematically investigated.
	Results: With sufficiently high-sequencing depth, sampling-induced read duplication is non-negligible, and removing duplicate reads can overcorrect read counts, causing systemic biases in variant allele fraction and copy number variation estimations.
	Minimal overcorrection occurs when duplicate reads are identified accounting for their mate reads, inserts are of a variety of lengths and samples are sequenced in separate batches.
	We investigate sampling-induced read duplication in deep sequencing data with 500 to 2000 duplicates-removed sequence coverage.
	We provide a quantitative solution to overcorrection and guidance for effective designs of deep sequencing platforms that facilitate accurate estimation of variant allele fraction and copy number variation.
	Availability and implementation: A Python implementation is freely available at https://bitbucket.org/wanding/duprecover/overview.Contact: wzhou1@mdanderson.org, kchen3@mdanderson.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Metagenomic data, which contains sequenced DNA reads of uncultured microbial species from environmental samples, provide a unique opportunity to thoroughly analyze microbial species that have never been identified before.
	Reconstructing 16S ribosomal RNA, a phylogenetic marker gene, is usually required to analyze the composition of the metagenomic data.
	However, massive volume of dataset, high sequence similarity between related species, skewed microbial abundance and lack of reference genes make 16S rRNA reconstruction difficult.
	Generic de novo assembly tools are not optimized for assembling 16S rRNA genes.
	In this work, we introduce a targeted rRNA assembly tool, REAGO (REconstruct 16S ribosomal RNA Genes from metagenOmic data).
	It addresses the above challenges by combining secondary structure-aware homology search, zproperties of rRNA genes and de novo assembly.
	Our experimental results show that our tool can correctly recover more rRNA genes than several popular generic metagenomic assembly tools and specially designed rRNA construction tools.
	Availability and implementation: The source code of REAGO is freely available at https://github.com/chengyuan/reago.
	Contact: yannisun@msu.edu
	Summary: A typical prokaryote population sequencing study can now consist of hundreds or thousands of isolates.
	Interrogating these datasets can provide detailed insights into the genetic structure of prokaryotic genomes.
	We introduce Roary, a tool that rapidly builds large-scale pan genomes, identifying the core and accessory genes.
	Roary makes construction of the pan genome of thousands of prokaryote samples possible on a standard desktop without compromising on the accuracy of results.
	Using a single CPU Roary can produce a pan genome consisting of 1000 isolates in 4.5 hours using 13 GB of RAM, with further speedups possible using multiple processors.
	Availability and implementation: Roary is implemented in Perl and is freely available under an open source GPLv3 license from http://sanger-pathogens.github.io/Roary Contact: roary@sanger.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Next-generation sequencing technologies produce short reads that are either de novo assembled or mapped to a reference genome.
	Genotypes and/or single-nucleotide polymorphisms are then determined from the read composition at each site, which become the basis for many downstream analyses.
	However, for low sequencing depths, e.g.
	510 , there is considerable statistical uncertainty in the assignment of genotypes because of random sampling of homologous base pairs in heterozygotes and sequencing or alignment errors.
	Recently, several probabilistic methods have been proposed to account for this uncertainty and make accurate inferences from low quality and/or coverage sequencing data.
	We present ngsTools, a collection of programs to perform population genetics analyses from next-generation sequencing data.
	The methods implemented in these programs do not rely on single-nucleotide polymorphism or genotype calling and are particularly suitable for low sequencing depth data.
	Availability: Programs included in ngsTools are implemented in C/CÃ¾Ã¾ and are freely available for noncommercial use at https://github.com/mfumagalli/ngsTools.
	Contact: mfumagalli82@gmail.com Supplementary Information: Supplementary materials are available at Bioinformatics online.
	Summary: Mutational signatures are patterns in the occurrence of somatic single-nucleotide variants that can reflect underlying mutational processes.
	The SomaticSignatures package provides flexible, interoperable and easy-to-use tools that identify such signatures in cancer sequencing data.
	It facilitates large-scale, cross-dataset estimation of mutational signatures, implements existing methods for pattern decomposition, supports extension through user-defined approaches and integrates with existing Bioconductor workflows.
	Availability and implementation: The R package SomaticSignatures is available as part of the Bioconductor project.
	Its documentation provides additional details on the methods and demonstrates applications to biological datasets.
	Contact: julian.gehring@embl.de, whuber@embl.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Primary data analysis methods are of critical importance in second generation DNA sequencing.
	Improved methods have the potential to increase yield and reduce the error rates.
	Openly documented analysis tools enable the user to understand the primary data, this is important for the optimization and validity of their scientific work.
	Results: In this article, we describe Swift, a new tool for performing primary data analysis on the Illumina Solexa Sequencing Platform.
	Swift is the first tool, outside of the vendors own software, which completes the full analysis process, from raw images through to base calls.
	As such it provides an alternative to, and independent validation of, the vendor supplied tool.
	Our results show that Swift is able to increase yield by 13.8%, at comparable error rate.
	Availability and Implementation: Swift is implemented in C++ and supported under Linux.
	It is supplied under an open source license (LGPL3), allowing researchers to build upon the platform.
	Swift is available from http://swiftng.sourceforge.net.Contact: new@sgenomics.org; nava.whiteford@nanoporetech.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The recently released Infinium HumanMethylation450 array (the '450k' array) provides a high-throughput assay to quantify DNA methylation (DNAm) at 450 000 loci across a range of genomic features.
	Although less comprehensive than high-throughput sequencing-based techniques, this product is more cost-effective and promises to be the most widely used DNAm high-throughput measurement technology over the next several years.
	Results: Here we describe a suite of computational tools that incorporate state-of-the-art statistical techniques for the analysis of DNAm data.
	The software is structured to easily adapt to future versions of the technology.
	We include methods for preprocessing, quality assessment and detection of differentially methylated regions from the kilobase to the megabase scale.
	We show how our software provides a powerful and flexible development platform for future methods.
	We also illustrate how our methods empower the technology to make discoveries previously thought to be possible only with sequencingbased methods.
	Availability and implementation: http://bioconductor.org/packages/release/bioc/html/minfi.html.
	Contact: khansen@jhsph.edu; rafa@jimmy.harvard.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: ShortRead is a package for input, quality assessment, manipulation and output of high-throughput sequencing data.
	ShortRead is provided in the R and Bioconductor environments, allowing ready access to additional facilities for advanced statistical analysis, data transformation, visualization and integration with diverse genomic resources.
	Availability and Implementation: This package is implemented in R and available at the Bioconductor web site; the package contains a 'vignette' outlining typical work flows.
	Contact: mtmorgan@fhcrc.org
	Motivation: High throughput sequencing technologies generate large amounts of short reads.
	Mapping these to a reference sequence consumes large amounts of processing time and memory, and read mapping errors can lead to noisy or incorrect alignments.
	SNP-o-matic is a fast, memory-efficient and stringent read mapping tool offering a variety of analytical output functions, with an emphasis on genotyping.
	Availability: http://snpomatic.sourceforge.net Contact: mm6@sanger.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We present a significantly improved version of the flowType and RchyOptimyx BioConductor-based pipeline that is both 14 times faster and can accommodate multiple levels of biomarker expression for up to 96 markers.
	With these improvements, the pipeline is positioned to be an integral part of data analysis for high-throughput experiments on high-dimensional single-cell assay platforms, including flow cytometry, mass cytometry and single-cell RT-qPCR.
	Availability: FlowType and RchyOptimyx are distributed under the Artistic 2.0 license through Bioconductor.
	Contact: rbrinkman@bccrc.ca
	Motivation: There are various reasons for rerunning bioinformatics tools and pipelines on sequencing data, including reproducing a past result, validation of a new tool or workflow using a known dataset, or tracking the impact of database changes.
	For identical results to be achieved, regularly updated reference sequence databases must be versioned and archived.
	Database administrators have tried to fill the requirements by supplying users with one-off versions of databases, but these are time consuming to set up and are inconsistent across resources.
	Disk storage and data backup performance has also discouraged maintaining multiple versions of databases since databases such as NCBI nr can consume 50 Gb or more disk space per version, with growth rates that parallel Moore's law.
	Results: Our end-to-end solution combines our own Kipper software package-a simple key-value large file versioning system-with BioMAJ (software for downloading sequence databases), and Galaxy (a web-based bioinformatics data processing platform).
	Available versions of databases can be recalled and used by command-line and Galaxy users.
	The Kipper data store format makes publishing curated FASTA databases convenient since in most cases it can store a range of versions into a file marginally larger than the size of the latest version.
	Availability and implementation: Kipper v1.0.0 and the Galaxy Versioned Data tool are written in Python and released as free and open source software available at https://github.com/PublicHealth-Bioinformatics/kipper and https://github.com/Public-Health-Bioinformatics/versioned_data, respectively; detailed setup instructions can be found at https://github.com/Public-HealthBioinformatics/versioned_data/blob/master/doc/setup.md Contact: Damion.Dooley@Bccdc.Ca or William.Hsiao@Bccdc.Ca Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Gene therapy with retroviral vectors can induce adverse effects when those vectors integrate in sensitive genomic regions.
	Retroviral vectors are preferred that target sensitive regions less frequently, motivating the search for localized clusters of integration sites and comparison of the clusters formed by integration of different vectors.
	Scan statistics allow the discovery of spatial differences in clustering and calculation of false discovery rates providing statistical methods for comparing retroviral vectors.
	Results: A scan statistic for comparing two vectors using multiple window widths is proposed with software to detect clustering differentials and compute false discovery rates.
	Application to several sets of experimentally determined HIV integration sites demonstrates the software.
	Simulated datasets of various sizes and signal strengths are used to determine the power to discover clusters and evaluate a convenient lower bound.
	This provides a toolkit for planning evaluations of new gene therapy vectors.
	Availability and implementation: The geneRxCluster R package containing a simple tutorial and usage hints is available from http://www.bioconductor.org.
	Contact: ccberry@ucsd.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Collecting data from large studies on high-throughput platforms, such as microarray or next-generation sequencing, typically requires processing samples in batches.
	There are often systematic but unpredictable biases from batch-to-batch, so proper randomization of biologically relevant traits across batches is crucial for distinguishing true biological differences from experimental artifacts.
	When a large number of traits are biologically relevant, as is common for clinical studies of patients with varying sex, age, genotype and medical background, proper randomization can be extremely difficult to prepare by hand, especially because traits may affect biological inferences, such as differential expression, in a combinatorial manner.
	Here we present ARTS (automated randomization of multiple traits for study design), which aids researchers in study design by automatically optimizing batch assignment for any number of samples, any number of traits and any batch size.
	Availability and implementation: ARTS is implemented in Perl and is available at github.com/mmaiensc/ARTS.
	ARTS is also available in the Galaxy Tool Shed, and can be used at the Galaxy installation hosted by the UIC Center for Research Informatics (CRI) at galaxy.cri.uic.edu.
	Contact: mmaiensc@uic.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Hidden Markov models (HMMs) are probabilistic models that are well-suited to solve many different classification problems in computation biology.
	StochHMM provides a command-line program and CÃ¾Ã¾ library that can implement a traditional HMM from a simple text file.
	StochHMM provides researchers the flexibility to create higherorder emissions, integrate additional data sources and/or user-defined functions into multiple points within the HMM framework.
	Additional features include user-defined alphabets, ability to handle ambiguous characters in an emission-dependent manner, user-defined weighting of state paths and ability to tie transition probabilities to sequence.
	Availability and implementation: StochHMM is implemented in CÃ¾Ã¾ and is available under the MIT License.
	Software, source code, documentation and examples can be found at http://github.com/KorfLab/StochHMM.
	Contact: ifkorf@ucdavis.edu The Author 2014.
	Published by Oxford University Press.
	All rights reserved.
	For Permissions, please e-mail: journals.permissions@oup.com
	Summary: Experimental techniques that survey an entire genome demand flexible, highly interactive visualization tools that can display new data alongside foundation datasets, such as reference gene annotations.
	The Integrated Genome Browser (IGB) aims to meet this need.
	IGB is an open source, desktop graphical display tool implemented in Java that supports real-time zooming and panning through a genome; layout of genomic features and datasets in moveable, adjustable tiers; incremental or genome-scale data loading from remote web servers or local files; and dynamic manipulation of quantitative data via genome graphs.
	Availability: The application and source code are available from http://igb.bioviz.org and http://genoviz.sourceforge.net.Contact: aloraine@uncc.edu The IGB is implemented in Java and runs on any computer platform that supports Java version 1.6 or higher.
	Summary: Array-based comparative genomic hybridization (CGH) technology is used to discover and validate genomic structural variation, including copy number variants, insertions, deletions and other structural variants (SVs).
	The visualization and summarization of the array CGH data outputs, potentially across many samples, is an important process in the identification and analysis of SVs.
	We have developed a software tool for SV analysis using data from array CGH technologies, which is also amenable to short-read sequence data.
	Availability and implementation: SnoopCGH is written in java and is available from http://snoopcgh.sourceforge.net/Contact: jg10@sanger.ac.uk; tc5@sanger.ac.uk
	Summary: Ongoing advances in high-throughput technologies have facilitated accurate proteomic measurements and provide a wealth of information on genomic and transcript level.
	In proteogenomics, this multi-omics data is combined to analyze unannotated organisms and to allow more accurate sample-specific predictions.
	Existing analysis methods still mainly depend on six-frame translations or reference protein databases that are extended by transcriptomic information or known single nucleotide polymorphisms (SNPs).
	However, six-frames introduce an artificial sixfold increase of the target database and SNP integration requires a suitable database summarizing results from previous experiments.
	We overcome these limitations by introducing MSProGene, a new method for integrative proteogenomic analysis based on customized RNA-Seq driven transcript databases.
	MSProGene is independent from existing reference databases or annotated SNPs and avoids large six-frame translated databases by constructing sample-specific transcripts.
	In addition, it creates a network combining RNA-Seq and peptide information that is optimized by a maximum-flow algorithm.
	It thereby also allows resolving the ambiguity of shared peptides for protein inference.
	We applied MSProGene on three datasets and show that it facilitates a databaseindependent reliable yet accurate prediction on gene and protein level and additionally identifies novel genes.
	Availability and implementation: MSProGene is written in Java and Python.
	It is open source and available at http://sourceforge.net/projects/msprogene/.Contact: renardb@rki.de
	Purpose: PaxtoolsR package enables access to pathway data represented in the BioPAX format and made available through the Pathway Commons webservice for users of the R language to aid in advanced pathway analyses.
	Features include the extraction, merging and validation of pathway data represented in the BioPAX format.
	This package also provides novel pathway datasets and advanced querying features for R users through the Pathway Commons webservice allowing users to query, extract and retrieve data and integrate these data with local BioPAX datasets.
	Availability and implementation: The PaxtoolsR package is compatible with versions of R 3.1.1 (and higher) on Windows, Mac OS X and Linux using Bioconductor 3.0 and is available through the Bioconductor R package repository along with source code and a tutorial vignette describing common tasks, such as data visualization and gene set enrichment analysis.
	Source code and documentation are at http://www.bioconductor.org/packages/paxtoolsr.
	This plugin is free, open-source and licensed under the LGPL-3.
	Contact: paxtools@cbio.mskcc.org or lunaa@cbio.mskcc.org
	Summary: DNAshapeR predicts DNA shape features in an ultra-fast, high-throughput manner from genomic sequencing data.
	The package takes either nucleotide sequence or genomic coordinates as input and generates various graphical representations for visualization and further analysis.
	DNAshapeR further encodes DNA sequence and shape features as user-defined combinations of k-mer and DNA shape features.
	The resulting feature matrices can be readily used as input of various machine learning software packages for further modeling studies.
	Availability and implementation: The DNAshapeR software package was implemented in the statistical programming language R and is freely available through the Bioconductor project at https://www.bioconductor.org/packages/devel/bioc/html/DNAshapeR.html and at the GitHub developer site, http://tsupeichiu.github.io/DNAshapeR/.Contact: rohs@usc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: The lack of visualization frameworks to guide interpretation and facilitate discovery is a potential bottleneck for precision medicine, systems genetics and other studies.
	To address this we have developed an interactive, reproducible, web-based prioritization approach that builds on our earlier work.
	HitWalker2 is highly flexible and can utilize many data types and prioritization methods based upon available data and desired questions, allowing it to be utilized in a diverse range of studies such as cancer, infectious disease and psychiatric disorders.
	Availability and implementation: Source code is freely available at https://github.com/biodev/HitWalker2 and implemented using Python/Django, Neo4j and Javascript (D3.js and jQuery).
	We support major open source browsers (e.g.
	Firefox and Chromium/Chrome).
	Contact: wilmotb@ohsu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Additional information/instructions are available at https://github.com/biodev/HitWalker2/wiki
	Motivation: Identifying regulatory elements is a fundamental problem in the field of gene transcription.
	Motif discovery-the task of identifying the sequence preference of transcription factor proteins, which bind to these elements-is an important step in this challenge.
	MEME is a popular motif discovery algorithm.
	Unfortunately, MEME's running time scales poorly with the size of the dataset.
	Experiments such as ChIP-Seq and DNase-Seq are providing a rich amount of information on the binding preference of transcription factors.
	MEME cannot discover motifs in data from these experiments in a practical amount of time without a compromising strategy such as discarding a majority of the sequences.
	Results: We present EXTREME, a motif discovery algorithm designed to find DNA-binding motifs in ChIP-Seq and DNase-Seq data.
	Unlike MEME, which uses the expectation-maximization algorithm for motif discovery, EXTREME uses the online expectation-maximization algorithm to discover motifs.
	EXTREME can discover motifs in large datasets in a practical amount of time without discarding any sequences.
	Using EXTREME on ChIP-Seq and DNase-Seq data, we discover many motifs, including some novel and infrequent motifs that can only be discovered by using the entire dataset.
	Conservation analysis of one of these novel infrequent motifs confirms that it is evolutionarily conserved and possibly functional.
	Availability and implementation: All source code is available at the Github repository http://github.com/uci-cbcl/EXTREME.Contact: xhx@ics.uci.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Saint is a web application which provides a lightweight annotation integration environment for quantitative biological models.
	The system enables modellers to rapidly mark up models with biological information derived from a range of data sources.
	Availability and Implementation: Saint is freely available for use on the web at http://www.cisban.ac.uk/saint.
	The web application is implemented in Google Web Toolkit and Tomcat, with all major browsers supported.
	The Java source code is freely available for download at http://saint-annotate.sourceforge.net.
	The Saint web server requires an installation of libSBML and has been tested on Linux (32-bit Ubuntu 8.10 and 9.04).
	Contact: helpdesk@cisban.ac.uk; a.l.lister@ncl.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Hidden Markov models (HMMs) are flexible and widely used in scientific studies.
	Particularly in genomics and genetics, there are multiple distinct regimes in the genome within each of which the relationships among multivariate features are distinct.
	Examples include differential gene regulation depending on gene functions and experimental conditions, and varying combinatorial patterns of multiple transcription factors.
	We developed a software package called MRHMMs (Multivariate Regression Hidden Markov Models and the variantS) that accommodates a variety of HMMs that can be flexibly applied to many biological studies and beyond.
	MRHMMs supplements existing HMM software packages in two aspects.
	First, MRHMMs provides a diverse set of emission probability structures, including mixture of multivariate normal distributions and (logistic) regression models.
	Second, MRHMMs is computationally efficient for analyzing large data-sets generated in current genome-wide studies.
	Especially, the software is written in C for the speed advantage and further amenable to implement alternative models to meet users' own purposes.
	Availability and implementation: http://sourceforge.net/projects/mrhmms/ Contact: ghoshd@psu.edu or yuzhang@stat.psu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Quantitative real-time polymerase chain reaction (qPCR) is routinely used for RNA expression profiling, validation of microarray hybridization data and clinical diagnostic assays.
	Although numerous statistical tools are available in the public domain for the analysis of microarray experiments, this is not the case for qPCR.
	Proprietary software is typically provided by instrument manufacturers, but these solutions are not amenable to the tandem analysis of multiple assays.
	This is problematic when an experiment involves more than a simple comparison between a control and treatment sample, or when many qPCR datasets are to be analyzed in a high-throughput facility.
	Results: We have developed HTqPCR, a package for the R statistical computing environment, to enable the processing and analysis of qPCR data across multiple conditions and replicates.
	Availability: HTqPCR and user documentation can be obtained through Bioconductor or at http://www.ebi.ac.uk/bertone/software.Contact: bertone@ebi.ac.uk
	Summary: Genome-scale metabolic models often lack annotations that would allow them to be used for further analysis.
	Previous efforts have focused on associating metabolites in the model with a cross reference, but this can be problematic if the reference is not freely available, multiple resources are used or the metabolite is added from a literature review.
	Associating each metabolite with chemical structure provides unambiguous identification of the components and a more detailed view of the metabolism.
	We have developed an open-source desktop application that simplifies the process of adding database cross references and chemical structures to genome-scale metabolic models.
	Annotated models can be exported to the Systems Biology Markup Language open interchange format.
	Availability: Source code, binaries, documentation and tutorials are freely available at http://johnmay.github.com/metingear.
	The application is implemented in Java with bundles available for MS Windows and Macintosh OS X.
	Contact: johnmay@ebi.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We provide a new statistical algorithm and software package called 'eigen-R2' for dissecting the variation of a highdimensional biological dataset with respect to other measured variables of interest.
	We apply eigen-R2 to two real-life examples and compare it with simply averaging R2 over many features.
	Availability: An R-package eigenR2 is available at http://www.genomine.org/eigenr2/ and will be made publicly available via Bioconductor.
	Contact: jstorey@princeton.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Here we present the open-source R/Bioconductor software package BEAT (BS-Seq Epimutation Analysis Toolkit).
	It implements all bioinformatics steps required for the quantitative high-resolution analysis of DNA methylation patterns from bisulfite sequencing data, including the detection of regional epimutation events, i.e.
	loss or gain of DNA methylation at CG positions relative to a reference.
	Using a binomial mixture model, the BEAT package aggregates methylation counts per genomic position, thereby compensating for low coverage, incomplete conversion and sequencing errors.
	Availability and implementation: BEAT is freely available as part of Bioconductor at www.bioconductor.org/packages/devel/bioc/html/ BEAT.html.
	The package is distributed under the GNU Lesser General Public License 3.0.
	Contact: akman@mpipz.mpg.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: It is expected that emerging digital gene expression (DGE) technologies will overtake microarray technologies in the near future for many functional genomics applications.
	One of the fundamental data analysis tasks, especially for gene expression studies, involves determining whether there is evidence that counts for a transcript or exon are significantly different across experimental conditions.
	edgeR is a Bioconductor software package for examining differential expression of replicated count data.
	An overdispersed Poisson model is used to account for both biological and technical variability.
	Empirical Bayes methods are used to moderate the degree of overdispersion across transcripts, improving the reliability of inference.
	The methodology can be used even with the most minimal levels of replication, provided at least one phenotype or experimental condition is replicated.
	The software may have other applications beyond sequencing data, such as proteome peptide count data.
	Availability: The package is freely available under the LGPL licence from the Bioconductor web site (http://bioconductor.org).Contact: mrobinson@wehi.edu.au
	Summary: With their many replicates and their random layouts, Illumina BeadArrays provide greater scope for detecting spatial artefacts than do other microarray technologies.
	They are also robust to artefact exclusion, yet there is a lack of tools that can perform these tasks for Illumina.
	We present BASH, a tool for this purpose.
	BASH adopts the concepts of Harshlight, but implements them in a manner that utilizes the unique characteristics of the Illumina technology.
	Using bead-level data, spatial artefacts of various kinds can thus be identified and excluded from further analyses.
	Availability: The beadarray Bioconductor package (version 1.10 onwards), www.bioconductor.org Contact: andy.lynch@cancer.org.uk Supplementary information: Additional information and a vignette are included in the beadarray package.
	Motivation: The Nearest Alignment Space Termination (NAST) tool is commonly used in sequence-based microbial ecology community analysis, but due to the limited portability of the original implementation, it has not been as widely adopted as possible.
	Python Nearest Alignment Space Termination (PyNAST) is a complete reimplementation of NAST, which includes three convenient interfaces: a Mac OS X GUI, a command-line interface and a simple application programming interface (API).
	Results: The availability of PyNAST will make the popular NAST algorithm more portable and thereby applicable to datasets orders of magnitude larger by allowing users to install PyNAST on their own hardware.
	Additionally because users can align to arbitrary template alignments, a feature not available via the original NAST web interface, the NAST algorithm will be readily applicable to novel tasks outside of microbial community analysis.
	Availability: PyNAST is available at http://pynast.sourceforge.net.Contact: rob.knight@colorado.edu
	Motivation: Sufficiently powered case-control studies with nextgeneration sequence (NGS) data remain prohibitively expensive for many investigators.
	If feasible, a more efficient strategy would be to include publicly available sequenced controls.
	However, these studies can be confounded by differences in sequencing platform; alignment, single nucleotide polymorphism and variant calling algorithms; read depth; and selection thresholds.
	Assuming one can match cases and controls on the basis of ethnicity and other potential confounding factors, and one has access to the aligned reads in both groups, we investigate the effect of systematic differences in read depth and selection threshold when comparing allele frequencies between cases and controls.
	We propose a novel likelihood-based method, the robust variance score (RVS), that substitutes genotype calls by their expected values given observed sequence data.
	Results: We show theoretically that the RVS eliminates read depth bias in the estimation of minor allele frequency.
	We also demonstrate that, using simulated and real NGS data, the RVS method controls Type I error and has comparable power to the 'gold standard' analysis with the true underlying genotypes for both common and rare variants.
	Availability and implementation: An RVS R script and instructions can be found at strug.research.sickkids.ca, and at https://github .com/strug-lab/RVS.
	Contact: lisa.strug@utoronto.ca Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Next-generation RNA sequencing offers an opportunity to investigate transcriptome in an unprecedented scale.
	Recent studies have revealed widespread alternative polyadenylation (polyA) in eukaryotes, leading to various mRNA isoforms differing in their 30 untranslated regions (30UTR), through which, the stability, localization and translation of mRNA can be regulated.
	However, very few, if any, methods and tools are available for directly analyzing this special alternative RNA processing event.
	Conventional methods rely on annotation of polyA sites; yet, such knowledge remains incomplete, and identification of polyA sites is still challenging.
	The goal of this article is to develop methods for detecting 30UTR switching without any prior knowledge of polyA annotations.
	Results: We propose a change-point model based on a likelihood ratio test for detecting 30UTR switching.
	We develop a directional testing procedure for identifying dramatic shortening or lengthening events in 30UTR, while controlling mixed directional false discovery rate at a nominal level.
	To our knowledge, this is the first approach to analyze 30UTR switching directly without relying on any polyA annotations.
	Simulation studies and applications to two real datasets reveal that our proposed method is powerful, accurate and feasible for the analysis of next-generation RNA sequencing data.
	Conclusions: The proposed method will fill a void among alternative RNA processing analysis tools for transcriptome studies.
	It can help to obtain additional insights from RNA sequencing data by understanding gene regulation mechanisms through the analysis of 30UTR switching.
	Availability and implementation: The software is implemented in Java and can be freely downloaded from http://utr.sourceforge.net/.Contact: zhiwei@njit.edu or hongzhe@mail.med.upenn.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Next-generation sequencing (NGS) has revolutionized the study of cancer genomes.
	However, the reads obtained from NGS of tumor samples often consist of a mixture of normal and tumor cells, which themselves can be of multiple clonal types.
	A prominent problem in the analysis of cancer genome sequencing data is deconvolving the mixture to identify the reads associated with tumor cells or a particular subclone of tumor cells.
	Solving the problem is, however, challenging because of the so-called 'identifiability problem', where different combinations of tumor purity and ploidy often explain the sequencing data equally well.
	Results: We propose a new model to resolve the identifiability problem by integrating two types of sequencing information-somatic copy number alterations and loss of heterozygosity-within a unified probabilistic framework.
	We derive algorithms to solve our model, and implement them in a software package called PyLOH.
	We benchmark the performance of PyLOH using both simulated data and 12 breast cancer sequencing datasets and show that PyLOH outperforms existing methods in disambiguating the identifiability problem and estimating tumor purity.
	Availability and implementation: The PyLOH package is written in Python and is publicly available at https://github.com/uci-cbcl/PyLOH.Contact: xhx@ics.uci.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Technological advances in high-throughput sequencing necessitate improved computational tools for processing and analyzing large-scale datasets in a systematic automated manner.
	For that purpose, we have developed PRADA (Pipeline for RNA-Sequencing Data Analysis), a flexible, modular and highly scalable software platform that provides many different types of information available by multifaceted analysis starting from raw paired-end RNA-seq data: gene expression levels, quality metrics, detection of unsupervised and supervised fusion transcripts, detection of intragenic fusion variants, homology scores and fusion frame classification.
	PRADA uses a dual-mapping strategy that increases sensitivity and refines the analytical endpoints.
	PRADA has been used extensively and successfully in the glioblastoma and renal clear cell projects of The Cancer Genome Atlas program.
	Availability and implementation: http://sourceforge.net/projects/prada/ Contact: gadgetz@broadinstitute.org or rverhaak@mdanderson.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Many programs for aligning short sequencing reads to a reference genome have been developed in the last 2 years.
	Most of them are very efficient for short reads but inefficient or not applicable for reads >200 bp because the algorithms are heavily and specifically tuned for short queries with low sequencing error rate.
	However, some sequencing platforms already produce longer reads and others are expected to become available soon.
	For longer reads, hashingbased software such as BLAT and SSAHA2 remain the only choices.
	Nonetheless, these methods are substantially slower than short-read aligners in terms of aligned bases per unit time.
	Results: We designed and implemented a new algorithm, BurrowsWheeler Aligner's Smith-Waterman Alignment (BWA-SW), to align long sequences up to 1 Mb against a large sequence database (e.g.
	the human genome) with a few gigabytes of memory.
	The algorithm is as accurate as SSAHA2, more accurate than BLAT, and is several to tens of times faster than both.
	Availability: http://bio-bwa.sourceforge.net Contact: rd@sanger.ac.uk
	Motivation: In order to discover quantitative trait loci, multi-dimensional genomic datasets combining DNA-seq and ChiP-/RNA-seq require methods that rapidly correlate tens of thousands of molecular phenotypes with millions of genetic variants while appropriately controlling for multiple testing.
	Results: We have developed FastQTL, a method that implements a popular cis-QTL mapping strategy in a user- and cluster-friendly tool.
	FastQTL also proposes an efficient permutation procedure to control for multiple testing.
	The outcome of permutations is modeled using beta distributions trained from a few permutations and from which adjusted P-values can be estimated at any level of significance with little computational cost.
	The Geuvadis & GTEx pilot datasets can be now easily analyzed an order of magnitude faster than previous approaches.
	Availability and implementation: Source code, binaries and comprehensive documentation of FastQTL are freely available to download at http://fastqtl.sourceforge.net/Contact: emmanouil.dermitzakis@unige.ch or olivier.delaneau@unige.ch Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: AliView is an alignment viewer and editor designed to meet the requirements of next-generation sequencing era phylogenetic datasets.
	AliView handles alignments of unlimited size in the formats most commonly used, i.e.
	FASTA, Phylip, Nexus, Clustal and MSF.
	The intuitive graphical interface makes it easy to inspect, sort, delete, merge and realign sequences as part of the manual filtering process of large datasets.
	AliView also works as an easy-to-use alignment editor for small as well as large datasets.
	Availability and implementation: AliView is released as open-source software under the GNU General Public License, version 3.0 (GPLv3), and is available at GitHub (www.github.com/AliView).
	The program is cross-platform and extensively tested on Linux, Mac OS X and Windows systems.
	Downloads and help are available at http://ormbunkar.se/aliview Contact: anders.larsson@ebc.uu.se Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The detection of genomic regions unusually rich in a given pattern is an important undertaking in the analysis of next-generation sequencing data.
	Recent studies of chromosomal translocations in activated B lymphocytes have identified regions that are frequently translocated to c-myc oncogene.
	A quantitative method for the identification of translocation hotspots was crucial to this study.
	Here we improve this analysis by using a simple probabilistic model and the framework provided by scan statistics to define the number and location of translocation breakpoint hotspots.
	A key feature of our method is that it provides a global chromosome-wide nominal control level to clustering, as opposed to previous methods based on local criteria.
	While being motivated by a specific application, the detection of unusual clusters is a widespread problem in bioinformatics.
	We expect our method to be useful in the analysis of data from other experimental approaches such as of ChIP-seq and 4C-seq.
	Results: The analysis of translocations from B lymphocytes with the method described here reveals the presence of longer hotspots when compared with those defined previously.
	Further, we show that the hotspot size changes substantially in the absence of DNA repair protein 53BP1.
	When 53BP1 deficiency is combined with overexpression of activation-induced cytidine deaminase, the hotspot length increases even further.
	These changes are not detected by previous methods that use local significance criteria for clustering.
	Our method is also able to identify several exclusive translocation hotspots located in genes of known tumor supressors.
	Availability and implementation: The detection of translocation hotspots is done with hot_scan, a program implemented in R and Perl.
	Source code and documentation are freely available for download at https://github.com/itojal/hot_scan.Contact: isilva@rockefeller.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Prions are self-templating protein aggregates that stably perpetuate distinct biological states and are of keen interest to researchers in both evolutionary and biomedical science.
	The best understood prions are from yeast and have a prion-forming domain with strongly biased amino acid composition, most notably enriched for Q or N. PLAAC is a web application that scans protein sequences for domains with prion-like amino acid composition.
	Users can upload sequence files, or paste sequences directly into a textbox.
	PLAAC ranks the input sequences by several summary scores and allows scores along sequences to be visualized.
	Text output files can be downloaded for further analyses, and visualizations saved in PDF and PNG formats.
	Availability and implementation: http://plaac.wi.mit.edu/.
	The Rubybased web framework and the command-line software (implemented in Java, with visualization routines in R) are available at http://github.com/whitehead/plaac under the MIT license.
	All software can be run under OS X, Windows and Unix.
	Contact: oliver.king@umassmed.edu or lindquist_admin@wi.mit.edu
	Summary Molecular inversion probes (MIPs) enable cost-effective multiplex targeted gene resequencing in large cohorts.
	However, the design of individual MIPs is a critical parameter governing the performance of this technology with respect to capture uniformity and specificity.
	MIPgen is a user-friendly package that simplifies the process of designing custom MIP assays to arbitrary targets.
	New logistic and SVM-derived models enable in silico predictions of assay success, and assay redesign exhibits improved coverage uniformity relative to previous methods, which in turn improves the utility of MIPs for costeffective targeted sequencing for candidate gene validation and for diagnostic sequencing in a clinical setting.
	Availability and implementation: MIPgen is implemented in C++.
	Source code and accompanying Python scripts are available at http://shendurelab.github.io/MIPGEN/.Contact: shendure@uw.edu or boylee@uw.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: EBImage provides general purpose functionality for reading, writing, processing and analysis of images.
	Furthermore, in the context of microscopy-based cellular assays, EBImage offers tools to segment cells and extract quantitative cellular descriptors.
	This allows the automation of such tasks using the R programming language and use of existing tools in the R environment for signal processing, statistical modeling, machine learning and data visualization.
	Availability: EBImage is free and open source, released under the LGPL license and available from the Bioconductor project (http://www.bioconductor.org/packages/release/bioc/html/EBImage.html).
	Contact: gregoire.pau@ebi.ac.uk
	Summary: Familial aggregation analysis is the first fundamental step to perform when assessing the extent of genetic background of a disease.
	However, there is a lack of software to analyze the familial clustering of complex phenotypes in very large pedigrees.
	Such pedigrees can be utilized to calculate measures that express trait aggregation on both the family and individual level, providing valuable directions in choosing families for detailed follow-up studies.
	We developed FamAgg, an open source R package that contains both established and novel methods to investigate familial aggregation of traits in large pedigrees.
	We demonstrate its use and interpretation by analyzing a publicly available cancer dataset with more than 20 000 participants distributed across approximately 400 families.
	Availability and implementation: The FamAgg package is freely available at the Bioconductor repository, http://www.bioconductor.org/packages/FamAgg.Contact: Christian.Weichenberger@eurac.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: The ability to efficiently investigate transcription factor binding sites (TFBSs) genomewide is central to computational studies of gene regulation.
	TFBSTools is an R/Bioconductor package for the analysis and manipulation of TFBSs and their associated transcription factor profile matrices.
	TFBStools provides a toolkit for handling TFBS profile matrices, scanning sequences and alignments including whole genomes, and querying the JASPAR database.
	The functionality of the package can be easily extended to include advanced statistical analysis, data visualization and data integration.
	Availability and implementation: The package is implemented in R and available under GPL-2 license from the Bioconductor website (http://bioconductor.org/packages/TFBSTools/).Contact: ge.tan09@imperial.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Sample source, procurement process and other technical variations introduce batch effects into genomics data.
	Algorithms to remove these artifacts enhance differences between known biological covariates, but also carry potential concern of removing intragroup biological heterogeneity and thus any personalized genomic signatures.
	As a result, accurate identification of novel subtypes from batch-corrected genomics data is challenging using standard algorithms designed to remove batch effects for class comparison analyses.
	Nor can batch effects be corrected reliably in future applications of genomics-based clinical tests, in which the biological groups are by definition unknown a priori.
	Results: Therefore, we assess the extent to which various batch correction algorithms remove true biological heterogeneity.
	We also introduce an algorithm, permuted-SVA (pSVA), using a new statistical model that is blind to biological covariates to correct for technical artifacts while retaining biological heterogeneity in genomic data.
	This algorithm facilitated accurate subtype identification in head and neck cancer from gene expression data in both formalin-fixed and frozen samples.
	When applied to predict Human Papillomavirus (HPV) status, pSVA improved cross-study validation even if the sample batches were highly confounded with HPV status in the training set.
	Availability and implementation: All analyses were performed using R version 2.15.0.
	The code and data used to generate the results of this manuscript is available from https://sourceforge.net/projects/psva.Contact: ejfertig@jhmi.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: MicroRNAs (miRNAs) are short single-stranded noncoding molecules that usually function as negative regulators to silence or suppress gene expression.
	Owning to the dynamic nature of miRNA and reduced microarray and sequencing costs, a growing number of researchers are now measuring high-dimensional miRNA expression data using repeated or multiple measures in which each individual has more than one sample collected and measured over time.
	However, the commonly used univariate association testing or the site-by-site (SBS) testing may underutilize the longitudinal feature of the data, leading to underpowered results and less biologically meaningful results.
	Results: We propose a penalized regression model incorporating grid search method (PGS), for analyzing associations of high-dimensional miRNA expression data with repeated measures.
	The development of this analytical framework was motivated by a real-world miRNA dataset.
	Comparisons between PGS and the SBS testing revealed that PGS provided smaller phenotype prediction errors and higher enrichment of phenotype-related biological pathways than the SBS testing.
	Our extensive simulations showed that PGS provided more accurate estimates and higher sensitivity than the SBS testing with comparable specificities.
	Availability and implementation: R source code for PGS algorithm, implementation example and simulation study are available for download at https://github.com/feizhe/PGS.Contact: y-zheng@northwestern.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The successful translation of genomic signatures into clinical settings relies on good discrimination between patient subgroups.
	Many sophisticated algorithms have been proposed in the statistics and machine learning literature, but in practice simpler algorithms are often used.
	However, few simple algorithms have been formally described or systematically investigated.
	Results: We give a precise definition of a popular simple method we refer to as mas-o-menos, which calculates prognostic scores for discrimination by summing standardized predictors, weighted by the signs of their marginal associations with the outcome.
	We study its behavior theoretically, in simulations and in an extensive analysis of 27 independent gene expression studies of bladder, breast and ovarian cancer, altogether totaling 3833 patients with survival outcomes.
	We find that despite its simplicity, mas-o-menos can achieve good discrimination performance.
	It performs no worse, and sometimes better, than popular and much more CPU-intensive methods for discrimination, including lasso and ridge regression.
	Availability and Implementation: Mas-o-menos is implemented for survival analysis as an option in the survHD package, available from http://www.bitbucket.org/lwaldron/survhd and submitted to Bioconductor.
	Contact: sdzhao@illinois.edu
	Motivation: Kinases of the eukaryotic protein kinase superfamily are key regulators of most aspects eukaryotic cellular behavior and have provided several drug targets including kinases dysregulated in cancers.
	The rapid increase in the number of genomic sequences has created an acute need to identify and classify members of this important class of enzymes efficiently and accurately.
	Results: Kinannote produces a draft kinome and comparative analyses for a predicted proteome using a single line command, and it is currently the only tool that automatically classifies protein kinases using the controlled vocabulary of Hanks and Hunter [Hanks and Hunter (1995)].
	A hidden Markov model in combination with a position-specific scoring matrix is used by Kinannote to identify kinases, which are subsequently classified using a BLAST comparison with a local version of KinBase, the curated protein kinase dataset from www.kinase.com.
	Kinannote was tested on the predicted proteomes from four divergent species.
	The average sensitivity and precision for kinome retrieval from the test species are 94.4 and 96.8%.
	The ability of Kinannote to classify identified kinases was also evaluated, and the average sensitivity and precision for full classification of conserved kinases are 71.5 and 82.5%, respectively.
	Kinannote has had a significant impact on eukaryotic genome annotation, providing protein kinase annotations for 36 genomes made public by the Broad Institute in the period spanning 2009 to the present.
	Availability: Kinannote is freely available at http://sourceforge.net/pro jects/kinannote.
	Contact: jmgold@broadinstitute.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We present Galaxy Portal app, an open source interface to the Galaxy system through smart phones and tablets.
	The Galaxy Portal provides convenient and efficient monitoring of job completion, as well as opportunities for inspection of results and execution history.
	In addition to being useful to the Galaxy community, we believe that the app also exemplifies a useful way of exploiting mobile interfaces for research/high-performance computing resources in general.
	Availability and implementation: The source is freely available under a GPL license on GitHub, along with user documentation and pre-compiled binaries and instructions for several platforms: https://github.com/Tarostar/QMLGalaxyPortal.
	It is available for iOS version 7 (and newer) through the Apple App Store, and for Android through Google Play for version 4.1 (API 16) or newer.
	Contact: geirksa@ifi.uio.no
	Motivation: There are many tools for variant calling and effect prediction, but little to tie together large sample groups.
	Aggregating, sorting and summarizing variants and effects across a cohort is often done with ad hoc scripts that must be re-written for every new project.
	In response, we have written MuCor, a tool to gather variants from a variety of input formats (including multiple files per sample), perform database lookups and frequency calculations, and write many types of reports.
	In addition to use in large studies with numerous samples, MuCor can also be employed to directly compare variant calls from the same sample across two or more platforms, parameters or pipelines.
	A companion utility, DepthGauge, measures coverage at regions of interest to increase confidence in calls.
	Availability and implementation: Source code is freely available at https://github.com/blachlylab/mucor and a Docker image is available at https://hub.docker.com/r/blachlylab/mucor/Contact: james.blachly@osumc.edu Supplementary data: Supplementary data are available at Bioinformatics online.
	Summary: The Sun Grid Engine (SGE) high-performance computing batch queueing system is commonly used in bioinformatics analysis.
	Creating re-usable scripts for the SGE is a common challenge.
	The qsubsec template language and interpreter described here allow researchers to easily create generic template definitions that encapsulate a particular computational job, effectively separating the process logic from the specific run details.
	At submission time, the generic template is filled in with specific values.
	This system provides an intermediate level between simple scripting and complete workflow management tools.
	Availability and implementation: Qsubsec is open-source and is available at https://github.com/alastair-droop/qsubsec.
	Contact: a.p.droop@leeds.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: FILTUS is a stand-alone tool for working with annotated variant files, e.g.
	when searching for variants causing Mendelian disease.
	Very flexible in terms of input file formats, FILTUS offers efficient filtering and a range of downstream utilities, including statistical analysis of gene sharing patterns, detection of de novo mutations in trios, quality control plots and autozygosity mapping.
	The autozygosity mapping is based on a hidden Markov model and enables accurate detection of autozygous regions directly from exome-scale variant files.
	Availability and implementation: FILTUS is written in Python and runs on Windows, Mac and Linux.
	Binaries and source code are freely available at http://folk.uio.no/magnusv/filtus.html and on GitHub: https://github.com/magnusdv/filtus.
	Automatic installation is available via PyPI (e.g.
	pip install filtus).
	Contact: magnusdv@medisin.uio.no Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We have created a Shiny-based Web application, called Shiny-phyloseq, for dynamic interaction with microbiome data that runs on any modern Web browser and requires no programming, increasing the accessibility and decreasing the entrance requirement to using phyloseq and related R tools.
	Along with a data- and contextaware dynamic interface for exploring the effects of parameter and method choices, Shiny-phyloseq also records the complete user input and subsequent graphical results of a user's session, allowing the user to archive, share and reproduce the sequence of steps that created their result-without writing any new code themselves.
	Availability and implementation: Shiny-phyloseq is implemented entirely in the R language.
	It can be hosted/launched by any system with R installed, including Windows, Mac OS and most Linux distributions.
	Information technology administrators can also host Shiny-phyloseq from a remote server, in which case users need only have a Web browser installed.
	Shiny-phyloseq is provided free of charge under a GPL-3 open-source license through GitHub at http://joey711.github.io/shiny-phyloseq/.
	Contact: mcmurdie@alumni.stanford.edu.
	Summary: Unsupervised class discovery is a highly useful technique in cancer research, where intrinsic groups sharing biological characteristics may exist but are unknown.
	The consensus clustering (CC) method provides quantitative and visual stability evidence for estimating the number of unsupervised classes in a dataset.
	ConsensusClusterPlus implements the CC method in R and extends it with new functionality and visualizations including item tracking, item-consensus and cluster-consensus plots.
	These new features provide users with detailed information that enable more specific decisions in unsupervised class discovery.
	Availability: ConsensusClusterPlus is open source software, written in R, under GPL-2, and available through the Bioconductor project (http://www.bioconductor.org/).Contact: mwilkers@med.unc.edu Supplementary Information: Supplementary data are available at Bioinformatics online.
	Motivation: High-throughput data is providing a comprehensive view of the molecular changes in cancer tissues.
	New technologies allow for the simultaneous genome-wide assay of the state of genome copy number variation, gene expression, DNA methylation and epigenetics of tumor samples and cancer cell lines.
	Analyses of current data sets find that genetic alterations between patients can differ but often involve common pathways.
	It is therefore critical to identify relevant pathways involved in cancer progression and detect how they are altered in different patients.
	Results: We present a novel method for inferring patient-specific genetic activities incorporating curated pathway interactions among genes.
	A gene is modeled by a factor graph as a set of interconnected variables encoding the expression and known activity of a gene and its products, allowing the incorporation of many types of omic data as evidence.
	The method predicts the degree to which a pathway's activities (e.g.
	internal gene states, interactions or highlevel 'outputs') are altered in the patient using probabilistic inference.
	Compared with a competing pathway activity inference approach called SPIA, our method identifies altered activities in cancer-related pathways with fewer false-positives in both a glioblastoma multiform (GBM) and a breast cancer dataset.
	PARADIGM identified consistent pathway-level activities for subsets of the GBM patients that are overlooked when genes are considered in isolation.
	Further, grouping GBM patients based on their significant pathway perturbations divides them into clinically-relevant subgroups having significantly different survival outcomes.
	These findings suggest that therapeutics might be chosen that target genes at critical points in the commonly perturbed pathway(s) of a group of patients.
	Availability: Source code available at http://sbenz.github.com/Paradigm Contact: jstuart@soe.ucsc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Genomics is expanding from a single reference per species paradigm into a more comprehensive pan-genome approach that analyzes multiple individuals together.
	A compressed de Bruijn graph is a sophisticated data structure for representing the genomes of entire populations.
	It robustly encodes shared segments, simple single-nucleotide polymorphisms and complex structural variations far beyond what can be represented in a collection of linear sequences alone.
	Results: We explore deep topological relationships between suffix trees and compressed de Bruijn graphs and introduce an algorithm, splitMEM, that directly constructs the compressed de Bruijn graph in time and space linear to the total number of genomes for a given maximum genome size.
	We introduce suffix skips to traverse several suffix links simultaneously and use them to efficiently decompose maximal exact matches into graph nodes.
	We demonstrate the utility of splitMEM by analyzing the nine-strain pan-genome of Bacillus anthracis and up to 62 strains of Escherichia coli, revealing their core-genome properties.
	Availability and implementation: Source code and documentation available open-source http://splitmem.sourceforge.net.Contact: mschatz@cshl.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Whole-genome high-coverage sequencing has been widely used for personal and cancer genomics as well as in various research areas.
	However, in the lack of an unbiased whole-genome truth set, the global error rate of variant calls and the leading causal artifacts still remain unclear even given the great efforts in the evaluation of variant calling methods.
	Results: We made 10 single nucleotide polymorphism and INDEL call sets with two read mappers and five variant callers, both on a haploid human genome and a diploid genome at a similar coverage.
	By investigating false heterozygous calls in the haploid genome, we identified the erroneous realignment in low-complexity regions and the incomplete reference genome with respect to the sample as the two major sources of errors, which press for continued improvements in these two areas.
	We estimated that the error rate of raw genotype calls is as high as 1 in 10-15 kb, but the error rate of post-filtered calls is reduced to 1 in 100-200 kb without significant compromise on the sensitivity.
	Availability and implementation: BWA-MEM alignment and raw variant calls are available at http://bit.ly/1g8XqRt scripts and miscellaneous data at https://github.com/lh3/varcmp.Contact: hengli@broadinstitute.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We present a new method to incrementally construct the FM-index for both short and long sequence reads, up to the size of a genome.
	It is the first algorithm that can build the index while implicitly sorting the sequences in the reverse (complement) lexicographical order without a separate sorting step.
	The implementation is among the fastest for indexing short reads and the only one that practically works for reads of averaged kilobases in length.
	Availability and implementation: https://github.com/lh3/ropebwt2 Contact: hengli@broadinstitute.org
	Summary: We develop a novel unsupervised deconvolution method, within a well-grounded mathematical framework, to dissect mixed gene expressions in heterogeneous tumor samples.
	We implement an R package, UNsupervised DecOnvolution (UNDO), that can be used to automatically detect cell-specific marker genes (MGs) located on the scatter radii of mixed gene expressions, estimate cellular proportions in each sample and deconvolute mixed expressions into cellspecific expression profiles.
	We demonstrate the performance of UNDO over a wide range of tumor-stroma mixing proportions, validate UNDO on various biologically mixed benchmark gene expression datasets and further estimate tumor purity in TCGA/CPTAC datasets.
	The highly accurate deconvolution results obtained suggest not only the existence of cell-specific MGs but also UNDO's ability to detect them blindly and correctly.
	Although the principal application here involves microarray gene expressions, our methodology can be readily applied to other types of quantitative molecular profiling data.
	Availability and implementation: UNDO is available at http://bioconductor.org/packages.
	Contact: yuewang@vt.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: k-Top Scoring Pairs (kTSP) is a classification method for prediction from high-throughput data based on a set of the paired measurements.
	Each of the two possible orderings of a pair of measurements (e.g.
	a reversal in the expression of two genes) is associated with one of two classes.
	The kTSP prediction rule is the aggregation of voting among such individual two-feature decision rules based on order switching.
	kTSP, like its predecessor, Top Scoring Pair (TSP), is a parameter-free classifier relying only on ranking of a small subset of features, rendering it robust to noise and potentially easy to interpret in biological terms.
	In contrast to TSP, kTSP has comparable accuracy to standard genomics classification techniques, including Support Vector Machines and Prediction Analysis for Microarrays.
	Here, we describe 'switchBox', an R package for kTSP-based prediction.
	Availability: The 'switchBox' package is freely available from Bioconductor: http://www.bioconductor.org.Contact: bahman@jhu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The development of cost-effective next-generation sequencing methods has spurred the development of high-throughput bioinformatics tools for detection of sequence variation.
	With many disparate variant-calling algorithms available, investigators must ask, 'Which method is best for my data?'
	Machine learning research has shown that so-called ensemble methods that combine the output of multiple models can dramatically improve classifier performance.
	Here we describe a novel variant-calling approach based on an ensemble of variant-calling algorithms, which we term the Consensus Genotyper for Exome Sequencing (CGES).
	CGES uses a two-stage voting scheme among four algorithm implementations.
	While our ensemble method can accept variants generated by any variant-calling algorithm, we used GATK2.8, SAMtools, FreeBayes and Atlas-SNP2 in building CGES because of their performance, widespread adoption and diverse but complementary algorithms.
	Results: We apply CGES to 132 samples sequenced at the Hudson Alpha Institute for Biotechnology (HAIB, Huntsville, AL) using the Nimblegen Exome Capture and Illumina sequencing technology.
	Our sample set consisted of 40 complete trios, two families of four, one parent-child duo and two unrelated individuals.
	CGES yielded the fewest total variant calls (NCGES=139 897), the highest Ts/Tv ratio (3.02), the lowest Mendelian error rate across all genotypes (0.028%), the highest rediscovery rate from the Exome Variant Server (EVS; 89.3%) and 1000 Genomes (1KG; 84.1%) and the highest positive predictive value (PPV; 96.1%) for a random sample of previously validated de novo variants.
	We describe these and other quality control (QC) metrics from consensus data and explain how the CGES pipeline can be used to generate call sets of varying quality stringency, including consensus calls present across all four algorithms, calls that are consistent across any three out of four algorithms, calls that are consistent across any two out of four algorithms or a more liberal set of all calls made by any algorithm.
	Availability and implementation: To enable accessible, efficient and reproducible analysis, we implement CGES both as a stand-alone command line tool available for download in GitHub and as a set of Galaxy tools and workflows configured to execute on parallel computers.
	Motivation: Existing sequence assembly editors struggle with the volumes of data now readily available from the latest generation of DNA sequencing instruments.
	Results: We describe the Gap5 software along with the data structures and algorithms used that allow it to be scalable.
	We demonstrate this with an assembly of 1.1 billion sequence fragments and compare the performance with several other programs.
	We analyse the memory, CPU, I/O usage and file sizes used by Gap5.
	Availability and Implementation: Gap5 is part of the Staden Package and is available under an Open Source licence from http://staden.sourceforge.net.
	It is implemented in C and Tcl/Tk.
	Currently it works on Unix systems only.
	Contact: jkb@sanger.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The accuracy of reference genomes is important for downstream analysis but a low error rate requires expensive manual interrogation of the sequence.
	Here, we describe a novel algorithm (Iterative Correction of Reference Nucleotides) that iteratively aligns deep coverage of short sequencing reads to correct errors in reference genome sequences and evaluate their accuracy.
	Results: Using Plasmodium falciparum (81% A + T content) as an extreme example, we show that the algorithm is highly accurate and corrects over 2000 errors in the reference sequence.
	We give examples of its application to numerous other eukaryotic and prokaryotic genomes and suggest additional applications.
	Availability: The software is available at http://icorn.sourceforge.net Contact: tdo@sanger.ac.uk; cnewbold@hammer.imm.ox.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: RNA binding proteins (RBPs) play important roles in post-transcriptional control of gene expression, including splicing, transport, polyadenylation and RNA stability.
	To model protein-RNA interactions by considering all available sources of information, it is necessary to integrate the rapidly growing RBP experimental data with the latest genome annotation, gene function, RNA sequence and structure.
	Such integration is possible by matrix factorization, where current approaches have an undesired tendency to identify only a small number of the strongest patterns with overlapping features.
	Because protein-RNA interactions are orchestrated by multiple factors, methods that identify discriminative patterns of varying strengths are needed.
	Results: We have developed an integrative orthogonality-regularized nonnegative matrix factorization (iONMF) to integrate multiple data sources and discover non-overlapping, class-specific RNA binding patterns of varying strengths.
	The orthogonality constraint halves the effective size of the factor model and outperforms other NMF models in predicting RBP interaction sites on RNA.
	We have integrated the largest data compendium to date, which includes 31 CLIP experiments on 19 RBPs involved in splicing (such as hnRNPs, U2AF2, ELAVL1, TDP-43 and FUS) and processing of 3'UTR (Ago, IGF2BP).
	We show that the integration of multiple data sources improves the predictive accuracy of retrieval of RNA binding sites.
	In our study the key predictive factors of proteinRNA interactions were the position of RNA structure and sequence motifs, RBP co-binding and gene region type.
	We report on a number of protein-specific patterns, many of which are consistent with experimentally determined properties of RBPs.
	Availability and implementation: The iONMF implementation and example datasets are available at https://github.com/mstrazar/ionmf.Contact: tomaz.curk@fri.uni-lj.si Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Researchers now have access to large volumes of genome sequences for comparative analysis, some generated by the plethora of public sequencing projects and, increasingly, from individual efforts.
	It is not possible, or necessarily desirable, that the public genome browsers attempt to curate all these data.
	Instead, a wealth of powerful tools is emerging to empower users to create their own visualizations and browsers.
	Results: We introduce a pipeline to easily generate collections of Web-accessible UCSC Genome Browsers interrelated by an alignment.
	It is intended to democratize our comparative genomic browser resources, serving the broad and growing community of evolutionary genomicists and facilitating easy public sharing via the Internet.
	Using the alignment, all annotations and the alignment itself can be efficiently viewed with reference to any genome in the collection, symmetrically.
	A new, intelligently scaled alignment display makes it simple to view all changes between the genomes at all levels of resolution, from substitutions to complex structural rearrangements, including duplications.
	To demonstrate this work, we create a comparative assembly hub containing 57 Escherichia coli and 9 Shigella genomes and show examples that highlight their unique biology.
	Availability and implementation: The source code is available as open source at: https://github.com/glennhickey/progressiveCactus The E.coli and Shigella genome hub is now a public hub listed on the UCSC browser public hubs Web page.
	Contact: benedict@soe.ucsc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Illumina produces a number of microarray-based technologies for human genotyping.
	An Infinium BeadChip is a twocolor platform that types between 105 and 106 single nucleotide polymorphisms (SNPs) per sample.
	Despite being widely used, there is a shortage of open source software to process the raw intensities from this platform into genotype calls.
	To this end, we have developed the R/Bioconductor package crlmm for analyzing BeadChip data.
	After careful preprocessing, our software applies the CRLMM algorithm to produce genotype calls, confidence scores and other quality metrics at both the SNP and sample levels.
	We provide access to the raw summary-level intensity data, allowing users to develop their own methods for genotype calling or copy number analysis if they wish.
	Availability and Implementation: The crlmm Bioconductor package is available from http://www.bioconductor.org.
	Data packages and documentation are available from http://rafalab.jhsph.edu/software .html.
	Contact: mritchie@wehi.edu.au; rafa@jhu.edu
	Summary: Cordova is an out-of-the-box solution for building and maintaining an online database of genetic variations integrated with pathogenicity prediction results from popular algorithms.
	Our primary motivation for developing this system is to aid researchers and clinician-scientists in determining the clinical significance of genetic variations.
	To achieve this goal, Cordova provides an interface to review and manually or computationally curate genetic variation data as well as share it for clinical diagnostics and the advancement of research.
	Availability and implementation: Cordova is open source under the MIT license and is freely available for download at https://github.com/clcg/cordova.Contact: sean.ephraim@gmail.com or terry-braun@uiowa.edu
	Motivation: The growing field of systems biology has driven demand for flexible tools to model and simulate biological systems.
	Two established problems in the modeling of biological processes are model selection and the estimation of associated parameters.
	A number of statistical approaches, both frequentist and Bayesian, have been proposed to answer these questions.
	Results: Here we present a Python package, ABC-SysBio, that implements parameter inference and model selection for dynamical systems in an approximate Bayesian computation (ABC) framework.
	ABC-SysBio combines three algorithms: ABC rejection sampler, ABC SMC for parameter inference and ABC SMC for model selection.
	It is designed to work with models written in Systems Biology Markup Language (SBML).
	Deterministic and stochastic models can be analyzed in ABC-SysBio.
	Availability: http://abc-sysbio.sourceforge.net Contact: christopher.barnes@imperial.ac.uk; ttoni@imperial.ac.uk; m.stumpf@imperial.ac.uk
	Summary: We present BioBlend, a unified API in a high-level language (python) that wraps the functionality of Galaxy and CloudMan APIs.
	BioBlend makes it easy for bioinformaticians to automate end-to-end large data analysis, from scratch, in a way that is highly accessible to collaborators, by allowing them to both provide the required infrastructure and automate complex analyses over large datasets within the familiar Galaxy environment.
	Availability and implementation: http://bioblend.readthedocs.org/.Automated installation of BioBlend is available via PyPI (e.g.
	pip install bioblend).
	Alternatively, the source code is available from the GitHub repository (https://github.com/afgane/bioblend) under the MIT open source license.
	The library has been tested and is working on Linux, Macintosh and Windows-based systems.
	Contact: enis.afgan@unimelb.edu.au The Author 2013.
	Published by Oxford University Press.
	All rights reserved.
	For Permissions, please email: journals.permissions@oup.com
	Summary: We present SVDetect, a program designed to identify genomic structural variations from paired-end and mate-pair nextgeneration sequencing data produced by the Illumina GA and ABI SOLiD platforms.
	Applying both sliding-window and clustering strategies, we use anomalously mapped read pairs provided by current short read aligners to localize genomic rearrangements and classify them according to their type, e.g.
	large insertionsdeletions, inversions, duplications and balanced or unbalanced interchromosomal translocations.
	SVDetect outputs predicted structural variants in various file formats for appropriate graphical visualization.
	Availability: Source code and sample data are available at http://svdetect.sourceforge.net/Contact: svdetect@curie.fr Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Whole genome sequencing of paired-end reads can be applied to characterize the landscape of large somatic rearrangements of cancer genomes.
	Several methods for detecting structural variants with whole genome sequencing data have been developed.
	So far, none of these methods has combined information about abnormally mapped read pairs connecting rearranged regions and associated global copy number changes automatically inferred from the same sequencing data file.
	Our aim was to create a computational method that could use both types of information, i.e.
	normal and abnormal reads, and demonstrate that by doing so we can highly improve both sensitivity and specificity rates of structural variant prediction.
	Results: We developed a computational method, SV-Bay, to detect structural variants from whole genome sequencing mate-pair or paired-end data using a probabilistic Bayesian approach.
	This approach takes into account depth of coverage by normal reads and abnormalities in read pair mappings.
	To estimate the model likelihood, SV-Bay considers GC-content and read mappability of the genome, thus making important corrections to the expected read count.
	For the detection of somatic variants, SV-Bay makes use of a matched normal sample when it is available.
	We validated SV-Bay on simulated datasets and an experimental mate-pair dataset for the CLB-GA neuroblastoma cell line.
	The comparison of SV-Bay with several other methods for structural variant detection demonstrated that SV-Bay has better prediction accuracy both in terms of sensitivity and false-positive detection rate.
	Availability and implementation: https://github.com/InstitutCurie/SV-Bay Contact: valentina.boeva@inserm.fr Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Genomes of emerging model organisms are now being sequenced at very low cost.
	However, obtaining accurate gene predictions remains challenging: even the best gene prediction algorithms make substantial errors and can jeopardize subsequent analyses.
	Therefore, many predicted genes must be time-consumingly visually inspected and manually curated.
	We developed GeneValidator (GV) to automatically identify problematic gene predictions and to aid manual curation.
	For each gene, GV performs multiple analyses based on comparisons to gene sequences from large databases.
	The resulting report identifies problematic gene predictions and includes extensive statistics and graphs for each prediction to guide manual curation efforts.
	GV thus accelerates and enhances the work of biocurators and researchers who need accurate gene predictions from newly sequenced genomes.
	Availability and implementation: GV can be used through a web interface or in the command-line.
	GV is open-source (AGPL), available at https://wurmlab.github.io/tools/genevalidator.Contact: y.wurm@qmul.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Sharing genomic data is crucial to support scientific investigation such as genome-wide association studies.
	However, recent investigations suggest the privacy of the individual participants in these studies can be compromised, leading to serious concerns and consequences, such as overly restricted access to data.
	Results: We introduce a novel cryptographic strategy to securely perform meta-analysis for genetic association studies in large consortia.
	Our methodology is useful for supporting joint studies among disparate data sites, where privacy or confidentiality is of concern.
	We validate our method using three multisite association studies.
	Our research shows that genetic associations can be analyzed efficiently and accurately across substudy sites, without leaking information on individual participants and site-level association summaries.
	Availability and implementation: Our software for secure metaanalysis of genetic association studies, SecureMA, is publicly available at http://github.com/XieConnect/SecureMA.
	Our customized secure computation framework is also publicly available at http://github.com/XieConnect/CircuitService Contact: b.malin@vanderbilt.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: flowDensity facilitates reproducible, high-throughput analysis of flow cytometry data by automating a predefined manual gating approach.
	The algorithm is based on a sequential bivariate gating approach that generates a set of predefined cell populations.
	It chooses the best cut-off for individual markers using characteristics of the density distribution.
	The Supplementary Material is linked to the online version of the manuscript.
	Availability and implementation: R source code freely available through BioConductor (http://master.bioconductor.org/packages/devel/bioc/html/flowDensity.html.).
	Data available from Flow Repository.org (dataset FR-FCM-ZZBW).
	Contact: rbrinkman@bccrc.ca Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We present a tool, diCal-IBD, for detecting identity-bydescent (IBD) tracts between pairs of genomic sequences.
	Our method builds on a recent demographic inference method based on the coalescent with recombination, and is able to incorporate demographic information as a prior.
	Simulation study shows that diCal-IBD has significantly higher recall and precision than that of existing singlenucleotide polymorphism-based IBD detection methods, while retaining reasonable accuracy for IBD tracts as small as 0.1 cM.
	Availability: http://sourceforge.net/projects/dical-ibd Contact: yss@eecs.berkeley.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Transposon insertion sequencing is a high-throughput technique for assaying large libraries of otherwise isogenic transposon mutants providing insight into gene essentiality, gene function and genetic interactions.
	We previously developed the Transposon Directed Insertion Sequencing (TraDIS) protocol for this purpose, which utilizes shearing of genomic DNA followed by specific PCR amplification of transposon-containing fragments and Illumina sequencing.
	Here we describe an optimized high-yield library preparation and sequencing protocol for TraDIS experiments and a novel software pipeline for analysis of the resulting data.
	The Bio-Tradis analysis pipeline is implemented as an extensible Perl library which can either be used as is, or as a basis for the development of more advanced analysis tools.
	This article can serve as a general reference for the application of the TraDIS methodology.
	Availability and implementation: The optimized sequencing protocol is included as supplementary information.
	The Bio-Tradis analysis pipeline is available under a GPL license at https://github.com/sanger-pathogens/Bio-Tradis Contact: parkhill@sanger.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: MATLAB is popular in biological research for creating and simulating models that use ordinary differential equations (ODEs).
	However, sharing or using these models outside of MATLAB is often problematic.
	A community standard such as Systems Biology Markup Language (SBML) can serve as a neutral exchange format, but translating models from MATLAB to SBML can be challengingespecially for legacy models not written with translation in mind.
	We developed MOCCASIN (Model ODE Converter for Creating Automated SBML INteroperability) to help.
	MOCCASIN can convert ODEbased MATLAB models of biochemical reaction networks into the SBML format.
	Availability and implementation: MOCCASIN is available under the terms of the LGPL 2.1 license (http://www.gnu.org/licenses/lgpl-2.1.html).
	Source code, binaries and test cases can be freely obtained from https://github.com/sbmlteam/moccasin.Contact: mhucka@caltech.edu Supplementary information: More information is available at https://github.com/sbmlteam/moccasin.
	Summary: The R/Bioconductor package Protein Array Analyzer (PAA) facilitates a flexible analysis of protein microarrays for biomarker discovery (esp., ProtoArrays).
	It provides a complete data analysis workflow including preprocessing and quality control, uni- and multivariate feature selection as well as several different plots and results tables to outline and evaluate the analysis results.
	As a main feature, PAA's multivariate feature selection methods are based on recursive feature elimination (e.g.
	SVM-recursive feature elimination, SVM-RFE) with stability ensuring strategies such as ensemble feature selection.
	This enables PAA to detect stable and reliable biomarker candidate panels.
	Availability and implementation: PAA is freely available (BSD 3-clause license) from http://www.bioconductor.org/packages/PAA/.
	Contact: michael.turewicz@rub.de or martin.eisenacher@rub.de
	Motivation: Statistical methods are used to test for the differential expression of genes in microarray experiments.
	The most widely used methods successfully test whether the true differential expression is different from zero, but give no assurance that the differences found are large enough to be biologically meaningful.
	Results: We present a method, t-tests relative to a threshold (TREAT), that allows researchers to test formally the hypothesis (with associated p-values) that the differential expression in a microarray experiment is greater than a given (biologically meaningful) threshold.
	We have evaluated the method using simulated data, a dataset from a quality control experiment for microarrays and data from a biological experiment investigating histone deacetylase inhibitors.
	When the magnitude of differential expression is taken into account, TREAT improves upon the false discovery rate of existing methods and identifies more biologically relevant genes.
	Availability: R code implementing our methods is contributed to the software package limma available at http://www.bioconductor.org.Contact: smyth@wehi.edu.au
	Motivation: Expression quantitative trait loci (eQTL) studies have discovered thousands of genetic variants that regulate gene expression, enabling a better understanding of the functional role of non-coding sequences.
	However, eQTL studies are costly, requiring large sample sizes and genome-wide genotyping of each sample.
	In contrast, analysis of allele-specific expression (ASE) is becoming a popular approach to detect the effect of genetic variation on gene expression, even within a single individual.
	This is typically achieved by counting the number of RNA-seq reads matching each allele at heterozygous sites and testing the null hypothesis of a 1:1 allelic ratio.
	In principle, when genotype information is not readily available, it could be inferred from the RNAseq reads directly.
	However, there are currently no existing methods that jointly infer genotypes and conduct ASE inference, while considering uncertainty in the genotype calls.
	Results: We present QuASAR, quantitative allele-specific analysis of reads, a novel statistical learning method for jointly detecting heterozygous genotypes and inferring ASE.
	The proposed ASE inference step takes into consideration the uncertainty in the genotype calls, while including parameters that model base-call errors in sequencing and allelic over-dispersion.
	We validated our method with experimental data for which high-quality genotypes are available.
	Results for an additional dataset with multiple replicates at different sequencing depths demonstrate that QuASAR is a powerful tool for ASE analysis when genotypes are not available.
	Availability and implementation: http://github.com/piquelab/QuASAR.Contact: fluca@wayne.edu or rpique@wayne.edu Supplementary information: Supplementary Material is available at Bioinformatics online.
	We present LuciPHOr2, a site localization tool for generic post-translational modifications (PTMs) using tandem mass spectrometry data.
	As an extension of the original LuciPHOr (version 1) for phosphorylation site localization, the new software provides a site-level localization score for generic PTMs and associated false discovery rate called the false localization rate.
	We describe several novel features such as operating system independence and reduced computation time through multiple threading.
	We also discuss optimal parameters for different types of data and illustrate the new tool on a human skeletal muscle dataset for lysine-acetylation.
	Availability and implementation: The software is freely available on the SourceForge website http://luciphor2.sourceforge.net.Contact: hyung_won_choi@nuhs.edu.sg, nesvi@med.umich.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Whole-genome sequencing has revolutionized the study of genetics.
	Genotyping-by-sequencing is now a viable method of genotyping, yet the bioinformatics involved can be daunting if not prohibitive for some laboratories.
	Here we present ArrayMaker, a user-friendly tool that extracts accurate single nucleotide polymorphism genotypes at pre-defined loci from whole-genome alignments and presents them in a standard genotyping format compatible with association analysis software and datasets genotyped on commercial array platforms.
	Using this tool, geneticists with only basic computing ability can genotype samples at any desired list of markers, facilitating genome-wide association analysis, fine mapping, candidate variant assessment, data sharing and compatibility of data sourced from multiple technologies.
	Availability and implementation: ArrayMaker is licensed under The MIT License and can be freely obtained at https://github.com/cw2014/ArrayMaker/.
	The program is implemented in Perl and runs on Linux operating systems.
	Supplementary information: Supplementary data are available at Bioinformatics online.
	Contact: cali.willet@sydney.edu.au The Author 2014.
	Published by Oxford University Press.
	All rights reserved.
	For Permissions, please e-mail: journals.permissions@oup.com
	Motivation: Finding one or more cell populations of interest, such as those correlating to a specific disease, is critical when analysing flow cytometry data.
	However, labelling of cell populations is not well defined, making it difficult to integrate the output of algorithms to external knowledge sources.
	Results: We developed flowCL, a software package that performs semantic labelling of cell populations based on their surface markers and applied it to labelling of the Federation of Clinical Immunology Societies Human Immunology Project Consortium lyoplate populations as a use case.
	Conclusion: By providing automated labelling of cell populations based on their immunophenotype, flowCL allows for unambiguous and reproducible identification of standardized cell types.
	Availability and implementation: Code, R script and documentation are available under the Artistic 2.0 license through Bioconductor (http://www.bioconductor.org/packages/devel/bioc/html/flowCL.html).Contact: rbrinkman@bccrc.ca Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: JCVI Metagenomics Reports (METAREP) is a Web 2.0 application designed to help scientists analyze and compare annotated metagenomics datasets.
	It utilizes Solr/Lucene, a highperformance scalable search engine, to quickly query large data collections.
	Furthermore, users can use its SQL-like query syntax to filter and refine datasets.
	METAREP provides graphical summaries for top taxonomic and functional classifications as well as a GO, NCBI Taxonomy and KEGG Pathway Browser.
	Users can compare absolute and relative counts of multiple datasets at various functional and taxonomic levels.
	Advanced comparative features comprise statistical tests as well as multidimensional scaling, heatmap and hierarchical clustering plots.
	Summaries can be exported as tabdelimited files, publication quality plots in PDF format.
	A data management layer allows collaborative data analysis and result sharing.
	Availability: Web site http://www.jcvi.org/metarep; source code http://github.com/jcvi/METAREP Contact: syooseph@jcvi.org Supplementary information: Supplementary data are available at Bioinformatics online.
	MAIN FEATURES
	Summary: The R/Bioconductor package girafe facilitates the functional exploration of alignments of sequence reads from nextgeneration sequencing data to a genome.
	It allows users to investigate the genomic intervals together with the aligned reads and to work with, visualise and export these intervals.
	Moreover, the package operates within and extends the ever-growing Bioconductor framework and thus enables users to leverage a multitude of methods for their data in order to answer specific research questions.
	Availability and Implementation: The R package girafe is available from the Bioconductor web site: http://www.bioconductor.org/packages/release/bioc/html/girafe.html An extensive vignette and the Bioconductor mailing lists provide additional documentation and help for using the package.
	Contact: joern.toedling@curie.fr Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Circular permutation is an important type of protein rearrangement.
	Natural circular permutations have implications for protein function, stability and evolution.
	Artificial circular permutations have also been used for protein studies.
	However, such relationships are difficult to detect for many sequence and structure comparison algorithms and require special consideration.
	Results: We developed a new algorithm, called Combinatorial Extension for Circular Permutations (CE-CP), which allows the structural comparison of circularly permuted proteins.
	CE-CP was designed to be user friendly and is integrated into the RCSB Protein Data Bank.
	It was tested on two collections of circularly permuted proteins.
	Pairwise alignments can be visualized both in a desktop application or on the web using Jmol and exported to other programs in a variety of formats.
	Availability and implementation: The CE-CP algorithm can be accessed through the RCSB website at http://www.rcsb.org/pdb/workbench/workbench.do.
	Source code is available under the LGPL 2.1 as part of BioJava 3 (http://biojava.org; http://github.com/biojava/biojava).Contact: sbliven@ucsd.edu or info@rcsb.org.
	Motivation: All current mitochondrial haplogroup classification tools require variants to be detected from an alignment with the reference sequence and to be properly named according to the canonical nomenclature standards for describing mitochondrial variants, before they can be compared with the haplogroup determining polymorphisms.
	With the emergence of high-throughput sequencing technologies and hence greater availability of mitochondrial genome sequences, there is a strong need for an automated haplogroup classification tool that is alignment-free and agnostic to reference sequence.
	Results: We have developed a novel mitochondrial genome haplogroup-defining algorithm using a k-mer approach namely Phy-Mer.
	Phy-Mer performs equally well as the leading haplogroup classifier, HaploGrep, while avoiding the errors that may occur when preparing variants to required formats and notations.
	We have further expanded Phy-Mer functionality such that next-generation sequencing data can be used directly as input.
	Availability and implementation: Phy-Mer is publicly available under the GNU Affero General Public License v3.0 on GitHub (https://github.com/danielnavarrogomez/phy-mer).Contact: Xiaowu_Gai@meei.harvard.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Parallel visualization of multiple individual human genomes is a complex endeavor that is rapidly gaining importance with the increasing number of personal, phased and cancer genomes that are being generated.
	It requires the display of variants such as SNPs, indels and structural variants that are unique to specific genomes and the introduction of multiple overlapping gaps in the reference sequence.
	Here, we describe GenPlay Multi-Genome, an application specifically written to visualize and analyze multiple human genomes in parallel.
	GenPlay Multi-Genome is ideally suited for the comparison of allele-specific expression and functional genomic data obtained from multiple phased genomes in a graphical interface with access to multiple-track operation.
	It also allows the analysis of data that have been aligned to custom genomes rather than to a standard reference and can be used as a variant calling format file browser and as a tool to compare different genome assembly, such as hg19 and hg38.
	Availability and implementation: GenPlay is available under the GNU public license (GPL-3) from http://genplay.einstein.yu.edu.
	The source code is available at https://github.com/JulienLajugie/GenPlay Contact: eric.bouhassira@einstein.yu.edu or julien.lajugie@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: With advances in sequencing technology, it has become faster and cheaper to obtain short-read data from which to assemble genomes.
	Although there has been considerable progress in the field of genome assembly, producing high-quality de novo assemblies from short-reads remains challenging, primarily because of the complex repeat structures found in the genomes of most higher organisms.
	The telomeric regions of many genomes are particularly difficult to assemble, though much could be gained from the study of these regions, as their evolution has not been fully characterized and they have been linked to aging.
	Results: In this article, we tackle the problem of assembling highly repetitive regions by developing a novel algorithm that iteratively extends long paths through a series of read-overlap graphs and evaluates them based on a statistical framework.
	Our algorithm, Telescoper, uses short- and long-insert libraries in an integrated way throughout the assembly process.
	Results on real and simulated data demonstrate that our approach can effectively resolve much of the complex repeat structures found in the telomeres of yeast genomes, especially when longer long-insert libraries are used.
	Availability: Telescoper is publicly available for download at sourceforge.net/p/telescoper.
	Contact: yss@eecs.berkeley.edu Supplementary Information: Supplementary data are available at Bioinformatics online.
	Motivation: The sequence alignment/map format (SAM) is a commonly used format to store the alignments between millions of short reads and a reference genome.
	Often certain positions within the reads are inherently more likely to contain errors due to the protocols used to prepare the samples.
	Such biases can have adverse effects on both mapping rate and accuracy.
	To understand the relationship between potential protocol biases and poor mapping we wrote SAMstat, a simple C program plotting nucleotide overrepresentation and other statistics in mapped and unmapped reads in a concise html page.
	Collecting such statistics also makes it easy to highlight problems in the data processing and enables non-experts to track data quality over time.
	Results: We demonstrate that studying sequence features in mapped data can be used to identify biases particular to one sequencing protocol.
	Once identified, such biases can be considered in the downstream analysis or even be removed by read trimming or filtering techniques.
	Availability: SAMStat is open source and freely available as a C program running on all Unix-compatible platforms.
	The source code is available from http://samstat.sourceforge.net.Contact: timolassmann@gmail.com
	Motivation: Deep profiling the phenotypic landscape of tissues using high-throughput flow cytometry (FCM) can provide important new insights into the interplay of cells in both healthy and diseased tissue.
	But often, especially in clinical settings, the cytometer cannot measure all the desired markers in a single aliquot.
	In these cases, tissue is separated into independently analysed samples, leaving a need to electronically recombine these to increase dimensionality.
	Nearest-neighbour (NN) based imputation fulfils this need but can produce artificial subpopulations.
	Clusteringbased NNs can reduce these, but requires prior domain knowledge to be able to parameterize the clustering, so is unsuited to discovery settings.
	Results: We present flowBin, a parameterization-free method for combining multitube FCM data into a higher-dimensional form suitable for deep profiling and discovery.
	FlowBin allocates cells to bins defined by the common markers across tubes in a multitube experiment, then computes aggregate expression for each bin within each tube, to create a matrix of expression of all markers assayed in each tube.
	We show, using simulated multitube data, that flowType analysis of flowBin output reproduces the results of that same analysis on the original data for cell types of >10% abundance.
	We used flowBin in conjunction with classifiers to distinguish normal from cancerous cells.
	We used flowBin together with flowType and RchyOptimyx to profile the immunophenotypic landscape of NPM1-mutated acute myeloid leukemia, and present a series of novel cell types associated with that mutation.
	Availability and implementation: FlowBin is available in Bioconductor under the Artistic 2.0 free open source license.
	All data used are available in FlowRepository under accessions: FRFCM-ZZYA, FR-FCM-ZZZK and FR-FCM-ZZES.
	Contact: rbrinkman@bccrc.ca.
	Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Calculating the edit-distance (i.e.
	minimum number of insertions, deletions and substitutions) between short DNA sequences is the primary task performed by seed-and-extend based mappers, which compare billions of sequences.
	In practice, only sequence pairs with a small editdistance provide useful scientific data.
	However, the majority of sequence pairs analyzed by seedand-extend based mappers differ by significantly more errors than what is typically allowed.
	Such error-abundant sequence pairs needlessly waste resources and severely hinder the performance of read mappers.
	Therefore, it is crucial to develop a fast and accurate filter that can rapidly and efficiently detect error-abundant string pairs and remove them from consideration before more computationally expensive methods are used.
	Results: We present a simple and efficient algorithm, Shifted Hamming Distance (SHD), which accelerates the alignment verification procedure in read mapping, by quickly filtering out error-abundant sequence pairs using bit-parallel and SIMD-parallel operations.
	SHD only filters string pairs that contain more errors than a user-defined threshold, making it fully comprehensive.
	It also maintains high accuracy with moderate error threshold (up to 5% of the string length) while achieving a 3-fold speedup over the best previous algorithm (Gene Myers's bit-vector algorithm).
	SHD is compatible with all mappers that perform sequence alignment for verification.
	Availability and implementation: We provide an implementation of SHD in C with Intel SSE instructions at: https://github.com/CMU-SAFARI/SHD.Contact: hxin@cmu.edu, calkan@cs.bilkent.edu.tr or onur@cmu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: DIYA (Do-It-Yourself Annotator) is a modular and configurable open source pipeline software, written in Perl, used for the rapid annotation of bacterial genome sequences.
	The software is currently used to take DNA contigs as input, either in the form of complete genomes or the result of shotgun sequencing, and produce an annotated sequence in Genbank file format as output.
	Availability: Distribution and source code are available at (https://sourceforge.net/projects/diyg/).Contact: tread@emory.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Sequencing reads generated by RNA-sequencing (RNA-seq) must first be mapped back to the genome through alignment before they can be further analyzed.
	Current fast and memory-saving short-read mappers could give us a quick view of the transcriptome.
	However, they are neither designed for reads that span across splice junctions nor for repetitive reads, which can be mapped to multiple locations in the genome (multi-reads).
	Here, we describe a new software package: ABMapper, which is specifically designed for exploring all putative locations of reads that are mapped to splice junctions or repetitive in nature.
	Availability and Implementation: The software is freely available at: http://abmapper.sourceforge.net/.
	The software is written in C++ and PERL.
	It runs on all major platforms and operating systems including Windows, Mac OS X and LINUX.
	Contact: tf.chan@cuhk.edu.hk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Identifying alterations in gene expression associated with different clinical states is important for the study of human biology.
	However, clinical samples used in gene expression studies are often derived from heterogeneous mixtures with variable cell-type composition, complicating statistical analysis.
	Considerable effort has been devoted to modeling sample heterogeneity, and presently, there are many methods that can estimate cell proportions or pure cell-type expression from mixture data.
	However, there is no method that comprehensively addresses mixture analysis in the context of differential expression without relying on additional proportion information, which can be inaccurate and is frequently unavailable.
	Results: In this study, we consider a clinically relevant situation where neither accurate proportion estimates nor pure cell expression is of direct interest, but where we are rather interested in detecting and interpreting relevant differential expression in mixture samples.
	We develop a method, Cell-type COmputational Differential Estimation (CellCODE), that addresses the specific statistical question directly, without requiring a physical model for mixture components.
	Our approach is based on latent variable analysis and is computationally transparent; it requires no additional experimental data, yet outperforms existing methods that use independent proportion measurements.
	CellCODE has few parameters that are robust and easy to interpret.
	The method can be used to track changes in proportion, improve power to detect differential expression and assign the differentially expressed genes to the correct cell type.
	Availability and implementation: The CellCODE R package can be downloaded at http://www.pitt.edu/ mchikina/CellCODE/ or installed from the GitHub repository 'mchikina/CellCODE'.
	Contact: mchikina@pitt.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: SEAL is a scalable tool for short read pair mapping and duplicate removal.
	It computes mappings that are consistent with those produced by BWA and removes duplicates according to the same criteria employed by Picard MarkDuplicates.
	On a 16-node Hadoop cluster, it is capable of processing about 13 GB per hour in map+rmdup mode, while reaching a throughput of 19 GB per hour in mapping-only mode.
	Availability: SEAL is available online at http://biodoopseal.sourceforge.net/.
	Contact: luca.pireddu@crs4.it
	Motivation: Ribosome profiling is a useful technique for studying translational dynamics and quantifying protein synthesis.
	Applications of this technique have shown that ribosomes are not uniformly distributed along mRNA transcripts.
	Understanding how each transcript-specific distribution arises is important for unraveling the translation mechanism.
	Results: Here, we apply kernel smoothing to construct predictive features and build a sparse model to predict the shape of ribosome footprint profiles from transcript sequences alone.
	Our results on Saccharomyces cerevisiae data show that the marginal ribosome densities can be predicted with high accuracy.
	The proposed novel method has a wide range of applications, including inferring isoform-specific ribosome footprints, designing transcripts with fast translation speeds and discovering unknown modulation during translation.
	Availability and implementation: A software package called riboShape is freely available at https://sourceforge.net/projects/riboshape Contact: yss@berkeley.edu
	Summary: We present an R based pipeline, ArrayExpressHTS, for pre-processing, expression estimation and data quality assessment of high-throughput sequencing transcriptional profiling (RNA-seq) datasets.
	The pipeline starts from raw sequence files and produces standard Bioconductor R objects containing gene or transcript measurements for downstream analysis along with web reports for data quality assessment.
	It may be run locally on a user's own computer or remotely on a distributed R-cloud farm at the European Bioinformatics Institute.
	It can be used to analyse user's own datasets or public RNA-seq datasets from the ArrayExpress Archive.
	Availability: The R package is available at www.ebi.ac.uk/tools/ rcloud with online documentation at www.ebi.ac.uk/Tools/rwiki/, also available as supplementary material.
	Contact: angela.goncalves@ebi.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Although gene-expression signature-based biomarkers are often developed for clinical diagnosis, many promising signatures fail to replicate during validation.
	One major challenge is that biological samples used to generate and validate the signature are often from heterogeneous biological contexts-controlled or in vitro samples may be used to generate the signature, but patient samples may be used for validation.
	In addition, systematic technical biases from multiple genome-profiling platforms often mask true biological variation.
	Addressing such challenges will enable us to better elucidate disease mechanisms and provide improved guidance for personalized therapeutics.
	Results: Here, we present a pathway profiling toolkit, Adaptive Signature Selection and InteGratioN (ASSIGN), which enables robust and context-specific pathway analyses by efficiently capturing pathway activity in heterogeneous sets of samples and across profiling technologies.
	The ASSIGN framework is based on a flexible Bayesian factor analysis approach that allows for simultaneous profiling of multiple correlated pathways and for the adaptation of pathway signatures into specific disease.
	We demonstrate the robustness and versatility of ASSIGN in estimating pathway activity in simulated data, cell lines perturbed pathways and in primary tissues samples including The Cancer Genome Atlas breast carcinoma samples and liver samples exposed to genotoxic carcinogens.
	Availability and implementation: Software for our approach is available for download at: http://www.bioconductor.org/packages/release/bioc/html/ASSIGN.html and https://github.com/wevan johnson/ASSIGN.
	Contact: andreab@genetics.utah.edu or wej@bu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Increasing rates of publication and DNA sequencing make the problem of finding relevant articles for a particular gene or genomic region more challenging than ever.
	Existing text-mining approaches focus on finding gene names or identifiers in English text.
	These are often not unique and do not identify the exact genomic location of a study.
	Results: Here, we report the results of a novel text-mining approach that extracts DNA sequences from biomedical articles and automatically maps them to genomic databases.
	We find that âˆ¼ 20% of open access articles in PubMed central (PMC) have extractable DNA sequences that can be accurately mapped to the correct gene (91%) and genome (96%).
	We illustrate the utility of data extracted by text2genome from more than 150 000 PMC articles for the interpretation of ChIP-seq data and the design of quantitative reverse transcriptase (RT)-PCR experiments.
	Conclusion: Our approach links articles to genes and organisms without relying on gene names or identifiers.
	It also produces genome annotation tracks of the biomedical literature, thereby allowing researchers to use the power of modern genome browsers to access and analyze publications in the context of genomic data.
	Availability and implementation: Source code is available under a BSD license from http://sourceforge.net/projects/text2genome/ and results can be browsed and downloaded at http://text2genome.org.Contact: maximilianh@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Nonlinear dose-response models are primary tools for estimating the potency [e.g.
	half-maximum inhibitory concentration (IC) known as IC50] of anti-cancer drugs.
	We present drexplorer software, which enables biologists to evaluate replicate reproducibility, detect outlier data points, fit different models, select the best model, estimate IC values at different percentiles and assess drug-drug interactions.
	drexplorer serves as a computation engine within the R environment and a graphical interface for users who do not have programming backgrounds.
	Availability and implementation: The drexplorer R package is freely available from GitHub at https://github.com/nickytong/drexplorer.
	A graphical user interface is shipped with the package.Contact: jingwang@mdanderson.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Current high-throughput sequencing technologies allow cost-efficient genotyping of millions of single nucleotide polymorphisms (SNPs) for hundreds of samples.
	However, the tools that are currently available for constructing linkage maps are not well suited for large datasets.
	Linkage maps of large datasets would be helpful in de novo genome assembly by facilitating comprehensive genome validation and refinement by enabling chimeric scaffold detection, as well as in family-based linkage and association studies, quantitative trait locus mapping, analysis of genome synteny and other complex genomic data analyses.
	Results: We describe a novel tool, called Lepidoptera-MAP (LepMAP), for constructing accurate linkage maps with ultradense genome-wide SNP data.
	Lep-MAP is fast and memory efficient and largely automated, requiring minimal user interaction.
	It uses simultaneously data on multiple outbred families and can increase linkage map accuracy by taking into account achiasmatic meiosis, a special feature of Lepidoptera and some other taxa with no recombination in one sex (no recombination in females in Lepidoptera).
	We demonstrate that Lep-MAP outperforms other methods on real and simulated data.
	We construct a genome-wide linkage map of the Glanville fritillary butterfly (Melitaea cinxia) with over 40 000 SNPs.
	The data were generated with a novel in-house SOLiD restriction site-associated DNA tag sequencing protocol, which is described in the online supplementary material.
	Availability and implementation: Java source code under GNU general public license with the compiled classes and the datasets are available from http://sourceforge.net/users/lep-map.Contact: pasi.rastas@helsinki.fi Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Mathematical modelling is central to systems and synthetic biology.
	Using simulations to calculate statistics or to explore parameter space is a common means for analysing these models and can be computationally intensive.
	However, in many cases, the simulations are easily parallelizable.
	Graphics processing units (GPUs) are capable of efficiently running highly parallel programs and outperform CPUs in terms of raw computing power.
	Despite their computational advantages, their adoption by the systems biology community is relatively slow, since differences in hardware architecture between GPUs and CPUs complicate the porting of existing code.
	Results: We present a Python package, cuda-sim, that provides highly parallelized algorithms for the repeated simulation of biochemical network models on NVIDIA CUDA GPUs.
	Algorithms are implemented for the three popular types of model formalisms: the LSODA algorithm for ODE integration, the Euler-Maruyama algorithm for SDE simulation and the Gillespie algorithm for MJP simulation.
	No knowledge of GPU computing is required from the user.
	Models can be specified in SBML format or provided as CUDA code.
	For running a large number of simulations in parallel, up to 360-fold decrease in simulation runtime is attained when compared to single CPU implementations.
	Availability: http://cuda-sim.sourceforge.net/Contact: christopher.barnes@imperial.ac.uk; m.stumpf@imperial.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Unsupervised 'cluster' analysis is an invaluable tool for exploratory microarray data analysis, as it organizes the data into groups of genes or samples in which the elements share common patterns.
	Once the data are clustered, finding the optimal number of informative subgroups within a dataset is a problem that, while important for understanding the underlying phenotypes, is one for which there is no robust, widely accepted solution.
	Results: To address this problem we developed an 'informativeness metric' based on a simple analysis of variance statistic that identifies the number of clusters which best separate phenotypic groups.
	The performance of the informativeness metric has been tested on both experimental and simulated datasets, and we contrast these results with those obtained using alternative methods such as the gap statistic.
	Availability: The method has been implemented in the Bioconductor R package attract; it is also freely available from http://compbio.dfci .harvard.edu/pubs/attract_1.0.1.zip.
	Contact: jess@jimmy.harvard.edu; johnq@jimmy.harvard.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: RNA thermometers (RNATs) are cis-regulatory elements that change secondary structure upon temperature shift.
	Often involved in the regulation of heat shock, cold shock and virulence genes, RNATs constitute an interesting potential resource in synthetic biology, where engineered RNATs could prove to be useful tools in biosensors and conditional gene regulation.
	Results: Solving the 2-temperature inverse folding problem is critical for RNAT engineering.
	Here we introduce RNAiFold2T, the first Constraint Programming (CP) and Large Neighborhood Search (LNS) algorithms to solve this problem.
	Benchmarking tests of RNAiFold2T against existent programs (adaptive walk and genetic algorithm) inverse folding show that our software generates two orders of magnitude more solutions, thus allowing ample exploration of the space of solutions.
	Subsequently, solutions can be prioritized by computing various measures, including probability of target structure in the ensemble, melting temperature, etc.
	Using this strategy, we rationally designed two thermosensor internal ribosome entry site (thermo-IRES) elements, whose normalized cap-independent translation efficiency is approximately 50% greater at 42 C than 30 C, when tested in reticulocyte lysates.
	Translation efficiency is lower than that of the wild-type IRES element, which on the other hand is fully resistant to temperature shift-up.
	This appears to be the first purely computational design of functional RNA thermoswitches, and certainly the first purely computational design of functional thermo-IRES elements.
	Availability: RNAiFold2T is publicly available as part of the new release RNAiFold3.0 at https://github.com/clotelab/RNAiFold and http://bioinformatics.bc.edu/clotelab/RNAiFold, which latter has a web server as well.
	The software is written in C Ã¾Ã¾ and uses OR-Tools CP search engine.
	Contact: clote@bc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: With the development of high-throughput sequencing, the number of assembled genomes continues to rise.
	It is critical to well organize and index many assembled genomes to promote future genomics studies.
	Burrows-Wheeler Transform (BWT) is an important data structure of genome indexing, which has many fundamental applications; however, it is still non-trivial to construct BWT for large collection of genomes, especially for highly similar or repetitive genomes.
	Moreover, the state-of-the-art approaches cannot well support scalable parallel computing owing to their incremental nature, which is a bottleneck to use modern computers to accelerate BWT construction.
	Results: We propose de Bruijn branch-based BWT constructor (deBWT), a novel parallel BWT construction approach.
	DeBWT innovatively represents and organizes the suffixes of input sequence with a novel data structure, de Bruijn branch encoding.
	This data structure takes the advantage of de Bruijn graph to facilitate the comparison between the suffixes with long common prefix, which breaks the bottleneck of the BWT construction of repetitive genomic sequences.
	Meanwhile, deBWT also uses the structure of de Bruijn graph for reducing unnecessary comparisons between suffixes.
	The benchmarking suggests that, deBWT is efficient and scalable to construct BWT for large dataset by parallel computing.
	It is well-suited to index many genomes, such as a collection of individual human genomes, with multiple-core servers or clusters.
	Availability and implementation: deBWT is implemented in C language, the source code is available at https://github.com/hitbc/deBWT or https://github.com/DixianZhu/deBWT Contact: ydwang@hit.edu.cn Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Read-based phasing deduces the haplotypes of an individual from sequencing reads that cover multiple variants, while genetic phasing takes only genotypes as input and applies the rules of Mendelian inheritance to infer haplotypes within a pedigree of individuals.
	Combining both into an approach that uses these two independent sources of information-reads and pedigree-has the potential to deliver results better than each individually.
	Results: We provide a theoretical framework combining read-based phasing with genetic haplotyping, and describe a fixed-parameter algorithm and its implementation for finding an optimal solution.
	We show that leveraging reads of related individuals jointly in this way yields more phased variants and at a higher accuracy than when phased separately, both in simulated and real data.
	Coverages as low as 2 for each member of a trio yield haplotypes that are as accurate as when analyzed separately at 15 coverage per individual.
	Availability and Implementation: https://bitbucket.org/whatshap/whatshap Contact: t.marschall@mpi-inf.mpg.de
	Motivation: Omics Pipe (http://sulab.scripps.edu/omicspipe) is a computational framework that automates multi-omics data analysis pipelines on high performance compute clusters and in the cloud.
	It supports best practice published pipelines for RNA-seq, miRNA-seq, Exome-seq, WholeGenome sequencing, ChIP-seq analyses and automatic processing of data from The Cancer Genome Atlas (TCGA).
	Omics Pipe provides researchers with a tool for reproducible, open source and extensible next generation sequencing analysis.
	The goal of Omics Pipe is to democratize next-generation sequencing analysis by dramatically increasing the accessibility and reproducibility of best practice computational pipelines, which will enable researchers to generate biologically meaningful and interpretable results.
	Results: Using Omics Pipe, we analyzed 100 TCGA breast invasive carcinoma paired tumor-normal datasets based on the latest UCSC hg19 RefSeq annotation.
	Omics Pipe automatically downloaded and processed the desired TCGA samples on a high throughput compute cluster to produce a results report for each sample.
	We aggregated the individual sample results and compared them to the analysis in the original publications.
	This comparison revealed high overlap between the analyses, as well as novel findings due to the use of updated annotations and methods.
	Availability and implementation: Source code for Omics Pipe is freely available on the web (https://bitbucket.org/sulab/omics_pipe).
	Omics Pipe is distributed as a standalone Python package for installation (https://pypi.python.org/pypi/omics_pipe) and as an Amazon Machine Image in Amazon Web Services Elastic Compute Cloud that contains all necessary third-party software dependencies and databases (https://pythonhosted.org/omics_pipe/AWS_installation.html).Contact: asu@scripps.edu or kfisch@ucsd.edu Supplementary Information: Supplementary data are available at Bioinformatics online.
	Summary: Currently available bisulfite sequencing tools frequently suffer from low mapping rates and low methylation calls, especially for data generated from the Illumina sequencer, NextSeq.
	Here, we introduce a sequential trimming-and-retrieving alignment approach for investigating DNA methylation patterns, which significantly improves the number of mapped reads and covered CpG sites.
	The method is implemented in an automated analysis toolkit for processing bisulfite sequencing reads.
	Availability and implementation: http://mysbfiles.stonybrook.edu/~xuefenwang/software.html and https://github.com/xfwang/BStools.Contact: xuefeng.wang@stonybrook.edu Supplementary information: Supplementary materials are available at Bioinformatics online.
	Summary: A genetic variant can be represented in the Variant Call Format (VCF) in multiple different ways.
	Inconsistent representation of variants between variant callers and analyses will magnify discrepancies between them and complicate variant filtering and duplicate removal.
	We present a software tool vt normalize that normalizes representation of genetic variants in the VCF.
	We formally define variant normalization as the consistent representation of genetic variants in an unambiguous and concise way and derive a simple general algorithm to enforce it.
	We demonstrate the inconsistent representation of variants across existing sequence analysis tools and show that our tool facilitates integration of diverse variant types and call sets.
	Availability and implementation: The source code is available for download at http://github.com/atks/vt.
	More detailed documentation is available at http://genome.sph.umich.edu/wiki/Variant_ Normalization.
	Contact: hmkang@umich.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Gene Ontology and other forms of gene-category analysis play a major role in the evaluation of high-throughput experiments in molecular biology.
	Single-category enrichment analysis procedures such as Fisher's exact test tend to flag large numbers of redundant categories as significant, which can complicate interpretation.
	We have recently developed an approach called model-based gene set analysis (MGSA), that substantially reduces the number of redundant categories returned by the genecategory analysis.
	In this work, we present the Bioconductor package mgsa, which makes the MGSA algorithm available to users of the R language.
	Our package provides a simple and flexible application programming interface for applying the approach.
	Availability: The mgsa package has been made available as part of Bioconductor 2.8.
	It is released under the conditions of the Artistic license 2.0.
	Contact: peter.robinson@charite.de; julien.gagneur@embl.de
	Motivation: PCR amplification of DNA is a key preliminary step in many applications of high-throughput sequencing technologies, yet design of novel barcoded primers and taxonomic analysis of novel or existing primers remains a challenging task.
	Results: PrimerProspector is an open-source software package that allows researchers to develop new primers from collections of sequences and to evaluate existing primers in the context of taxonomic data.
	Availability: PrimerProspector is open-source software available at http://pprospector.sourceforge.net Contact: rob.knight@colorado.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Exome capture kits have capture efficiencies that range from 40 to 60%.
	A significant amount of off-target reads are from the mitochondrial genome.
	These unintentionally sequenced mitochondrial reads provide unique opportunities to study the mitochondria genome.
	Results: MitoSeek is an open-source software tool that can reliably and easily extract mitochondrial genome information from exome and whole genome sequencing data.
	MitoSeek evaluates mitochondrial genome alignment quality, estimates relative mitochondrial copy numbers and detects heteroplasmy, somatic mutation and structural variants of the mitochondrial genome.
	MitoSeek can be set up to run in parallel or serial on large exome sequencing datasets.
	Availability: https://github.com/riverlee/MitoSeek Contact: yan.guo@vanderbilt.edu Supplementary information: Supplementary data are available at
	Motivation: A growing number of studies have explored the process of pre-implantation embryonic development of multiple mammalian species.
	However, the conservation and variation among different species in their developmental programming are poorly defined due to the lack of effective computational methods for detecting co-regularized genes that are conserved across species.
	The most sophisticated method to date for identifying conserved co-regulated genes is a twostep approach.
	This approach first identifies gene clusters for each species by a cluster analysis of gene expression data, and subsequently computes the overlaps of clusters identified from different species to reveal common subgroups.
	This approach is ineffective to deal with the noise in the expression data introduced by the complicated procedures in quantifying gene expression.
	Furthermore, due to the sequential nature of the approach, the gene clusters identified in the first step may have little overlap among different species in the second step, thus difficult to detect conserved co-regulated genes.
	Results: We propose a cross-species bi-clustering approach which first denoises the gene expression data of each species into a data matrix.
	The rows of the data matrices of different species represent the same set of genes that are characterized by their expression patterns over the developmental stages of each species as columns.
	A novel bi-clustering method is then developed to cluster genes into subgroups by a joint sparse rank-one factorization of all the data matrices.
	This method decomposes a data matrix into a product of a column vector and a row vector where the column vector is a consistent indicator across the matrices (species) to identify the same gene cluster and the row vector specifies for each species the developmental stages that the clustered genes co-regulate.
	Efficient optimization algorithm has been developed with convergence analysis.
	This approach was first validated on synthetic data and compared to the two-step method and several recent joint clustering methods.
	We then applied this approach to two real world datasets of gene expression during the pre-implantation embryonic development of the human and mouse.
	Coregulated genes consistent between the human and mouse were identified, offering insights into conserved functions, as well as similarities and differences in genome activation timing between the human and mouse embryos.
	Availability and Implementation: The R package containing the implementation of the proposed method in C Ã¾Ã¾ is available at: https://github.com/JavonSun/mvbc.git and also at the R platform https://www.r-project.org/.Contact: jinbo@engr.uconn.edu
	Motivation: Quantification of cellular changes to perturbations can provide a powerful approach to infer crosstalk among molecular components in biological networks.
	Existing crosstalk inference methods conduct network-structure learning based on a single phenotypic feature (e.g.
	abundance) of a biomarker.
	These approaches are insufficient for analyzing perturbation data that can contain information about multiple features (e.g.
	abundance, activity or localization) of each biomarker.
	Results: We propose a computational framework for inferring phenotypic crosstalk (PHOCOS) that is suitable for high-content microscopy or other modalities that capture multiple phenotypes per biomarker.
	PHOCOS uses a robust graph-learning paradigm to predict direct effects from potential indirect effects and identify errors owing to noise or missing links.
	The result is a multi-feature, sparse network that parsimoniously captures direct and strong interactions across phenotypic attributes of multiple biomarkers.
	We use simulated and biological data to demonstrate the ability of PHOCOS to recover multi-attribute crosstalk networks from cellular perturbation assays.
	Availability and implementation: PHOCOS is available in open source at https://github.com/AltschulerWu-Lab/PHOCOS Contact: steven.altschuler@ucsf.edu or lani.wu@ucsf.edu
	Motivation: The alignment of sequencing reads to a transcriptome is a common and important step in many RNA-seq analysis tasks.
	When aligning RNA-seq reads directly to a transcriptome (as is common in the de novo setting or when a trusted reference annotation is available), care must be taken to report the potentially large number of multi-mapping locations per read.
	This can pose a substantial computational burden for existing aligners, and can considerably slow downstream analysis.
	Results: We introduce a novel concept, quasi-mapping, and an efficient algorithm implementing this approach for mapping sequencing reads to a transcriptome.
	By attempting only to report the potential loci of origin of a sequencing read, and not the base-to-base alignment by which it derives from the reference, RapMap-our tool implementing quasi-mapping-is capable of mapping sequencing reads to a target transcriptome substantially faster than existing alignment tools.
	The algorithm we use to implement quasi-mapping uses several efficient data structures and takes advantage of the special structure of shared sequence prevalent in transcriptomes to rapidly provide highly-accurate mapping information.
	We demonstrate how quasi-mapping can be successfully applied to the problems of transcript-level quantification from RNA-seq reads and the clustering of contigs from de novo assembled transcriptomes into biologically meaningful groups.
	Availability and implementation: RapMap is implemented in C Ã¾Ã¾11 and is available as opensource software, under GPL v3, at https://github.com/COMBINE- lab/RapMap.Contact: rob.patro@cs.stonybrook.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Prior to applying genomic predictors to clinical samples, the genomic data must be properly normalized to ensure that the test set data are comparable to the data upon which the predictor was trained.
	The most effective normalization methods depend on data from multiple patients.
	From a biomedical perspective, this implies that predictions for a single patient may change depending on which other patient samples they are normalized with.
	This test set bias will occur when any cross-sample normalization is used before clinical prediction.
	Results: We demonstrate that results from existing gene signatures which rely on normalizing test data may be irreproducible when the patient population changes composition or size using a set of curated, publicly available breast cancer microarray experiments.
	As an alternative, we examine the use of gene signatures that rely on ranks from the data and show why signatures using rank-based features can avoid test set bias while maintaining highly accurate classification, even across platforms.
	Availability and implementation: The code, data and instructions necessary to reproduce our entire analysis is available at https://github.com/prpatil/testsetbias.Contact: jtleek@gmail.com or bhaibeka@uhnresearch.ca Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Tag density plots are very important to intuitively reveal biological phenomena from capture-based sequencing data by visualizing the normalized read depth in a region.
	Results: We have developed iTagPlot to compute tag density across functional features in parallel using multicores and a grid engine and to interactively explore it in a graphical user interface.
	It allows us to stratify features by defining groups based on biological function and measurement, summary statistics and unsupervised clustering.
	Availability and implementation: http://sourceforge.net/projects/itagplot/.Contact: jechoi@gru.edu and jeochoi@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Identification of protein interaction subnetworks is an important step to help us understand complex molecular mechanisms in cancer.
	In this paper, we develop a BMRF-Net package, implemented in Java and CÃ¾Ã¾, to identify protein interaction subnetworks based on a bagging Markov random field (BMRF) framework.
	By integrating gene expression data and protein-protein interaction data, this software tool can be used to identify biologically meaningful subnetworks.
	A user friendly graphic user interface is developed as a Cytoscape plugin for the BMRF-Net software to deal with the input/output interface.
	The detailed structure of the identified networks can be visualized in Cytoscape conveniently.
	The BMRF-Net package has been applied to breast cancer data to identify significant subnetworks related to breast cancer recurrence.
	Availability and implementation: The BMRF-Net package is available at http://sourceforge.net/projects/bmrfcjava/.
	The package is tested under Ubuntu 12.04 (64-bit), Java 7, glibc 2.15 and Cytoscape 3.1.0.
	Contact: xuan@vt.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: The variant call format (VCF) is a generic format for storing DNA polymorphism data such as SNPs, insertions, deletions and structural variants, together with rich annotations.
	VCF is usually stored in a compressed manner and can be indexed for fast data retrieval of variants from a range of positions on the reference genome.
	The format was developed for the 1000 Genomes Project, and has also been adopted by other projects such as UK10K, dbSNP and the NHLBI Exome Project.
	VCFtools is a software suite that implements various utilities for processing VCF files, including validation, merging, comparing and also provides a general Perl API.
	Availability: http://vcftools.sourceforge.net Contact: rd@sanger.ac.uk The VCF
	Motivation: N6-methyl-adenosine (m6A) is the most prevalent mRNA methylation but precise prediction of its mRNA location is important for understanding its function.
	A recent sequencing technology, known as Methylated RNA Immunoprecipitation Sequencing technology (MeRIP-seq), has been developed for transcriptome-wide profiling of m6A.
	We previously developed a peak calling algorithm called exomePeak.
	However, exomePeak over-simplifies data characteristics and ignores the reads' variances among replicates or reads dependency across a site region.
	To further improve the performance, new model is needed to address these important issues of MeRIP-seq data.
	Results: We propose a novel, graphical model-based peak calling method, MeTPeak, for transcriptome-wide detection of m6A sites from MeRIP-seq data.
	MeTPeak explicitly models read count of an m6A site and introduces a hierarchical layer of Beta variables to capture the variances and a Hidden Markov model to characterize the reads dependency across a site.
	In addition, we developed a constrained Newton's method and designed a log-barrier function to compute analytically intractable, positively constrained Beta parameters.
	We applied our algorithm to simulated and real biological datasets and demonstrated significant improvement in detection performance and robustness over exomePeak.
	Prediction results on publicly available MeRIP-seq datasets are also validated and shown to be able to recapitulate the known patterns of m6A, further validating the improved performance of MeTPeak.
	Availability and implementation: The package 'MeTPeak' is implemented in R and C Ã¾Ã¾, and additional details are available at https://github.com/compgenomics/MeTPeak Contact: yufei.huang@utsa.edu or xdchoi@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Extracting chemical features like Atom-Atom Mapping (AAM), Bond Changes (BCs) and Reaction Centres from biochemical reactions helps us understand the chemical composition of enzymatic reactions.
	Reaction Decoder is a robust command line tool, which performs this task with high accuracy.
	It supports standard chemical input/output exchange formats i.e.
	RXN/SMILES, computes AAM, highlights BCs and creates images of the mapped reaction.
	This aids in the analysis of metabolic pathways and the ability to perform comparative studies of chemical reactions based on these features.
	Availability and implementation: This software is implemented in Java, supported on Windows, Linux and Mac OSX, and freely available at https://github.com/asad/ReactionDecoder Contact: asad@ebi.ac.uk or s9asad@gmail.com
	Motivation: A dominant approach to genetic association studies is to perform univariate tests between genotype-phenotype pairs.
	However, analyzing related traits together increases statistical power, and certain complex associations become detectable only when several variants are tested jointly.
	Currently, modest sample sizes of individual cohorts, and restricted availability of individual-level genotype-phenotype data across the cohorts limit conducting multivariate tests.
	Results: We introduce metaCCA, a computational framework for summary statistics-based analysis of a single or multiple studies that allows multivariate representation of both genotype and phenotype.
	It extends the statistical technique of canonical correlation analysis to the setting where original individual-level records are not available, and employs a covariance shrinkage algorithm to achieve robustness.
	Multivariate meta-analysis of two Finnish studies of nuclear magnetic resonance metabolomics by metaCCA, using standard univariate output from the program SNPTEST, shows an excellent
	Summary: Complex formation and conformational transitions of biological macromolecules in solution can be effectively studied using the information about overall shape and size provided by small angle X-ray scattering (SAXS).
	Hybrid modeling is often applied to integrate high-resolution models into SAXS data analysis.
	To facilitate this task, we present SASpy, a PyMOL plugin that provides an easy-to-use graphical interface for SAXS-based hybrid modeling.
	Through a few mouse clicks in SASpy, low-resolution models can be superimposed to high-resolution structures, theoretical scattering profiles and fits can be calculated and displayed on-the-fly.
	Mouse-based manual rearrangements of complexes are conveniently applied to rapidly check and interactively refine tentative models.
	Interfaces to automated rigid-body and flexible refinement of macromolecular models against the experimental SAXS data are provided.
	Availability and implementation: SASpy is available as open source at: github.com/emblsaxs/ saspy/.
	Working installations of both PyMOL (www.pymol.org) and ATSAS (www.embl-hamburg.
	de/biosaxs/download.html) are required.
	Contact: apanjkovich@embl-hamburg.de or svergun@embl-hamburg.de
	Motivation: The explosive growth of next-generation sequencing datasets poses a challenge to the mapping of reads to reference genomes in terms of alignment quality and execution speed.
	With the continuing progress of high-throughput sequencing technologies, read length is constantly increasing and many existing aligners are becoming inefficient as generated reads grow larger.
	Results: We present CUSHAW2, a parallelized, accurate, and memory-efficient long read aligner.
	Our aligner is based on the seed-and-extend approach and uses maximal exact matches as seeds to find gapped alignments.
	We have evaluated and compared CUSHAW2 to the three other long read aligners BWA-SW, Bowtie2 and GASSST, by aligning simulated and real datasets to the human genome.
	The performance evaluation shows that CUSHAW2 is consistently among the highest-ranked aligners in terms of alignment quality for both single-end and paired-end alignment, while demonstrating highly competitive speed.
	Furthermore, our aligner shows good parallel scalability with respect to the number of CPU threads.
	Availability: CUSHAW2, written in C++, and all simulated datasets are available at http://cushaw2.sourceforge.net Contact: liuy@uni-mainz.de; bertil.schmidt@uni-mainz.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: We have created an R package named phylogeo that provides a set of geographic utilities for sequencing-based microbial ecology studies.
	Although the geographic location of samples is an important aspect of environmental microbiology, none of the major software packages used in processing microbiome data include utilities that allow users to map and explore the spatial dimension of their data.
	phylogeo solves this problem by providing a set of plotting and mapping functions that can be used to visualize the geographic distribution of samples, to look at the relatedness of microbiomes using ecological distance, and to map the geographic distribution of particular sequences.
	By extending the popular phyloseq package and using the same data structures and command formats, phylogeo allows users to easily map and explore the geographic dimensions of their data from the R programming language.
	Availability and Implementation: phylogeo is documented and freely available http://zachcp.github.io/phylogeo Contact: zcharlop@rockefeller.edu
	Summary: Identifying mentions of named entities, such as genes or diseases, and normalizing them to database identifiers have become an important step in many text and data mining pipelines.
	Despite this need, very few entity normalization systems are publicly available as source code or web services for biomedical text mining.
	Here we present the GNAT Java library for text retrieval, named entity recognition, and normalization of gene and protein mentions in biomedical text.
	The library can be used as a component to be integrated with other text-mining systems, as a framework to add user-specific extensions, and as an efficient stand-alone application for the identification of gene and protein names for data analysis.
	On the BioCreative III test data, the current version of GNAT achieves a Tap-20 score of 0.1987.
	Availability: The library and web services are implemented in Java and the sources are available from http://gnat.sourceforge.net.Contact: jorg.hakenberg@roche.com
	Motivation: The variation in community composition between microbiome samples, termed beta diversity, can be measured by pairwise distance based on either presence-absence or quantitative species abundance data.
	PERMANOVA, a permutation-based extension of multivariate analysis of variance to a matrix of pairwise distances, partitions within-group and between-group distances to permit assessment of the effect of an exposure or intervention (grouping factor) upon the sampled microbiome.
	Within-group distance and exposure/intervention effect size must be accurately modeled to estimate statistical power for a microbiome study that will be analyzed with pairwise distances and PERMANOVA.
	Results: We present a framework for PERMANOVA power estimation tailored to marker-gene microbiome studies that will be analyzed by pairwise distances, which includes: (i) a novel method for distance matrix simulation that permits modeling of within-group pairwise distances according to pre-specified population parameters; (ii) a method to incorporate effects of different sizes within the simulated distance matrix; (iii) a simulation-based method for estimating PERMANOVA power from simulated distance matrices; and (iv) an R statistical software package that implements the above.
	Matrices of pairwise distances can be efficiently simulated to satisfy the triangle inequality and incorporate group-level effects, which are quantified by the adjusted coefficient of determination, omega-squared (x2).
	From simulated distance matrices, available PERMANOVA power or necessary sample size can be estimated for a planned microbiome study.
	Availability and implementation: http://github.com/brendankelly/micropower.Contact: brendank@mail.med.upenn.edu or hongzhe@upenn.edu
	Motivation: Long arrays of near-identical tandem repeats are a common feature of centromeric and subtelomeric regions in complex genomes.
	These sequences present a source of repeat structure diversity that is commonly ignored by standard genomic tools.
	Unlike reads shorter than the underlying repeat structure that rely on indirect inference methods, e.g.
	assembly, long reads allow direct inference of satellite higher order repeat structure.
	To automate characterization of local centromeric tandem repeat sequence variation we have designed Alpha-CENTAURI (ALPHA satellite CENTromeric AUtomated Repeat Identification), that takes advantage of Pacific Bioscience long-reads from whole-genome sequencing datasets.
	By operating on reads prior to assembly, our approach provides a more comprehensive set of repeat-structure variants and is not impacted by rearrangements or sequence underrepresentation due to misassembly.
	Results: We demonstrate the utility of Alpha-CENTAURI in characterizing repeat structure for alpha satellite containing reads in the hydatidiform mole (CHM1, haploid-like) genome.
	The pipeline is designed to report local repeat organization summaries for each read, thereby monitoring rearrangements in repeat units, shifts in repeat orientation and sites of array transition into nonsatellite DNA, typically defined by transposable element insertion.
	We validate the method by showing consistency with existing centromere high order repeat references.
	Alpha-CENTAURI can, in principle, run on any sequence data, offering a method to generate a sequence repeat resolution that could be readily performed using consensus sequences available for other satellite families in genomes without high-quality reference assemblies.
	Availability and implementation: Documentation and source code for Alpha-CENTAURI are freely available at http://github.com/volkansevim/alpha-CENTAURI.Contact: ali.bashir@mssm.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: SPREAD is a user-friendly, cross-platform application to analyze and visualize Bayesian phylogeographic reconstructions incorporating spatial-temporal diffusion.
	The software maps phylogenies annotated with both discrete and continuous spatial information and can export high-dimensional posterior summaries to keyhole markup language (KML) for animation of the spatial diffusion through time in virtual globe software.
	In addition, SPREAD implements Bayes factor calculation to evaluate the support for hypotheses of historical diffusion among pairs of discrete locations based on Bayesian stochastic search variable selection estimates.
	SPREAD takes advantage of multicore architectures to process large joint posterior distributions of phylogenies and their spatial diffusion and produces visualizations as compelling and interpretable statistical summaries for the different spatial projections.
	Availability: SPREAD is licensed under the GNU Lesser GPL and its source code is freely available as a GitHub repository: https://github.com/phylogeography/SPREAD Contact: filip.bielejec@rega.kuleuven.be
	Motivation: The diversity of the immune repertoire is initially generated by random rearrangements of the receptor gene during early T and B cell development.
	Rearrangement scenarios are composed of random events-choices of gene templates, base pair deletions and insertionsdescribed by probability distributions.
	Not all scenarios are equally likely, and the same receptor sequence may be obtained in several different ways.
	Quantifying the distribution of these rearrangements is an essential baseline for studying the immune system diversity.
	Inferring the properties of the distributions from receptor sequences is a computationally hard problem, requiring enumerating every possible scenario for every sampled receptor sequence.
	Results: We present a Hidden Markov model, which accounts for all plausible scenarios that can generate the receptor sequences.
	We developed and implemented a method based on the Baum-Welch algorithm that can efficiently infer the parameters for the different events of the rearrangement process.
	We tested our software tool on sequence data for both the alpha and beta chains of the T cell receptor.
	To test the validity of our algorithm, we also generated synthetic sequences produced by a known model, and confirmed that its parameters could be accurately inferred back from the sequences.
	The inferred model can be used to generate synthetic sequences, to calculate the probability of generation of any receptor sequence, as well as the theoretical diversity of the repertoire.
	We estimate this diversity to be 1023 for human T cells.
	The model gives a baseline to investigate the selection and dynamics of immune repertoires.
	Availability and implementation: Source code and sample sequence files are available at https://bit bucket.org/yuvalel/repgenhmm/downloads.
	Contact: elhanati@lpt.ens.fr or tmora@lps.ens.fr or awalczak@lpt.ens.fr
	Motivation: Transposable elements (TEs) and repetitive DNA make up a sizable fraction of Eukaryotic genomes, and their annotation is crucial to the study of the structure, organization, and evolution of any newly sequenced genome.
	Although RepeatMasker and nHMMER are useful for identifying these repeats, they require a pre-compiled repeat library-which is not always available.
	De novo identification tools such as Recon, RepeatScout or RepeatGluer serve to identify TEs purely from sequence content, but are either limited by runtimes that prohibit whole-genome use or degrade in quality in the presence of substitutions that disrupt the sequence patterns.
	Results: phRAIDER is a de novo TE identification tool that address the issues of excessive runtime without sacrificing sensitivity as compared to competing tools.
	The underlying model is a new definition of elementary repeats that incorporates the PatternHunter spaced seed model, allowing for greater sensitivity in the presence of genomic substitutions.
	As compared with the premier tool in the literature, RepeatScout, phRAIDER shows an average 10 speedup on any single human chromosome and has the ability to process the whole human genome in just over three hours.
	Here we discuss the tool, the theoretical model underlying the tool, and the results demonstrating its effectiveness.
	Availability and implementation: phRAIDER is an open source tool available from https://github.com/karroje/phRAIDER.
	Contact: karroje@miamiOH.edu or Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Nanopore-based sequencing techniques can reconstruct properties of biosequences by analyzing the sequence-dependent ionic current steps produced as biomolecules pass through a pore.
	Typically this involves alignment of new data to a reference, where both reference construction and alignment have been performed by hand.
	Results: We propose an automated method for aligning nanopore data to a reference through the use of hidden Markov models.
	Several features that arise from prior processing steps and from the class of enzyme used can be simply incorporated into the model.
	Previously, the M2MspA nanopore was shown to be sensitive enough to distinguish between cytosine, methylcytosine and hydroxymethylcytosine.
	We validated our automated methodology on a subset of that data by automatically calculating an error rate for the distinction between the three cytosine variants and show that the automated methodology produces a 2-3% error rate, lower than the 10% error rate from previous manual segmentation and alignment.
	Availability and implementation: The data, output, scripts and tutorials replicating the analysis are available at https://github.com/UCSCNanopore/Data/tree/master/Automation.Contact: karplus@soe.ucsc.edu or jmschreiber91@gmail.com Supplementary information: Supplementary data are available from Bioinformatics online.
	Motivation: Chromatin Interaction Analysis by Paired-End Tag sequencing (ChIA-PET) is an established method for detecting genome-wide looping interactions at high resolution.
	Current ChIA-PET analysis software packages either fail to correct for non-specific interactions due to genomic proximity or only address a fraction of the steps required for data processing.
	We present Mango, a complete ChIA-PET data analysis pipeline that provides statistical confidence estimates for interactions and corrects for major sources of bias including differential peak enrichment and genomic proximity.
	Results: Comparison to the existing software packages, ChIA-PET Tool and ChiaSig revealed that Mango interactions exhibit much better agreement with high-resolution Hi-C data.
	Importantly, Mango executes all steps required for processing ChIA-PET datasets, whereas ChiaSig only completes 20% of the required steps.
	Application of Mango to multiple available ChIA-PET datasets permitted the independent rediscovery of known trends in chromatin loops including enrichment of CTCF, RAD21, SMC3 and ZNF143 at the anchor regions of interactions and strong bias for convergent CTCF motifs.
	Availability and implementation: Mango is open source and distributed through github at https://github.com/dphansti/mango.
	Contact: mpsnyder@standford.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Microbial community profiling is a highly active area of research, but tools that facilitate visualization of phylogenetic trees and associated environmental data have not kept up with the increasing quantity of data generated in these studies.
	Results: TopiaryExplorer supports the visualization of very large phylogenetic trees, including features such as the automated coloring of branches by environmental data, manipulation of trees and incorporation of per-tip metadata (e.g.
	taxonomic labels).
	Availability: http://topiaryexplorer.sourceforge.net Contact: rob.knight@colorado.edu
	Summary: Single nucleotide variations (SNVs) located within a reading frame can result in single amino acid polymorphisms (SAPs), leading to alteration of the corresponding amino acid sequence as well as function of a protein.
	Accurate detection of SAPs is an important issue in proteomic analysis at the experimental and bioinformatic level.
	Herein, we present sapFinder, an R software package, for detection of the variant peptides based on tandem mass spectrometry (MS/MS)-based proteomics data.
	This package automates the construction of variation-associated databases from public SNV repositories or sample-specific next-generation sequencing (NGS) data and the identification of SAPs through database searching, post-processing and generation of HTML-based report with visualized interface.
	Availability and implementation: sapFinder is implemented as a Bioconductor package in R. The package and the vignette can be downloaded at http://bioconductor.org/packages/devel/bioc/html/sapFinder.html and are provided under a GPL-2 license.
	Contact: siqiliu@genomics.cn Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Analysis of multiple genomes requires sophisticated tools that provide search, visualization, interactivity and data export.
	Comparative genomics datasets tend to be large and complex, making development of these tools difficult.
	In addition to scalability, comparative genomics tools must also provide userfriendly interfaces such that the research scientist can explore complex data with minimal technical expertise.
	Results: We describe a new version of the Sybil software package and its application to the important human pathogen Streptococcus pneumoniae.
	This new software provides a feature-rich set of comparative genomics tools for inspection of multiple genome structures, mining of orthologous gene families and identification of potential vaccine candidates.
	Availability: The S.pneumoniae resource is online at http://strepneumo-sybil.igs.umaryland.edu.
	The software, database and website are available for download as a portable virtual machine and from http://sourceforge.net/projects/sybil.Contact: driley@som.umaryland.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	The Affymetrix Axiom genotyping standard and 'best practice' workflow for Linux and Mac users consists of three stand-alone executable programs (Affymetrix Power Tools) and an R package (SNPolisher).
	Currently, SNP analysis has to be performed in a step-by-step procedure.
	Manual intervention and/or programming skills by the user is required at each intermediate point, as Affymetrix Power Tools programs do not produce input files for the program next-in-line.
	An additional problem is that the output format of genotypes is not compatible with most analysis software currently available.
	AffyPipe solves all the above problems, by automating both standard and 'best practice' workflows for any species genotyped with the Axiom technology.
	AffyPipe does not require programming skills and performs all the steps necessary to obtain a final genotype file.
	Furthermore, users can directly edit SNP probes and export genotypes in PLINK format.
	Availability and implementation: https://github.com/nicolazzie/AffyPipe.git.
	Contact: ezequiel.nicolazzi@tecnoparco.org
	Summary: Immunoinformatics approaches are widely used in a variety of applications from basic immunological to applied biomedical research.
	Complex data integration is inevitable in immunological research and usually requires comprehensive pipelines including multiple tools and data sources.
	Non-standard input and output formats of immunoinformatics tools make the development of such applications difficult.
	Here we present FRED 2, an open-source immunoinformatics framework offering easy and unified access to methods for epitope prediction and other immunoinformatics applications.
	FRED 2 is implemented in Python and designed to be extendable and flexible to allow rapid prototyping of complex applications.
	Availability and implementation: FRED 2 is available at http://fred-2.github.io Contact: schubert@informatik.uni-tuebingen.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Branch is a web application that provides users with the ability to interact directly with large biomedical datasets.
	The interaction is mediated through a collaborative graphical user interface for building and evaluating decision trees.
	These trees can be used to compose and test sophisticated hypotheses and to develop predictive models.
	Decision trees are built and evaluated based on a library of imported datasets and can be stored in a collective area for sharing and re-use.
	Availability and implementation: Branch is hosted at http://biobranch.org/ and the open source code is available at http://bitbucket.org/sulab/biobranch/.Contacts: asu@scripps.edu or bgood@scripps.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We present Goldilocks: a Python package providing functionality for collecting summary statistics, identifying shifts in variation, discovering outlier regions and locating and extracting interesting regions from one or more arbitrary genomes for further analysis, for a userprovided definition of interesting.
	Availability and implementation: Goldilocks is freely available open-source software distributed under the MIT licence.
	Source code is hosted publicly at https://github.com/SamStudio8/goldilocks and the package may also be installed using pip install goldilocks.
	Documentation can be found at https://goldilocks.readthedocs.org.Contact: msn@aber.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: CytoSEED is a Cytoscape plugin for viewing, manipulating and analyzing metabolic models created using the Model SEED.
	The CytoSEED plugin enables users of the Model SEED to create informative visualizations of the reaction networks generated for their organisms of interest.
	These visualizations are useful for understanding organism-specific biochemistry and for highlighting the results of flux variability analysis experiments.
	Availability and Implementation: Freely available for download on the web at http://sourceforge.net/projects/cytoseed/.
	Implemented in Java SE 6 and supported on all platforms that support Cytoscape.
	Contact: dejongh@hope.edu Supplementary information: Installation instructions, a tutorial, and full-size figures are available at http://www.cs.hope.edu/cytoseed/.
	Summary: forqs is a forward-in-time simulation of recombination, quantitative traits and selection.
	It was designed to investigate haplotype patterns resulting from scenarios where substantial evolutionary change has taken place in a small number of generations due to recombination and/or selection on polygenic quantitative traits.
	Availability and implementation: forqs is implemented as a command-line CÃ¾Ã¾ program.
	Source code and binary executables for Linux, OSX and Windows are freely available under a permissive BSD license: https://bitbucket.org/dkessner/forqs.Contact: jnovembre@uchicago.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: NetPathMiner is a general framework for mining, from genome-scale networks, paths that are related to specific experimental conditions.
	NetPathMiner interfaces with various input formats including KGML, SBML and BioPAX files and allows for manipulation of networks in three different forms: metabolic, reaction and gene representations.
	NetPathMiner ranks the obtained paths and applies Markov model-based clustering and classification methods to the ranked paths for easy interpretation.
	NetPathMiner also provides static and interactive visualizations of networks and paths to aid manual investigation.
	Availability: The package is available through Bioconductor and from Github at http://github.com/ahmohamed/NetPathMiner Contact: mohamed@kuicr.kyoto-u.ac.jp Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Here, we present riboPicker, a robust framework for the rapid, automated identification and removal of ribosomal RNA sequences from metatranscriptomic datasets.
	The results can be exported for subsequent analysis, and the databases used for the web-based version are updated on a regular basis.
	riboPicker categorizes rRNA-like sequences and provides graphical visualizations and tabular outputs of ribosomal coverage, alignment results and taxonomic classifications.
	Availability and implementation: This open-source application was implemented in Perl and can be used as stand-alone version or accessed online through a user-friendly web interface.
	The source code, user help and additional information is available at http://ribopicker.sourceforge.net/.Contact: rschmied@sciences.sdsu.edu; redwards@cs.sdsu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Most approaches used to identify cancer driver genes focus, true to their name, on entire genes and assume that a gene, treated as one entity, has a specific role in cancer.
	This approach may be correct to describe effects of gene loss or changes in gene expression; however, mutations may have different effects, including their relevance to cancer, depending on which region of the gene they affect.
	Except for rare and well-known exceptions, there are not enough data for reliable statistics for individual positions, but an intermediate level of analysis, between an individual position and the entire gene, may give us better statistics than the former and better resolution than the latter approach.
	Results: We have developed e-Driver, a method that exploits the internal distribution of somatic missense mutations between the protein's functional regions (domains or intrinsically disordered regions) to find those that show a bias in their mutation rate as compared with other regions of the same protein, providing evidence of positive selection and suggesting that these proteins may be actual cancer drivers.
	We have applied e-Driver to a large cancer genome dataset from The Cancer Genome Atlas and compared its performance with that of four other methods, showing that e-Driver identifies novel candidate cancer drivers and, because of its increased resolution, provides deeper insights into the potential mechanism of cancer driver genes identified by other methods.
	Availability and implementation: A Perl script with e-Driver and the files to reproduce the results described here can be downloaded from https://github.com/eduardporta/e-Driver.git Contact: adam@godziklab.org or eppardo@sanfordburnham.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Despite rapid progress in sequencing technology, assembling de novo the genomes of new species as well as reconstructing complex metagenomes remains major technological challenges.
	New synthetic long read (SLR) technologies promise significant advances towards these goals; however, their applicability is limited by high sequencing requirements and the inability of current assembly paradigms to cope with combinations of short and long reads.
	Results: Here, we introduce Architect, a new de novo scaffolder aimed at SLR technologies.
	Unlike previous assembly strategies, Architect does not require a costly subassembly step; instead it assembles genomes directly from the SLR's underlying short reads, which we refer to as read clouds.
	This enables a 4- to 20-fold reduction in sequencing requirements and a 5-fold increase in assembly contiguity on both genomic and metagenomic datasets relative to state-of-the-art assembly strategies aimed directly at fully subassembled long reads.
	Availability and Implementation: Our source code is freely available at https://github.com/kule shov/architect.
	Contact: kuleshov@stanford.edu
	Motivation: Detection of allelic imbalances in ChIP-Seq reads is a powerful approach to identify functional non-coding single nucleotide variants (SNVs), either polymorphisms or mutations, which modulate the affinity of transcription factors for chromatin.
	We present ABC, a computational tool that identifies allele-specific binding of transcription factors from aligned ChIP-Seq reads at heterozygous SNVs.
	ABC controls for potential false positives resulting from biases introduced by the use of short sequencing reads in ChIP-Seq and can efficiently process a large number of heterozygous SNVs.
	Results: ABC successfully identifies previously characterized functional SNVs, such as the rs4784227 breast cancer risk associated SNP that modulates the affinity of FOXA1 for the chromatin.
	Availability and implementation: The code is open-source under an Artistic-2.0 license and versioned on GitHub (https://github.com/mlupien/ABC/).
	ABC is written in PERL and can be run on any platform with both PERL ( 5.18.1) and R ( 3.1.1) installed.
	The script requires the PERL Statistics::R module.
	Contact: mlupien@uhnres.utoronto.ca Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Statistical methods development for differential expression analysis of RNA sequencing (RNA-seq) requires software tools to assess accuracy and error rate control.
	Since true differential expression status is often unknown in experimental datasets, artificially constructed datasets must be utilized, either by generating costly spike-in experiments or by simulating RNA-seq data.
	Results: Polyester is an R package designed to simulate RNA-seq data, beginning with an experimental design and ending with collections of RNA-seq reads.
	Its main advantage is the ability to simulate reads indicating isoform-level differential expression across biological replicates for a variety of experimental designs.
	Data generated by Polyester is a reasonable approximation to real RNA-seq data and standard differential expression workflows can recover differential expression set in the simulation by the user.
	Availability and implementation: Polyester is freely available from Bioconductor (http://bioconductor.org/).
	Contact: jtleek@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Genome-wide association studies revealed that most disease-associated single nucleotide polymorphisms (SNPs) are located in regulatory regions within introns or in regions between genes.
	Regulatory SNPs (rSNPs) are such SNPs that affect gene regulation by changing transcription factor (TF) binding affinities to genomic sequences.
	Identifying potential rSNPs is crucial for understanding disease mechanisms.
	In silico methods that evaluate the impact of SNPs on TF binding affinities are not scalable for large-scale analysis.
	Results: We describe affinity testing for regulatory SNPs (atSNP), a computationally efficient R package for identifying rSNPs in silico.
	atSNP implements an importance sampling algorithm coupled with a first-order Markov model for the background nucleotide sequences to test the significance of affinity scores and SNP-driven changes in these scores.
	Application of atSNP with >20 K SNPs indicates that atSNP is the only available tool for such a large-scale task.
	atSNP provides user-friendly output in the form of both tables and composite logo plots for visualizing SNPmotif interactions.
	Evaluations of atSNP with known rSNP-TF interactions indicate that atSNP is able to prioritize motifs for a given set of SNPs with high accuracy.
	Availability and implementation: https://github.com/keleslab/atSNP.Contact: keles@stat.wisc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The development of Approximate Bayesian Computation (ABC) algorithms for parameter inference which are both computationally efficient and scalable in parallel computing environments is an important area of research.
	Monte Carlo rejection sampling, a fundamental component of ABC algorithms, is trivial to distribute over multiple processors but is inherently inefficient.
	While development of algorithms such as ABC Sequential Monte Carlo (ABC-SMC) help address the inherent inefficiencies of rejection sampling, such approaches are not as easily scaled on multiple processors.
	As a result, current Bayesian inference software offerings that use ABC-SMC lack the ability to scale in parallel computing environments.
	Results: We present al3c, a CÃ¾Ã¾ framework for implementing ABC-SMC in parallel.
	By requiring only that users define essential functions such as the simulation model and prior distribution function, al3c abstracts the user from both the complexities of parallel programming and the details of the ABC-SMC algorithm.
	By using the al3c framework, the user is able to scale the ABC-SMC algorithm in parallel computing environments for his or her specific application, with minimal programming overhead.
	Availability and implementation: al3c is offered as a static binary for Linux and OS-X computing environments.
	The user completes an XML configuration file and CÃ¾Ã¾ plug-in template for the specific application, which are used by al3c to obtain the desired results.
	Users can download the static binaries, source code, reference documentation and examples (including those in this article) by visiting https://github.com/ahstram/al3c.Contact: astram@usc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: BFC is a free, fast and easy-to-use sequencing error corrector designed for Illumina short reads.
	It uses a non-greedy algorithm but still maintains a speed comparable to implementations based on greedy methods.
	In evaluations on real data, BFC appears to correct more errors with fewer overcorrections in comparison to existing tools.
	It particularly does well in suppressing systematic sequencing errors, which helps to improve the base accuracy of de novo assemblies.
	Availability and implementation: https://github.com/lh3/bfc Contact: hengli@broadinstitute.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Direct analysis of microbial communities in the environment and human body has become more convenient and reliable owing to the advancements of high-throughput sequencing techniques for 16S rRNA gene profiling.
	Inferring the correlation relationship among members of microbial communities is of fundamental importance for genomic survey study.
	Traditional Pearson correlation analysis treating the observed data as absolute abundances of the microbes may lead to spurious results because the data only represent relative abundances.
	Special care and appropriate methods are required prior to correlation analysis for these compositional data.
	Results: In this article, we first discuss the correlation definition of latent variables for compositional data.
	We then propose a novel method called CCLasso based on least squares with '1 penalty to infer the correlation network for latent variables of compositional data from metagenomic data.
	An effective alternating direction algorithm from augmented Lagrangian method is used to solve the optimization problem.
	The simulation results show that CCLasso outperforms existing methods, e.g.
	SparCC, in edge recovery for compositional data.
	It also compares well with SparCC in estimating correlation network of microbe species from the Human Microbiome Project.
	Availability and implementation: CCLasso is open source and freely available from https://github.com/huayingfang/CCLasso under GNU LGPL v3.
	Contact: dengmh@pku.edu.cn Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Biological networks change in response to genetic and environmental cues.
	Changes are reflected in the abundances of biomolecules, the composition of protein complexes and other descriptors of the biological state.
	Methods to infer the dynamic state of a cell would have great value for understanding how cells change over time to accomplish biological goals.
	Results: A new method predicts the dynamic state of protein complexes in a cell, with protein expression inferred from transcription profile time courses and protein complexes inferred by joint analysis of protein co-expression and protein-protein interaction maps.
	Two algorithmic advances are presented: a new method, DHAC (Dynamical Hierarchical Agglomerative Clustering), for clustering time-evolving networks; and a companion method, MATCH-EM, for matching corresponding clusters across time points.
	With link prediction as an objective assessment metric, DHAC provides a substantial advance over existing clustering methods.
	An application to the yeast metabolic cycle demonstrates how waves of gene expression correspond to individual protein complexes.
	Our results suggest regulatory mechanisms for assembling the mitochondrial ribosome and illustrate dynamic changes in the components of the nuclear pore.
	Availability: All source code and data are available under the Boost Software License as supplementary material, at www.baderzone.org, and at sourceforge.net/projects/dhacdist Contact: joel.bader@jhu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Identification of driver mutations in human diseases is often limited by cohort size and availability of appropriate statistical models.
	We propose a method for the systematic discovery of genetic alterations that are causal determinants of disease, by prioritizing genes upstream of functional disease drivers, within regulatory networks inferred de novo from experimental data.
	Here we present the implementation of Driver-gene Inference by Genetical-Genomic Information Theory as an R-system package.
	Availability and implementation: The diggit package is freely available under the GPL-2 license from Bioconductor (http://www.bioconductor.org).Contact: ma2581@cumc.columbia.edu or ac2248@cumc.columbia.edu
	Motivation: Within medical research there is an increasing trend toward deriving multiple types of data from the same individual.
	The most effective prognostic prediction methods should use all available data, as this maximizes the amount of information used.
	In this article, we consider a variety of learning strategies to boost prediction performance based on the use of all available data.
	Implementation: We consider data integration via the use of multiple kernel learning supervised learning methods.
	We propose a scheme in which feature selection by statistical score is performed separately per data type and by pathway membership.
	We further consider the introduction of a confidence measure for the class assignment, both to remove some ambiguously labeled datapoints from the training data and to implement a cautious classifier that only makes predictions when the associated confidence is high.
	Results: We use the METABRIC dataset for breast cancer, with prediction of survival at 2000 days from diagnosis.
	Predictive accuracy is improved by using kernels that exclusively use those genes, as features, which are known members of particular pathways.
	We show that yet further improvements can be made by using a range of additional kernels based on clinical covariates such as Estrogen Receptor (ER) status.
	Using this range of measures to improve prediction performance, we show that the test accuracy on new instances is nearly 80%, though predictions are only made on 69.2% of the patient cohort.
	Availability: https://github.com/jseoane/FSMKL Contact: J.Seoane@bristol.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Copy number variations (CNVs) are a major source of genomic variability and are especially significant in cancer.
	Until recently microarray technologies have been used to characterize CNVs in genomes.
	However, advances in next-generation sequencing technology offer significant opportunities to deduce copy number directly from genome sequencing data.
	Unfortunately cancer genomes differ from normal genomes in several aspects that make them far less amenable to copy number detection.
	For example, cancer genomes are often aneuploid and an admixture of diploid/non-tumor cell fractions.
	Also patient-derived xenograft models can be laden with mouse contamination that strongly affects accurate assignment of copy number.
	Hence, there is a need to develop analytical tools that can take into account cancer-specific parameters for detecting CNVs directly from genome sequencing data.
	Results: We have developed WaveCNV, a software package to identify copy number alterations by detecting breakpoints of CNVs using translation-invariant discrete wavelet transforms and assign digitized copy numbers to each event using next-generation sequencing data.
	We also assign alleles specifying the chromosomal ratio following duplication/loss.
	We verified copy number calls using both microarray (correlation coefficient 0.97) and quantitative polymerase chain reaction (correlation coefficient 0.94) and found them to be highly concordant.
	We demonstrate its utility in pancreatic primary and xenograft sequencing data.
	Availability and implementation: Source code and executables are available at https://github.com/WaveCNV.
	The segmentation algorithm is implemented in MATLAB, and copy number assignment is implemented Perl.
	Contact: lakshmi.muthuswamy@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: SMeagol is a software tool to simulate highly realistic microscopy data based on spatial systems biology models, in order to facilitate development, validation and optimization of advanced analysis methods for live cell single molecule microscopy data.
	Availability and implementation: SMeagol runs on Matlab R2014 and later, and uses compiled binaries in C for reaction-diffusion simulations.
	Documentation, source code and binaries for Mac OS, Windows and Ubuntu Linux can be downloaded from http://smeagol.sourceforge.net.Contact: johan.elf@icm.uu.se Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Several tools exist to identify cancer driver genes based on somatic mutation data.
	However, these tools do not account for subclasses of cancer genes: oncogenes, which undergo gain-of-function events, and tumor suppressor genes (TSGs) which undergo loss-of-function.
	A method which accounts for these subclasses could improve performance while also suggesting a mechanism of action for new putative cancer genes.
	Results: We develop a panel of five complementary statistical tests and assess their performance against a curated set of 99 HiConf cancer genes using a pan-cancer dataset of 1.7 million mutations.
	We identify patient bias as a novel signal for cancer gene discovery, and use it to significantly improve detection of oncogenes over existing methods (AUROC Â¼ 0.894).
	Additionally, our test of truncation event rate separates oncogenes and TSGs from one another (AUROC Â¼ 0.922).
	Finally, a random forest integrating the five tests further improves performance and identifies new cancer genes, including CACNG3, HDAC2, HIST1H1E, NXF1, GPS2 and HLA-DRB1.
	Availability and implementation: All mutation data, instructions, functions for computing the statistics and integrating them, as well as the HiConf gene panel, are available at www.github.com/ Bose-Lab/Improved-Detection-of-Cancer-Genes.
	Contact: rbose@dom.wustl.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The probability of effective treatment of cancer with a targeted therapeutic can be improved for patients with defined genotypes containing actionable mutations.
	To this end, many human cancer biobanks are integrating more tightly with genomic sequencing facilities and with those creating and maintaining patient-derived xenografts (PDX) and cell lines to provide renewable resources for translational research.
	Results: To support the complex data management needs and workflows of several such biobanks, we developed Acquire.
	It is a robust, secure, web-based, database-backed open-source system that supports all major needs of a modern cancer biobank.
	Its modules allow for i) up-to-the-minute 'scoreboard' and graphical reporting of collections; ii) end user roles and permissions; iii) specimen inventory through caTissue Suite; iv) shipping forms for distribution of specimens to pathology, genomic analysis and PDX/cell line creation facilities; v) robust ad hoc querying; vi) molecular and cellular quality control metrics to track specimens' progress and quality; vii) public researcher request; viii) resource allocation committee distribution request review and oversight and ix) linkage to available derivatives of specimen.
	Availability and Implementation: Acquire implements standard controlled vocabularies, ontologies and objects from the NCI, CDISC and others.
	Here we describe the functionality of the system, its technological stack and the processes it supports.
	A test version Acquire is available at https://tcrbacquire-stg.research.bcm.edu; software is available in https://github.com/BCM-DLDCC/Acquire; and UML models, data and workflow diagrams, behavioral specifications and other documents are available at https://github.com/BCM-DLDCC/Acquire/tree/master/supplementaryMaterials.Contact: becnel@bcm.edu
	Motivation: Computational identification of genomic structural variants via high-throughput sequencing is an important problem for which a number of highly sophisticated solutions have been recently developed.
	With the advent of high-throughput transcriptome sequencing (RNA-Seq), the problem of identifying structural alterations in the transcriptome is now attracting significant attention.
	In this article, we introduce two novel algorithmic formulations for identifying transcriptomic structural variants through aligning transcripts to the reference genome under the consideration of such variation.
	The first formulation is based on a nucleotide-level alignment model; a second, potentially faster formulation is based on chaining fragments shared between each transcript and the reference genome.
	Based on these formulations, we introduce a novel transcriptome-to-genome alignment tool, Dissect (DIScovery of Structural Alteration Event Containing Transcripts), which can identify and characterize transcriptomic events such as duplications, inversions, rearrangements and fusions.
	Dissect is suitable for whole transcriptome structural variation discovery problems involving sufficiently long reads or accurately assembled contigs.
	Results: We tested Dissect on simulated transcripts altered via structural events, as well as assembled RNA-Seq contigs from human prostate cancer cell line C4-2.
	Our results indicate that Dissect has high sensitivity and specificity in identifying structural alteration events in simulated transcripts as well as uncovering novel structural alterations in cancer transcriptomes.
	Availability: Dissect is available for public use at: http://dissecttrans.sourceforge.net Contact: denizy@mit.edu; fhach@cs.sfu.ca; cenk@cs.sfu.ca
	Summary: Promoter capture Hi-C (PCHi-C) allows the genome-wide interrogation of physical interactions between distal DNA regulatory elements and gene promoters in multiple tissue contexts.
	Visual integration of the resultant chromosome interaction maps with other sources of genomic annotations can provide insight into underlying regulatory mechanisms.
	We have developed Capture HiC Plotter (CHiCP), a web-based tool that allows interactive exploration of PCHi-C interaction maps and integration with both public and user-defined genomic datasets.
	Availability and Implementation: CHiCP is freely accessible from www.chicp.org and supports most major HTML5 compliant web browsers.
	Full source code and installation instructions are available from http://github.com/D-I-L/django-chicp.Contact: ob219@cam.ac.uk
	Motivation: Designing an RNA-seq study depends critically on its specific goals, technology and underlying biology, which renders general guidelines inadequate.
	We propose a Bayesian framework to customize experiments so that goals can be attained and resources are not wasted, with a focus on alternative splicing.
	Results: We studied how read length, sequencing depth, library preparation and the number of replicates affects cost-effectiveness of single-sample and group comparison studies.
	Optimal settings varied strongly according to the target organism or tissue (potential 50-500% cost cuts) and, interestingly, short reads outperformed long reads for standard analyses.
	Our framework learns key characteristics for study design from the data, and predicts if and how to continue experimentation.
	These predictions matched several follow-up experimental datasets that were used for validation.
	We provide default pipelines, but the framework can be combined with other data analysis methods and can help assess their relative merits.
	Availability and implementation: casper package at www.bioconductor.org/packages/release/bioc/ html/casper.html, Supplementary Manual by typing casperDesign() at the R prompt.
	Contact: rosselldavid@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Analysis of microbial genomes often requires the general organization and comparison of tens to thousands of genomes both from public repositories and unpublished sources.
	MicrobeDB provides a foundation for such projects by the automation of downloading published, completed bacterial and archaeal genomes from key sources, parsing annotations of all genomes (both public and private) into a local database, and allowing interaction with the database through an easy to use programming interface.
	MicrobeDB creates a simple to use, easy to maintain, centralized local resource for various large-scale comparative genomic analyses and a backend for future microbial application design.
	Availability: MicrobeDB is freely available under the GNU-GPL at: http://github.com/mlangill/microbedb/Contact: morgan.g.i.langille@gmail.com
	Motivation: Due to advances in molecular sequencing and the increasingly rapid collection of molecular data, the field of phyloinformatics is transforming into a computational science.
	Therefore, new tools are required that can be deployed in supercomputing environments and that scale to hundreds or thousands of cores.
	Results: We describe RAxML-Light, a tool for large-scale phylogenetic inference on supercomputers under maximum likelihood.
	It implements a light-weight checkpointing mechanism, deploys 128-bit (SSE3) and 256-bit (AVX) vector intrinsics, offers two orthogonal memory saving techniques and provides a fine-grain production-level message passing interface parallelization of the likelihood function.
	To demonstrate scalability and robustness of the code, we inferred a phylogeny on a simulated DNA alignment (1481 taxa, 20 000 000 bp) using 672 cores.
	This dataset requires one terabyte of RAM to compute the likelihood score on a single tree.
	Code Availability: https://github.com/stamatak/RAxML-Light-1.0.5 Data Availability: http://www.exelixis-lab.org/onLineMaterial.tar.bz2 Contact: alexandros.stamatakis@h-its.org Supplementary Information: Supplementary data are available at Bioinformatics online.
	Summary: FermiKit is a variant calling pipeline for Illumina whole-genome germline data.
	It de novo assembles short reads and then maps the assembly against a reference genome to call SNPs, short insertions/deletions and structural variations.
	FermiKit takes about one day to assemble 30-fold human whole-genome data on a modern 16-core server with 85 GB RAM at the peak, and calls variants in half an hour to an accuracy comparable to the current practice.
	FermiKit assembly is a reduced representation of raw data while retaining most of the original information.
	Availability and implementation: https://github.com/lh3/fermikit Contact: hengli@broadinstitute.org VC The Author 2015.
	Published by Oxford University Press.
	All rights reserved.
	For Permissions, please e-mail: journals.permissions@oup.com
	Motivation: As the quantity of data per sequencing experiment increases, the challenges of fragment assembly are becoming increasingly computational.
	The de Bruijn graph is a widely used data structure in fragment assembly algorithms, used to represent the information from a set of reads.
	Compaction is an important data reduction step in most de Bruijn graph based algorithms where long simple paths are compacted into single vertices.
	Compaction has recently become the bottleneck in assembly pipelines, and improving its running time and memory usage is an important problem.
	Results: We present an algorithm and a tool BCALM 2 for the compaction of de Bruijn graphs.
	BCALM 2 is a parallel algorithm that distributes the input based on a minimizer hashing technique, allowing for good balance of memory usage throughout its execution.
	For human sequencing data, BCALM 2 reduces the computational burden of compacting the de Bruijn graph to roughly an hour and 3 GB of memory.
	We also applied BCALM 2 to the 22 Gbp loblolly pine and 20 Gbp white spruce sequencing datasets.
	Compacted graphs were constructed from raw reads in less than 2 days and 40 GB of memory on a single machine.
	Hence, BCALM 2 is at least an order of magnitude more efficient than other available methods.
	Availability and Implementation: Source code of BCALM 2 is freely available at: https://github.com/GATB/bcalm Contact: rayan.chikhi@univ-lille1.fr
	Summary: New applications of next-generation sequencing technologies use pools of DNA from multiple individuals to estimate population genetic parameters.
	However, no publicly available tools exist to analyse single-nucleotide polymorphism (SNP) calling results directly for evolutionary parameters important in detecting natural selection, including nucleotide diversity and gene diversity.
	We have developed SNPGenie to fill this gap.
	The user submits a FASTA reference sequence(s), a Gene Transfer Format (.GTF) file with CDS information and a SNP report(s) in an increasing selection of formats.
	The program estimates nucleotide diversity, distance from the reference and gene diversity.
	Sites are flagged for multiple overlapping reading frames, and are categorized by polymorphism type: nonsynonymous, synonymous, or ambiguous.
	The results allow single nucleotide, single codon, sliding window, whole gene and whole genome/population analyses that aid in the detection of positive and purifying natural selection in the source population.
	Availability and implementation: SNPGenie version 1.2 is a Perl program with no additional dependencies.
	It is free, open-source, and available for download at https://github.com/hugheslab/snpgenie.
	Contact: nelsoncw@email.sc.edu or austin@biol.sc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The Cancer Genome Atlas (TCGA) RNA-Sequencing data are used widely for research.
	TCGA provides 'Level 3' data, which have been processed using a pipeline specific to that resource.
	However, we have found using experimentally derived data that this pipeline produces geneexpression values that vary considerably across biological replicates.
	In addition, some RNASequencing analysis tools require integer-based read counts, which are not provided with the Level 3 data.
	As an alternative, we have reprocessed the data for 9264 tumor and 741 normal samples across 24 cancer types using the Rsubread package.
	We have also collated corresponding clinical data for these samples.
	We provide these data as a community resource.
	Results: We compared TCGA samples processed using either pipeline and found that the Rsubread pipeline produced fewer zero-expression genes and more consistent expression levels across replicate samples than the TCGA pipeline.
	Additionally, we used a genomic-signature approach to estimate HER2 (ERBB2) activation status for 662 breast-tumor samples and found that the Rsubread data resulted in stronger predictions of HER2 pathway activity.
	Finally, we used data from both pipelines to classify 575 lung cancer samples based on histological type.
	This analysis identified various non-coding RNA that may influence lung-cancer histology.
	Availability and implementation: The RNA-Sequencing and clinical data can be downloaded from Gene Expression Omnibus (accession number GSE62944).
	Scripts and code that were used to process and analyze the data are available from https://github.com/srp33/TCGA_RNASeq_Clinical.Contact: stephen_piccolo@byu.edu or andreab@genetics.utah.edu Supplementary information: Supplementary material is available at Bioinformatics online.
	Motivation: The field of phylodynamics focuses on the problem of reconstructing population size dynamics over time using current genetic samples taken from the population of interest.
	This technique has been extensively used in many areas of biology but is particularly useful for studying the spread of quickly evolving infectious diseases agents, e.g.
	influenza virus.
	Phylodynamic inference uses a coalescent model that defines a probability density for the genealogy of randomly sampled individuals from the population.
	When we assume that such a genealogy is known, the coalescent model, equipped with a Gaussian process prior on population size trajectory, allows for nonparametric Bayesian estimation of population size dynamics.
	Although this approach is quite powerful, large datasets collected during infectious disease surveillance challenge the state-of-the-art of Bayesian phylodynamics and demand inferential methods with relatively low computational cost.
	Results: To satisfy this demand, we provide a computationally efficient Bayesian inference framework based on Hamiltonian Monte Carlo for coalescent process models.
	Moreover, we show that by splitting the Hamiltonian function, we can further improve the efficiency of this approach.
	Using several simulated and real datasets, we show that our method provides accurate estimates of population size dynamics and is substantially faster than alternative methods based on elliptical slice sampler and Metropolis-adjusted Langevin algorithm.
	Availability and implementation: The R code for all simulation studies and real data analysis conducted in this article are publicly available at http://www.ics.uci.edu/ slan/lanzi/CODES.html and in the R package phylodyn available at https://github.com/mdkarcher/phylodyn.Contact: S.Lan@warwick.ac.uk or babaks@uci.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The de novo assembly of genomes from whole- genome shotgun sequence data is a computationally intensive, multi-stage task and it is not known a priori which methods and parameter settings will produce optimal results.
	In current de novo assembly projects, a popular strategy involves trying many approaches, using different tools and settings, and then comparing and contrasting the results in order to select a final assembly for publication.
	Results: Herein, we present RAMPART, a configurable workflow management system for de novo genome assembly, which helps the user identify combinations of third-party tools and settings that provide good results for their particular genome and sequenced reads.
	RAMPART is designed to exploit High performance computing environments, such as clusters and shared memory systems, where available.
	Availability and implementation: RAMPART is available under the GPLv3 license at: https://github.com/TGAC/RAMPART.
	Contact: daniel.mapleson@tgac.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	In addition, the user manual is available online at: http://rampart.readthedocs.org/en/latest.
	Motivation: Many biological data processing problems can be formalized as clustering problems to partition data points into sensible and biologically interpretable groups.
	Results: This article introduces densityCut, a novel density-based clustering algorithm, which is both time- and space-efficient and proceeds as follows: densityCut first roughly estimates the densities of data points from a K-nearest neighbour graph and then refines the densities via a random walk.
	A cluster consists of points falling into the basin of attraction of an estimated mode of the underlining density function.
	A post-processing step merges clusters and generates a hierarchical cluster tree.
	The number of clusters is selected from the most stable clustering in the hierarchical cluster tree.
	Experimental results on ten synthetic benchmark datasets and two microarray gene expression datasets demonstrate that densityCut performs better than state-of-the-art algorithms for clustering biological datasets.
	For applications, we focus on the recent cancer mutation clustering and single cell data analyses, namely to cluster variant allele frequencies of somatic mutations to reveal clonal architectures of individual tumours, to cluster single-cell gene expression data to uncover cell population compositions, and to cluster single-cell mass cytometry data to detect communities of cells of the same functional states or types.
	densityCut performs better than competing algorithms and is scalable to large datasets.
	Availability and Implementation: Data and the densityCut R package is available from https://bit bucket.org/jerry00/densitycut_dev.
	Contact: condon@cs.ubc.ca or sshah@bccrc.ca or jiaruid@cs.ubc.ca Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Alternative splicing is an important mechanism in which the regions of pre-mRNAs are differentially joined in order to form different transcript isoforms.
	Alternative splicing is involved in the regulation of normal physiological functions but also linked to the development of diseases such as cancer.
	We analyse differential expression and splicing using RNA-sequencing time series in three different settings: overall gene expression levels, absolute transcript expression levels and relative transcript expression levels.
	Results: Using estrogen receptor a signaling response as a model system, our Gaussian processbased test identifies genes with differential splicing and/or differentially expressed transcripts.
	We discover genes with consistent changes in alternative splicing independent of changes in absolute expression and genes where some transcripts change whereas others stay constant in absolute level.
	The results suggest classes of genes with different modes of alternative splicing regulation during the experiment.
	Availability and Implementation: R and Matlab codes implementing the method are available at https://github.com/PROBIC/diffsplicing.
	An interactive browser for viewing all model fits is available at http://users.ics.aalto.fi/hande/splicingGP/Contact: hande.topa@helsinki.fi or antti.honkela@helsinki.fi Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Computational prediction of transcription factor (TF) binding sites in the genome remains a challenging task.
	Here, we present Romulus, a novel computational method for identifying individual TF binding sites from genome sequence information and cell-type-specific experimental data, such as DNase-seq.
	It combines the strengths of previous approaches, and improves robustness by reducing the number of free parameters in the model by an order of magnitude.
	Results: We show that Romulus significantly outperforms existing methods across three sources of DNase-seq data, by assessing the performance of these tools against ChIP-seq profiles.
	The difference was particularly significant when applied to binding site prediction for low-informationcontent motifs.
	Our method is capable of inferring multiple binding modes for a single TF, which differ in their DNase I cut profile.
	Finally, using the model learned by Romulus and ChIP-seq data, we introduce Binding in Closed Chromatin (BCC) as a quantitative measure of TF pioneer factor activity.
	Uniquely, our measure quantifies a defining feature of pioneer factors, namely their ability to bind closed chromatin.
	Availability and Implementation: Romulus is freely available as an R package at http://github.com/ajank/Romulus.
	Contact: ajank@mimuw.edu.pl Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: There is an increasing need for rich and dynamic biological data visualizations in bioinformatic web applications.
	New standards in web technologies, like SVG or Canvas, are now supported by most modern web browsers allowing the blossoming of powerful visualizations in biological data analysis.
	The exploration of different ways to visualize genomic data is still challenging due to the lack of flexible tools to develop them.
	Here, I present a set of libraries aimed at creating powerful tree- and track-based visualizations for the web.
	Its modularity and rich API facilitate the development of many different visualizations ranging from simple species trees to complex visualizations comprising per-node data annotations or even simple genome browsers.
	Availability and Implementation: The TnT libraries have been written in Javascript, licensed under the APACHE 2.0 license and hosted at https://github.com/tntvis.Contact: mp@ebi.ac.uk
	Motivation: Leveraging the large compendium of genomic data to predict biomedical pathways and specific mechanisms of protein interactions genome-wide in metazoan organisms has been challenging.
	In contrast to unicellular organisms, biological and technical variation originating from diverse tissues and cell-lineages is often the largest source of variation in metazoan data compendia.
	Therefore, a new computational strategy accounting for the tissue heterogeneity in the functional genomic data is needed to accurately translate the vast amount of human genomic data into specific interaction-level hypotheses.
	Results: We developed an integrated, scalable strategy for inferring multiple human gene interaction types that takes advantage of data from diverse tissue and cell-lineage origins.
	Our approach specifically predicts both the presence of a functional association and also the most likely interaction type among human genes or its protein products on a whole-genome scale.
	We demonstrate that directly incorporating tissue contextual information improves the accuracy of our predictions, and further, that such genome-wide results can be used to significantly refine regulatory interactions from primary experimental datasets (e.g.
	ChIP-Seq, mass spectrometry).
	Availability and implementation: An interactive website hosting all of our interaction predictions is publically available at http://pathwaynet.princeton.edu.
	Software was implemented using the open-source Sleipnir library, which is available for download at https://bitbucket.org/libsleipnir/lib sleipnir.bitbucket.org.
	Contact: ogt@cs.princeton.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The position-weight matrix (PWM) is a useful representation of a transcription factor binding site (TFBS) sequence pattern because the PWM can be estimated from a small number of representative TFBS sequences.
	However, because the PWM probability model assumes independence between individual nucleotide positions, the PWMs for some TFs poorly discriminate binding sites from non-binding-sites that have similar sequence content.
	Since the local threedimensional DNA structure ('shape') is a determinant of TF binding specificity and since DNA shape has a significant sequence-dependence, we combined DNA shape-derived features into a TF-generalized regulatory score and tested whether the score could improve PWM-based discrimination of TFBS from non-binding-sites.
	Results: We compared a traditional PWM model to a model that combines the PWM with a DNA shape feature-based regulatory potential score, for accuracy in detecting binding sites for 75 vertebrate transcription factors.
	The PWM Ã¾ shape model was more accurate than the PWM-only model, for 45% of TFs tested, with no significant loss of accuracy for the remaining TFs.
	Availability and implementation: The shape-based model is available as an open-source R package at that is archived on the GitHub software repository at https://github.com/ramseylab/regshape/.
	Contact: stephen.ramsey@oregonstate.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: A current challenge in understanding cancer processes is to pinpoint which mutations influence the onset and progression of disease.
	Toward this goal, we describe a method called PARADIGMSHIFT that can predict whether a mutational event is neutral, gainor loss-of-function in a tumor sample.
	The method uses a beliefpropagation algorithm to infer gene activity from gene expression and copy number data in the context of a set of pathway interactions.
	Results: The method was found to be both sensitive and specific on a set of positive and negative controls for multiple cancers for which pathway information was available.
	Application to the Cancer Genome Atlas glioblastoma, ovarian and lung squamous cancer datasets revealed several novel mutations with predicted high impact including several genes mutated at low frequency suggesting the approach will be complementary to current approaches that rely on the prevalence of events to reach statistical significance.
	Availability: All source code is available at the github repository http:github.org/paradigmshift.Contact: jstuart@soe.ucsc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Recent developments in experimental methods facilitate increasingly larger signal transduction datasets.
	Two main approaches can be taken to derive a mathematical model from these data: training a network (obtained, e.g., from literature) to the data, or inferring the network from the data alone.
	Purely data-driven methods scale up poorly and have limited interpretability, whereas literature-constrained methods cannot deal with incomplete networks.
	Results: We present an efficient approach, implemented in the R package CNORfeeder, to integrate literature-constrained and datadriven methods to infer signalling networks from perturbation experiments.
	Our method extends a given network with links derived from the data via various inference methods, and uses information on physical interactions of proteins to guide and validate the integration of links.
	We apply CNORfeeder to a network of growth and inflammatory signalling.
	We obtain a model with superior data fit in the human liver cancer HepG2 and propose potential missing pathways.
	Availability: CNORfeeder is in the process of being submitted to Bioconductor and in the meantime available at www.cellnopt.org.
	Contact: saezrodriguez@ebi.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Meta-analysis of genomics data seeks to identify genes associated with a biological phenotype across multiple datasets; however, merging data from different platforms by their features (genes) is challenging.
	Meta-analysis using functionally or biologically characterized gene sets simplifies data integration is biologically intuitive and is seen as having great potential, but is an emerging field with few established statistical methods.
	Results: We transform gene expression profiles into binary gene set profiles by discretizing results of gene set enrichment analyses and apply a new iterative bi-clustering algorithm (iBBiG) to identify groups of gene sets that are coordinately associated with groups of phenotypes across multiple studies.
	iBBiG is optimized for meta-analysis of large numbers of diverse genomics data that may have unmatched samples.
	It does not require prior knowledge of the number or size of clusters.
	When applied to simulated data, it outperforms commonly used clustering methods, discovers overlapping clusters of diverse sizes and is robust in the presence of noise.
	We apply it to meta-analysis of breast cancer studies, where iBBiG extracted novel gene set-phenotype association that predicted tumor metastases within tumor subtypes.
	Availability: Implemented in the Bioconductor package iBBiG Contact: aedin@jimmy.harvard.edu
	Motivation: RNA-seq has been widely used to study the transcriptome.
	Comparing to microarray, sequencing-based RNA-seq is able to identify splicing variants and single nucleotide variants in one experiment simultaneously.
	This provides unique opportunity to detect variants that associated with aberrant splicing.
	Despite the popularity of RNA-seq, no bioinformatics tool has been developed to leverage this advantage to identify variants associated with aberrant splicing.
	Results: We have developed PVAAS, a tool to identify single nucleotide variants that associated with aberrant alternative splicing from RNA-seq data.
	PVAAS works in three steps: (i) identify aberrant splicings; (ii) use user-provided variants or perform variant calling; (iii) assess the significance of association between variants and aberrant splicing events.
	Availability and implementation: PVAAS is written in Python and C. Source code and a comprehensive user's manual are freely available at: http://pvaas.sourceforge.net/.Contact: wang.liguo@mayo.edu or kocher.jeanpierre@mayo.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: High-throughput sequencing technologies introduce novel demands on tools available for data analysis.
	We have developed NGSView (Next Generation Sequence View), a generally applicable, flexible and extensible next-generation sequence alignment editor.
	The software allows for visualization and manipulation of millions of sequences simultaneously on a desktop computer, through a graphical interface.
	NGSView is available under an open source license and can be extended through a well documented API.
	Availability: http://ngsview.sourceforge.net Contact: arner@gsc.riken.jp
	Summary: Finding and translating stretches of DNA lacking stop codons is a task common in the analysis of sequence data.
	However, the computational tools for finding open reading frames are sufficiently slow that they are becoming a bottleneck as the volume of sequence data grows.
	This computational bottleneck is especially problematic in metagenomics when searching unassembled reads, or screening assembled contigs for genes of interest.
	Here, we present OrfM, a tool to rapidly identify open reading frames (ORFs) in sequence data by applying the Aho-Corasick algorithm to find regions uninterrupted by stop codons.
	Benchmarking revealed that OrfM finds identical ORFs to similar tools ('GetOrf' and 'Translate') but is four-five times faster.
	While OrfM is sequencing platform-agnostic, it is best suited to large, high quality datasets such as those produced by Illumina sequencers.
	Availability and Implementation: Source code and binaries are freely available for download at http://github.com/wwood/OrfM or through GNU Guix under the LGPL 3Ã¾ license.
	OrfM is implemented in C and supported on GNU/Linux and OSX.
	Contacts: b.woodcroft@uq.edu.au Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We developed MolBioLib to address the need for adaptable next-generation sequencing analysis tools.
	The result is a compact, portable and extensively tested CÃ¾Ã¾11 software framework and set of applications tailored to the demands of next-generation sequencing data and applicable to many other applications.
	MolBioLib is designed to work with common file formats and data types used both in genomic analysis and general data analysis.
	A central relational-database-like Table class is a flexible and powerful object to intuitively represent and work with a wide variety of tabular datasets, ranging from alignment data to annotations.
	MolBioLib has been used to identify causative single-nucleotide polymorphisms in whole genome sequencing, detect balanced chromosomal rearrangements and compute enrichment of messenger RNAs (mRNAs) on microtubules, typically requiring applications of under 200 lines of code.
	MolBioLib includes programs to perform a wide variety of analysis tasks, such as computing read coverage, annotating genomic intervals and novel peak calling with a wavelet algorithm.
	Although MolBioLib was designed primarily for bioinformatics purposes, much of its functionality is applicable to a wide range of problems.
	Complete documentation and an extensive automated test suite are provided.
	Availability: MolBioLib is available for download at: http://sourceforge .net/projects/molbiolib Contact: ohsumit@molbio.mgh.harvard.edu
	Summary: Data-dependent acquisition (DDA) is the most common method used to control the acquisition process of shotgun proteomics experiments.
	While novel DDA approaches have been proposed, their evaluation is made difficult by the need of programmatic control of a mass spectrometer.
	An alternative is in silico analysis, for which suitable software has been unavailable.
	To meet this need, we have developed MSAcquisitionSimulator-a collection of C Ã¾Ã¾ programs for simulating ground truth LC-MS data and the subsequent application of custom DDA algorithms.
	It provides an opportunity for researchers to test, refine and evaluate novel DDA algorithms prior to implementation on a mass spectrometer.
	Availability and implementation: The software is freely available from its Github repository http://www.github.com/DennisGoldfarb/MSAcquisitionSimulator/ which contains further documentation and usage instructions.
	Contact: weiwang@cs.ucla.edu or ben_major@med.unc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: RNA sequencing is becoming a standard for expression profiling experiments and many tools have been developed in the past few years to analyze RNA-Seq data.
	Numerous 'Bioconductor' packages are available for next-generation sequencing data loading in R, e.g.
	ShortRead and Rsamtools as well as to perform differential gene expression analyses, e.g.
	DESeq and edgeR.
	However, the processing tasks lying in between these require the precise interplay of many Bioconductor packages, e.g.
	Biostrings, IRanges or external solutions are to be sought.
	Results: We developed 'easyRNASeq', an R package that simplifies the processing of RNA sequencing data, hiding the complex interplay of the required packages behind a single functionality.
	Availability: The package is implemented in R (as of version 2.15) and is available from Bioconductor (as of version 2.10) at the URL: http://bioconductor.org/packages/release/bioc/html/easyRNASeq.html, where installation and usage instructions can be found.
	Contact: delhomme@embl.de
	Purpose: The rcellminer R package provides a wide range of functionality to help R users access and explore molecular profiling and drug response data for the NCI-60.
	The package enables flexible programmatic access to CellMiner's unparalleled breadth of NCI-60 data, including gene and protein expression, copy number, whole exome mutations, as well as activity data for 21K compounds, with information on their structure, mechanism of action and repeat screens.
	Functions are available to easily visualize compound structures, activity patterns and molecular feature profiles.
	Additionally, embedded R Shiny applications allow interactive data exploration.
	Availability and implementation: rcellminer is compatible with R 3.2 and above on Windows, Mac OS X and Linux.
	The package, documentation, tutorials and Shiny-based applications are available through Bioconductor (http://www.bioconductor.org/packages/rcellminer); ongoing updates will occur according to the Bioconductor release schedule with new CellMiner data.
	The package is free and open-source (LGPL 3).
	Contact: lunaa@cbio.mskcc.org or vinodh.rajapakse@nih.gov
	Motivation: A series of methods in population genetics use multilocus genotype data to assign individuals membership in latent clusters.
	These methods belong to a broad class of mixedmembership models, such as latent Dirichlet allocation used to analyze text corpora.
	Inference from mixed-membership models can produce different output matrices when repeatedly applied to the same inputs, and the number of latent clusters is a parameter that is often varied in the analysis pipeline.
	For these reasons, quantifying, visualizing, and annotating the output from mixedmembership models are bottlenecks for investigators across multiple disciplines from ecology to text data mining.
	Results: We introduce pong, a network-graphical approach for analyzing and visualizing membership in latent clusters with a native interactive D3.js visualization.
	pong leverages efficient algorithms for solving the Assignment Problem to dramatically reduce runtime while increasing accuracy compared with other methods that process output from mixed-membership models.
	We apply pong to 225 705 unlinked genome-wide single-nucleotide variants from 2426 unrelated individuals in the 1000 Genomes Project, and identify previously overlooked aspects of global human population structure.
	We show that pong outpaces current solutions by more than an order of magnitude in runtime while providing a customizable and interactive visualization of population structure that is more accurate than those produced by current tools.
	Availability and Implementation: pong is freely available and can be installed using the Python package management system pip.
	pong's source code is available at https://github.com/abehr/pong.
	Contact: aaron_behr@alumni.brown.edu or sramachandran@brown.edu Supplementary Information: Supplementary data are available at Bioinformatics online.
	Motivation: Whole genome sequencing (WGS) of parent-offspring trios is a powerful approach for identifying disease-associated genes via detecting copy number variations (CNVs).
	Existing approaches, which detect CNVs for each individual in a trio independently, usually yield low-detection accuracy.
	Joint modeling approaches leveraging Mendelian transmission within the parent-offspring trio can be an efficient strategy to improve CNV detection accuracy.
	Results: In this study, we developed TrioCNV, a novel approach for jointly detecting CNVs in parent-offspring trios from WGS data.
	Using negative binomial regression, we modeled the read depth signal while considering both GC content bias and mappability bias.
	Moreover, we incorporated the family relationship and used a hidden Markov model to jointly infer CNVs for three samples of a parent-offspring trio.
	Through application to both simulated data and a trio from 1000 Genomes Project, we showed that TrioCNV achieved superior performance than existing approaches.
	Availability and implementation: The software TrioCNV implemented using a combination of Java and R is freely available from the website at https://github.com/yongzhuang/TrioCNV.Contact: ydwang@hit.edu.cn Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The Optical Mapping System discovers structural variants and potentiates sequence assembly of genomes via scaffolding and comparisons that globally validate or correct sequence assemblies.
	Despite its utility, there are few publicly available tools for aligning optical mapping datasets.
	Results: Here we present software, named 'Maligner', for the alignment of both single molecule restriction maps (Rmaps) and in silico restriction maps of sequence contigs to a reference.
	Maligner provides two modes of alignment: an efficient, sensitive dynamic programming implementation that scales to large eukaryotic genomes, and a faster indexed based implementation for finding alignments with unmatched sites in the reference but not the query.
	We compare our software to other publicly available tools on Rmap datasets and show that Maligner finds more correct alignments in comparable runtime.
	Lastly, we introduce the M-Score statistic for normalizing alignment scores across restriction maps and demonstrate its utility for selecting high quality alignments.
	Availability and implementation: The Maligner software is written in C Ã¾Ã¾ and is available at https://github.com/LeeMendelowitz/maligner under the GNU General Public License.Contact: mpop@umiacs.umd.edu VC The Author 2015.
	Published by Oxford University Press.
	All rights reserved.
	For Permissions, please e-mail: journals.permissions@oup.com
	Motivation: The Ensembl Project provides release-specific Perl APIs for efficient high-level programmatic access to data stored in various Ensembl database schema.
	Although Perl scripts are perfectly suited for processing large volumes of text-based data, Perl is not ideal for developing large-scale software applications nor embedding in graphical interfaces.
	The provision of a novel Java API would facilitate type-safe, modular, object-orientated development of new Bioinformatics tools with which to access, analyse and visualize Ensembl data.
	Results: The JEnsembl API implementation provides basic data retrieval and manipulation functionality from the Core, Compara and Variation databases for all species in Ensembl and EnsemblGenomes and is a platform for the development of a richer API to Ensembl datasources.
	The JEnsembl architecture uses a text-based configuration module to provide evolving, versioned mappings from database schema to code objects.
	A single installation of the JEnsembl API can therefore simultaneously and transparently connect to current and previous database instances (such as those in the public archive) thus facilitating better analysis repeatability and allowing 'through time' comparative analyses to be performed.
	Availability: Project development, released code libraries, Maven repository and documentation are hosted at SourceForge (http://jen sembl.sourceforge.net).
	Contact: jensembl-develop@lists.sf.net, andy.law@roslin.ed.ac.uk, trevor.paterson@roslin.ed.ac.uk
	Summary: Identification of metabolites using high-resolution multi-stage mass spectrometry (MSn) data is a significant challenge demanding access to all sorts of computational infrastructures.
	MetiTree is a user-friendly, web application dedicated to organize, process, share, visualize and compare MSn data.
	It integrates several features to export and visualize complex MSn data, facilitating the exploration and interpretation of metabolomics experiments.
	A dedicated spectral tree viewer allows the simultaneous presentation of three related types of MSn data, namely, the spectral data, the fragmentation tree and the fragmentation reactions.
	MetiTree stores the data in an internal database to enable searching for similar fragmentation trees and matching against other MSn data.
	As such MetiTree contains much functionality that will make the difficult task of identifying unknown metabolites much easier.
	Availability: MetiTree is accessible at http://www.MetiTree.nl.
	The source code is available at https://github.com/NetherlandsMetabolo micsCentre/metitree/wiki.
	Contact: m.rojas@lacdr.leidenuniv.nl or t.reijmers@lacdr.leidenuniv.nl
	Motivation: Increasingly, cost-effective high-throughput DNA sequencing technologies are being utilized to sequence human pedigrees to elucidate the genetic cause of a wide variety of human diseases.
	While numerous tools exist for variant prioritization within a single genome, the ability to concurrently analyze variants within pedigrees remains a challenge, especially should there be no prior indication of the underlying genetic cause of the disease.
	Here, we present a tool, variant analysis of sequenced pedigrees (VASP), a flexible data integration environment capable of producing a summary of pedigree variation, providing relevant information such as compound heterozygosity, genome phasing and disease inheritance patterns.
	Designed to aggregate data across a sequenced pedigree, VASP allows both powerful filtering and custom prioritization of both single nucleotide variants (SNVs) and small indels.
	Hence, clinical and research users with prior knowledge of a disease are able to dramatically reduce the variant search space based on a wide variety of custom prioritization criteria.
	Availability and implementation: Source code available for academic non-commercial research purposes at https://github.com/mattmattmattmatt/VASP.Contact: matt.field@anu.edu.au Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Recent advances in high-throughput omics technologies have enabled biomedical researchers to collect large-scale genomic data.
	As a consequence, there has been growing interest in developing methods to integrate such data to obtain deeper insights regarding the underlying biological system.
	A key challenge for integrative studies is the heterogeneity present in the different omics data sources, which makes it difficult to discern the coordinated signal of interest from source-specific noise or extraneous effects.
	Results: We introduce a novel method of multi-modal data analysis that is designed for heterogeneous data based on non-negative matrix factorization.
	We provide an algorithm for jointly decomposing the data matrices involved that also includes a sparsity option for high-dimensional settings.
	The performance of the proposed method is evaluated on synthetic data and on real DNA methylation, gene expression and miRNA expression data from ovarian cancer samples obtained from The Cancer Genome Atlas.
	The results show the presence of common modules across patient samples linked to cancer-related pathways, as well as previously established ovarian cancer subtypes.
	Availability and implementation: The source code repository is publicly available at https://github.com/yangzi4/iNMF.
	Contact: gmichail@umich.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Over the last few years, methods based on suffix arrays using the Burrows-Wheeler Transform have been widely used for DNA sequence read matching and assembly.
	These provide very fast search algorithms, linear in the search pattern size, on a highly compressible representation of the dataset being searched.
	Meanwhile, algorithmic development for genotype data has concentrated on statistical methods for phasing and imputation, based on probabilistic matching to hidden Markov model representations of the reference data, which while powerful are much less computationally efficient.
	Here a theory of haplotype matching using suffix array ideas is developed, which should scale too much larger datasets than those currently handled by genotype algorithms.
	Results: Given M sequences with N bi-allelic variable sites, an O(NM) algorithm to derive a representation of the data based on positional prefix arrays is given, which is termed the positional Burrows-Wheeler transform (PBWT).
	On large datasets this compresses with run-length encoding by more than a factor of a hundred smaller than using gzip on the raw data.
	Using this representation a method is given to find all maximal haplotype matches within the set in O(NM) time rather than O(NM2) as expected from naive pairwise comparison, and also a fast algorithm, empirically independent of M given sufficient memory for indexes, to find maximal matches between a new sequence and the set.
	The discussion includes some proposals about how these approaches could be used for imputation and phasing.
	Availability: http://github.com/richarddurbin/pbwt Contact: richard.durbin@sanger.ac.uk
	Motivation: Gene expression experiments aim to accurately quantify thousands of transcripts in parallel.
	Factors posterior to RNA extraction can, however, impair their accurate representation.
	RNA degradation and differences in the efficiency of amplification affect raw intensity measurements using Affymetrix expression arrays.
	The positional intensity decay of specifically hybridized probes along the transcript they intend to interrogate is used to estimate the RNA quality in a sample and to correct probe intensities for the degradation bias.
	This functionality, for which no previous software solution is available, is implemented in the R/Bioconductor package AffyRNADegradation presented here.
	Availability: The package is available via Bioconductor at the URL http://bioconductor.org/packages/release/bioc/html/AffyRNA Degradation.html Contact: Fasold@izbi.uni-Leipzig.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: ImgLib2 is an open-source Java library for n-dimensional data representation and manipulation with focus on image processing.
	It aims at minimizing code duplication by cleanly separating pixelalgebra, data access and data representation in memory.
	Algorithms can be implemented for classes of pixel types and generic access patterns by which they become independent of the specific dimensionality, pixel type and data representation.
	ImgLib2 illustrates that an elegant high-level programming interface can be achieved without sacrificing performance.
	It provides efficient implementations of common data types, storage layouts and algorithms.
	It is the data model underlying ImageJ2, the KNIME Image Processing toolbox and an increasing number of Fiji-Plugins.
	Availability: ImgLib2 is licensed under BSD.
	Documentation and source code are available at http://imglib2.net and in a public repository at https://github.com/imagej/imglib.Supplementary Information: Supplementary data are available at Bioinformatics Online.
	Contact: saalfeld@mpi-cbg.de
	Motivation: High Throughput Sequencing (HTS) has enabled researchers to probe the human T cell receptor (TCR) repertoire, which consists of many rare sequences.
	Distinguishing between true but rare TCR sequences and variants generated by polymerase chain reaction (PCR) and sequencing errors remains a formidable challenge.
	The conventional approach to handle errors is to remove low quality reads, and/or rare TCR sequences.
	Such filtering discards a large number of true and often rare TCR sequences.
	However, accurate identification and quantification of rare TCR sequences is essential for repertoire diversity estimation.
	Results: We devised a pipeline, called Recover TCR (RTCR), that accurately recovers TCR sequences, including rare TCR sequences, from HTS data (including barcoded data) even at low coverage.
	RTCR employs a data-driven statistical model to rectify PCR and sequencing errors in an adaptive manner.
	Using simulations, we demonstrate that RTCR can easily adapt to the error profiles of different types of sequencers and exhibits consistently high recall and high precision even at low coverages where other pipelines perform poorly.
	Using published real data, we show that RTCR accurately resolves sequencing errors and outperforms all other pipelines.
	Availability and Implementation: The RTCR pipeline is implemented in Python (v2.7) and C and is freely available at http://uubram.github.io/RTCR/along with documentation and examples of typical usage.
	Contact: b.gerritsen@uu.nl
	Summary: Modern biotechnical research is becoming increasingly reliant on computational structural modeling programs to develop novel solutions to scientific questions.
	Rosetta is one such protein modeling suite that has already demonstrated wide applicability to a number of diverse research projects.
	Unfortunately, Rosetta is largely a command-line-driven software package which restricts its use among non-computational researchers.
	Some graphical interfaces for Rosetta exist, but typically are not as sophisticated as commercial software.
	Here, we present InteractiveROSETTA, a graphical interface for the PyRosetta framework that presents easy-to-use controls for several of the most widely used Rosetta protocols alongside a sophisticated selection system utilizing PyMOL as a visualizer.
	InteractiveROSETTA is also capable of interacting with remote Rosetta servers, facilitating sophisticated protocols that are not accessible in PyRosetta or which require greater computational resources.
	Availability and implementation: InteractiveROSETTA is freely available at https://github.com/schenc3/InteractiveROSETTA/releases and relies upon a separate download of PyRosetta which is available at http://www.pyrosetta.org after obtaining a license (free for academic use).Contact: bystrc@rpi.edu
	Motivation: The interpretation of cancer-related single-nucleotide variants (SNVs) considering the protein features they affect, such as known functional sites, protein-protein interfaces, or relation with already annotated mutations, might complement the annotation of genetic variants in the analysis of NGS data.
	Current tools that annotate mutations fall short on several aspects, including the ability to use protein structure information or the interpretation of mutations in protein complexes.
	Results: We present the Structure-PPi system for the comprehensive analysis of coding SNVs based on 3D protein structures of protein complexes.
	The 3D repository used, Interactome3D, includes experimental and modeled structures for proteins and protein-protein complexes.
	Structure-PPi annotates SNVs with features extracted from UniProt, InterPro, APPRIS, dbNSFP and COSMIC databases.
	We illustrate the usefulness of Structure-PPi with the interpretation of 1 027 122 non-synonymous SNVs from COSMIC and the 1000G Project that provides a collection of 172 700 SNVs mapped onto the protein 3D structure of 8726 human proteins (43.2% of the 20 214 SwissProt-curated proteins in UniProtKB release 2014_06) and protein-protein interfaces with potential functional implications.
	Availability and implementation: Structure-PPi, along with a user manual and examples, isavailable at http://structureppi.bioinfo.cnio.es/Structure, the code for local installations at https://github.com/Rbbt-Workflows Contact: tpons@cnio.es Supplementary Information: Supplementary data are available at Bioinformatics online.
	Summary: Drug versus Disease (DvD) provides a pipeline, available through R or Cytoscape, for the comparison of drug and disease gene expression profiles from public microarray repositories.
	Negatively correlated profiles can be used to generate hypotheses of drug-repurposing, whereas positively correlated profiles may be used to infer side effects of drugs.
	DvD allows users to compare drug and disease signatures with dynamic access to databases Array Express, Gene Expression Omnibus and data from the Connectivity Map.
	Availability and implementation: R package (submitted to Bioconductor) under GPL 3 and Cytoscape plug-in freely available for download at www.ebi.ac.uk/saezrodriguez/DVD/.
	Contact: saezrodriguez@ebi.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Measuring differential gene expression is a common task in the analysis of RNA-Seq data.
	To identify differentially expressed genes between two samples, it is crucial to normalize the datasets.
	While multiple normalization methods are available, all of them are based on certain assumptions that may or may not be suitable for the type of data they are applied on.
	Researchers therefore need to select an adequate normalization strategy for each RNA-Seq experiment.
	This selection includes exploration of different normalization methods as well as their comparison.
	Methods that agree with each other most likely represent realistic assumptions under the particular experimental conditions.
	Results: We developed the NVT package, which provides a fast and simple way to analyze and evaluate multiple normalization methods via visualization and representation of correlation values, based on a user-defined set of uniformly expressed genes.
	Availability and Implementation: The R package is freely available under https://github.com/Edert/NVT Contact: thomas.rattei@univie.ac.at Supplementary information: Supplementary data are available at Bioinformatics online.
	pileup.js is a new browser-based genome viewer.
	It is designed to facilitate the investigation of evidence for genomic variants within larger web applications.
	It takes advantage of recent developments in the JavaScript ecosystem to provide a modular, reliable and easily embedded library.
	Availability and implementation: The code and documentation for pileup.js is publicly available at https://github.com/hammerlab/pileup.js under the Apache 2.0 license.Contact: correspondence@hammerlab.org
	Motivation: Cell populations are never truly homogeneous; individual cells exist in biochemical states that define functional differences between them.
	New technology based on microfluidic arrays combined with multiplexed quantitative polymerase chain reactions now enables high-throughput single-cell gene expression measurement, allowing assessment of cellular heterogeneity.
	However, few analytic tools have been developed specifically for the statistical and analytical challenges of single-cell quantitative polymerase chain reactions data.
	Results: We present a statistical framework for the exploration, quality control and analysis of single-cell gene expression data from microfluidic arrays.
	We assess accuracy and within-sample heterogeneity of single-cell expression and develop quality control criteria to filter unreliable cell measurements.
	We propose a statistical model accounting for the fact that genes at the single-cell level can be on (and a continuous expression measure is recorded) or dichotomously off (and the recorded expression is zero).
	Based on this model, we derive a combined likelihood ratio test for differential expression that incorporates both the discrete and continuous components.
	Using an experiment that examines treatment-specific changes in expression, we show that this combined test is more powerful than either the continuous or dichotomous component in isolation, or a t-test on the zero-inflated data.
	Although developed for measurements from a specific platform (Fluidigm), these tools are generalizable to other multi-parametric measures over large numbers of events.
	Availability: All results presented here were obtained using the SingleCellAssay R package available on GitHub (http://github.com/RGLab/SingleCellAssay).
	Contact: rgottard@fhcrc.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Stable isotope-labelling experiments have recently gained increasing popularity in metabolomics studies, providing unique insights into the dynamics of metabolic fluxes, beyond the steadystate information gathered by routine mass spectrometry.
	However, most liquid chromatography-mass spectrometry data analysis software lacks features that enable automated annotation and relative quantification of labelled metabolite peaks.
	Here, we describe mzMatch-ISO, a new extension to the metabolomics analysis pipeline mzMatch.R.
	Results: Targeted and untargeted isotope profiling using mzMatchISO provides a convenient visual summary of the quality and quantity of labelling for every metabolite through four types of diagnostic plots that show (i) the chromatograms of the isotope peaks of each compound in each sample group; (ii) the ratio of mono-isotopic and labelled peaks indicating the fraction of labelling; (iii) the average peak area of mono-isotopic and labelled peaks in each sample group; and (iv) the trend in the relative amount of labelling in a predetermined isotopomer.
	To aid further statistical analyses, the values used for generating these plots are also provided as a tab-delimited file.
	We demonstrate the power and versatility of mzMatch-ISO by analysing a 13C-labelled metabolome dataset from trypanosomal parasites.
	Availability: mzMatch.R and mzMatch-ISO are available free of charge from http://mzmatch.sourceforge.net and can be used on Linux and Windows platforms running the latest version of R. Contact: rainer.breitling@manchester.ac.uk.
	Supplementary information: Supplementary data are available at Bioinformatics online
	Summary: Current web-based genome browsers require repetitious user input to scroll over long distances, alter the drawing density of elements or zoom through multiple orders of magnitude.
	Generally, either the server or the client is responsible for the majority of data processing, resulting in either servers having to receive and handle data relevant only to one user, or clients redundantly processing widely viewed data.
	ChromoZoom pre-renders and caches general-use tracks into tiled images on the server and serves them in an interactive web interface with inertial scrolling and precise, fluent zooming via the mouse wheel or trackpad.
	Custom tracks in several formats can be rendered by client-side code alongside the pre-rendered tracks, minimizing server load because of user-specific rendering and eliminating the need to transmit private data.
	ChromoZoom thereby enables rapid and simultaneous exploration of curated, experimental and personal genomic datasets.
	Availability: Human and yeast genome researchers may browse recent assemblies within ChromoZoom at http://chromozoom.org/.Source code is available at http://github.com/rothlab/chromozoom/.Contact: fritz.roth@utoronto.ca Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Novel technologies brought in unprecedented amounts of high-throughput sequencing data along with great challenges in their analysis and interpretation.
	The percent-spliced-in (PSI, ) metric estimates the incidence of single-exon-skipping events and can be computed directly by counting reads that align to known or predicted splice junctions.
	However, the majority of human splicing events are more complex than single-exon skipping.
	Results: In this short report, we present a framework that generalizes the metric to arbitrary classes of splicing events.
	We change the view from exon centric to intron centric and split the value of into two indices, 5 and 3, measuring the rate of splicing at the 50 and 30 end of the intron, respectively.
	The advantage of having two separate indices is that they deconvolute two distinct elementary acts of the splicing reaction.
	The completeness of splicing index is decomposed in a similar way.
	This framework is implemented as bam2ssj, a BAM-file-processing pipeline for strand-specific counting of reads that align to splice junctions or overlap with splice sites.
	It can be used as a consistent protocol for quantifying splice junctions from RNA-seq data because no such standard procedure currently exists.
	Availability: The CÃ¾Ã¾ code of bam2ssj is open source and is available at https://github.com/pervouchine/bam2ssj Contact: dp@crg.eu
	Motivation: Phylogenies are increasingly used in all fields of medical and biological research.
	Because of the next generation sequencing revolution, datasets used for conducting phylogenetic analyses grow at an unprecedented pace.
	We present ExaML version 3, a dedicated productionlevel code for inferring phylogenies on whole-transcriptome and whole-genome alignments using supercomputers.
	Results: We introduce several improvements and extensions to ExaML: Extensions of substitution models and supported data types, the integration of a novel load balance algorithm as well as a parallel I/O optimization that significantly improve parallel efficiency, and a production-level implementation for Intel MIC-based hardware platforms.
	Availability and implementation: The code is available under GNU GPL at https://github.com/sta matak/ExaML.
	Contact: Alexandros.Stamatakis@h-its.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: PANDA (Passing Attributes between Networks for Data Assimilation) is a gene regulatory network inference method that uses message-passing to integrate multiple sources of 'omics data.
	PANDA was originally coded in C Ã¾Ã¾.
	In this application note we describe PyPanda, the Python version of PANDA.
	PyPanda runs considerably faster than the C Ã¾Ã¾ version and includes additional features for network analysis.
	Availability and implementation: The open source PyPanda Python package is freely available at http://github.com/davidvi/pypanda.Contact: mkuijjer@jimmy.harvard.edu or d.g.p.van_ijzendoorn@lumc.nl
	Summary: Better protocols and decreasing costs have made high-throughput sequencing experiments now accessible even to small experimental laboratories.
	However, comparing one or few experiments generated by an individual lab to the vast amount of relevant data freely available in the public domain might be limited due to lack of bioinformatics expertise.
	Though several tools, including genome browsers, allow such comparison at a single gene level, they do not provide a genome-wide view.
	We developed Heat*seq, a web-tool that allows genome scale comparison of high throughput experiments chromatin immuno-precipitation followed by sequencing, RNAsequencing and Cap Analysis of Gene Expression) provided by a user, to the data in the public domain.
	Heat*seq currently contains over 12 000 experiments across diverse tissues and cell types in human, mouse and drosophila.
	Heat*seq displays interactive correlation heatmaps, with an ability to dynamically subset datasets to contextualize user experiments.
	High quality figures and tables are produced and can be downloaded in multiple formats.
	Availability and Implementation: Web application: http://www.heatstarseq.roslin.ed.ac.uk/.
	Source code: https://github.com/gdevailly.Contact: Guillaume.Devailly@roslin.ed.ac.uk or Anagha.Joshi@roslin.ed.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We have implemented a high-performance computing (HPC) version of ProtTest that can be executed in parallel in multicore desktops and clusters.
	This version, called ProtTest 3, includes new features and extended capabilities.
	Availability: ProtTest 3 source code and binaries are freely available under GNU license for download from http://darwin.uvigo.es/software/prottest3, linked to a Mercurial repository at Bitbucket (https://bitbucket.org/).Contact: dposada@uvigo.es Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Data collection in spreadsheets is ubiquitous, but current solutions lack support for collaborative semantic annotation that would promote shared and interdisciplinary annotation practices, supporting geographically distributed players.
	Results: OntoMaton is an open source solution that brings ontology lookup and tagging capabilities into a cloud-based collaborative editing environment, harnessing Google Spreadsheets and the NCBO Web services.
	It is a general purpose, format-agnostic tool that may serve as a component of the ISA software suite.
	OntoMaton can also be used to assist the ontology development process.
	Availability: OntoMaton is freely available from Google widgets under the CPAL open source license; documentation and examples at: https://github.com/ISA-tools/OntoMaton.Contact: isatools@googlegroups.com
	Summary: Complex computational experiments in Systems Biology, such as fitting model parameters to experimental data, can be challenging to perform.
	Not only do they frequently require a high level of computational power, but the software needed to run the experiment needs to be usable by scientists with varying levels of computational expertise, and modellers need to be able to obtain up-to-date experimental data resources easily.
	We have developed a software suite, the Systems Biology Software Infrastructure (SBSI), to facilitate the parameter-fitting process.
	SBSI is a modular software suite composed of three major components: SBSINumerics, a high-performance library containing parallelized algorithms for performing parameter fitting; SBSIDispatcher, a middleware application to track experiments and submit jobs to back-end servers; and SBSIVisual, an extensible client application used to configure optimization experiments and view results.
	Furthermore, we have created a plugin infrastructure to enable project-specific modules to be easily installed.
	Plugin developers can take advantage of the existing user-interface and application framework to customize SBSI for their own uses, facilitated by SBSI's use of standard data formats.
	Availability and implementation: All SBSI binaries and sourcecode are freely available from http://sourceforge.net/projects/sbsi under an Apache 2 open-source license.
	The server-side SBSINumerics runs on any Unix-based operating system; both SBSIVisual and SBSIDispatcher are written in Java and are platform independent, allowing use on Windows, Linux and Mac OS X.
	The SBSI project website at http://www.sbsi.ed.ac.uk provides documentation and tutorials.
	Contact: stg@inf.ed.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Brain is a Java software library facilitating the manipulation and creation of ontologies and knowledge bases represented with the Web Ontology Language (OWL).
	Availability and implementation: The Java source code and the library are freely available at https://github.com/loopasam/Brain and on the Maven Central repository (GroupId: uk.ac.ebi.brain).
	The documentation is available at https://github.com/loopasam/Brain/wiki.Contact: croset@ebi.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Bioclipse, a graphical workbench for the life sciences, provides functionality for managing and visualizing life science data.
	We introduce Bioclipse-R, which integrates Bioclipse and the statistical programming language R. The synergy between Bioclipse and R is demonstrated by the construction of a decision support system for anticancer drug screening and mutagenicity prediction, which shows how Bioclipse-R can be used to perform complex tasks from within a single software system.
	Availability and implementation: Bioclipse-R is implemented as a set of Java plug-ins for Bioclipse based on the R-package rj.
	Source code and binary packages are available from https://github.com/bioclipse and http://www.bioclipse.net/bioclipse-r, respectively.Contact: martin.eklund@farmbio.uu.se Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The current generation of DNA sequencing technologies produce a large amount of data quickly.
	All of these data need to pass some form of quality control (QC) processing and checking before they can be used for any analysis.
	The large number of samples that are run through Illumina sequencing machines makes the process of QC an onerous and time-consuming task that requires multiple pieces of information from several sources.
	Results: AlmostSignificant is an open-source platform for aggregating multiple sources of quality metrics as well as run and sample meta-data associated with DNA sequencing runs from Illumina sequencing machines.
	AlmostSignificant is a graphical platform to streamline the QC of DNA sequencing data, to store these data for future reference together with extra meta-data associated with the sequencing runs not typically retained.
	This simplifies the challenge of monitoring the volume of data produced by Illumina sequencers.
	AlmostSignificant has been used to track the quality of over 80 sequencing runs covering over 2500 samples produced over the last three years.
	Availability and Implementation: The code and documentation for AlmostSignificant is freely available at https://github.com/bartongroup/AlmostSignificant.Contacts: c.cole@dundee.ac.uk or g.j.barton@dundee.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Sequencing and microarray samples often are collected or processed in multiple batches or at different times.
	This often produces technical biases that can lead to incorrect results in the downstream analysis.
	There are several existing batch adjustment tools for '-omics' data, but they do not indicate a priori whether adjustment needs to be conducted or how correction should be applied.
	We present a software pipeline, BatchQC, which addresses these issues using interactive visualizations and statistics that evaluate the impact of batch effects in a genomic dataset.
	BatchQC can also apply existing adjustment tools and allow users to evaluate their benefits interactively.
	We used the BatchQC pipeline on both simulated and real data to demonstrate the effectiveness of this software toolkit.
	Availability and Implementation: BatchQC is available through Bioconductor: http://bioconductor.org/packages/BatchQC and GitHub: https://github.com/mani2012/BatchQC.Contact: wej@bu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: B-cell receptor (BCR) repertoire profiling is an important tool for understanding the biology of diverse immunologic processes.
	Current methods for analyzing adaptive immune receptor repertoires depend upon PCR amplification of VDJ rearrangements followed by long read amplicon sequencing spanning the VDJ junctions.
	While this approach has proven to be effective, it is frequently not feasible due to cost or limited sample material.
	Additionally, there are many existing datasets where short-read RNA sequencing data are available but PCR amplified BCR data are not.
	Results: We present here V'DJer, an assembly-based method that reconstructs adaptive immune receptor repertoires from short-read RNA sequencing data.
	This method captures expressed BCR loci from a standard RNA-seq assay.
	We applied this method to 473 Melanoma samples from The Cancer Genome Atlas and demonstrate V'DJer's ability to accurately reconstruct BCR repertoires from short read mRNA-seq data.
	Availability and Implementation: V'DJer is implemented in C/C Ã¾Ã¾, freely available for academic use and can be downloaded from Github: https://github.com/mozack/vdjer Contact: benjamin_vincent@med.unc.edu or parkerjs@email.unc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: PhenomeScape is a Cytoscape app which provides easy access to the PhenomeExpress algorithm to interpret gene expression data.
	PhenomeExpress integrates protein interaction networks with known phenotype to gene associations to find active sub-networks enriched in differentially expressed genes.
	It also incorporates cross-species phenotypes and associations to include results from animal models of disease.
	With expression data imported into PhenomeScape, the user can quickly generate and visualise interactive sub-networks.
	PhenomeScape thus enables researchers to use prior knowledge of a disease to identify differentially regulated sub-networks and to generate an overview of altered biologically processes specific to that disease.
	Availability and Implementation: Freely available for download at https://github.com/soulj/PhenomeScape Contact: jamie.soul@postgrad.manchester.ac.uk or jean-marc.schwartz@manchester.ac.uk
	Summary: The Protein Data Bank (PDB) now contains more than 120,000 three-dimensional (3D) structures of biological macromolecules.
	To allow an interpretation of how PDB data relates to other publicly available annotations, we developed a novel data integration platform that maps 3D structural information across various datasets.
	This integration bridges from the human genome across protein sequence to 3D structure space.
	We developed novel software solutions for data management and visualization, while incorporating new libraries for web-based visualization using SVG graphics.
	Availability and Implementation: The new views are available from http://www.rcsb.org and software is available from https://github.com/rcsb/.Contact: andreas.prlic@rcsb.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Ancient DNA (aDNA) molecules in fossilized bones and teeth, coprolites, sediments, mummified specimens and museum collections represent fantastic sources of information for evolutionary biologists, revealing the agents of past epidemics and the dynamics of past populations.
	However, the analysis of aDNA generally faces two major issues.
	Firstly, sequences consist of a mixture of endogenous and various exogenous backgrounds, mostly microbial.
	Secondly, high nucleotide misincorporation rates can be observed as a result of severe post-mortem DNA damage.
	Such misincorporation patterns are instrumental to authenticate ancient sequences versus modern contaminants.
	We recently developed the user-friendly mapDamage package that identifies such patterns from next-generation sequencing (NGS) sequence datasets.
	The absence of formal statistical modeling of the DNA damage process, however, precluded rigorous quantitative comparisons across samples.
	Results: Here, we describe mapDamage 2.0 that extends the original features of mapDamage by incorporating a statistical model of DNA damage.
	Assuming that damage events depend only on sequencing position and post-mortem deamination, our Bayesian statistical framework provides estimates of four key features of aDNA molecules: the average length of overhangs ( ), nick frequency ( ) and cytosine deamination rates in both double-stranded regions ( d) and overhangs ( s).
	Our model enables rescaling base quality scores according to their probability of being damaged.
	mapDamage 2.0 handles NGS datasets with ease and is compatible with a wide range of DNA library protocols.
	Availability: mapDamage 2.0 is available at ginolhac.github.
	io/mapDamage/ as a Python package and documentation is maintained at the Centre for GeoGenetics Web site (geogenetics.ku.dk/ publications/mapdamage2.0/).
	Contact: jonsson.hakon@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: RNA-seq experiments produce digital counts of reads that are affected by both biological and technical variation.
	To distinguish the systematic changes in expression between conditions from noise, the counts are frequently modeled by the Negative Binomial distribution.
	However, in experiments with small sample size, the per-gene estimates of the dispersion parameter are unreliable.
	Method: We propose a simple and effective approach for estimating the dispersions.
	First, we obtain the initial estimates for each gene using the method of moments.
	Second, the estimates are regularized, i.e.
	shrunk towards a common value that minimizes the average squared difference between the initial estimates and the shrinkage estimates.
	The approach does not require extra modeling assumptions, is easy to compute and is compatible with the exact test of differential expression.
	Results: We evaluated the proposed approach using 10 simulated and experimental datasets and compared its performance with that of currently popular packages edgeR, DESeq, baySeq, BBSeq and SAMseq.
	For these datasets, sSeq performed favorably for experiments with small sample size in sensitivity, specificity and computational time.
	Availability: http://www.stat.purdue.edu/~ovitek/Software.html and Bioconductor.
	Contact: ovitek@purdue.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Principal component analysis (PCA) is a basic tool often used in bioinformatics for visualization and dimension reduction.
	However, it is known that PCA may not consistently estimate the true direction of maximal variability in high-dimensional, low sample size settings, which are typical for molecular data.
	Assuming that the underlying signal is sparse, i.e.
	that only a fraction of features contribute to a principal component (PC), this estimation consistency can be retained.
	Most existing sparse PCA methods use L1-penalization, i.e.
	the lasso, to perform feature selection.
	But, the lasso is known to lack variable selection consistency in high dimensions and therefore a subsequent interpretation of selected features can give misleading results.
	Results: We present S4VDPCA, a sparse PCA method that incorporates a subsampling approach, namely stability selection.
	S4VDPCA can consistently select the truly relevant variables contributing to a sparse PC while also consistently estimate the direction of maximal variability.
	The performance of the S4VDPCA is assessed in a simulation study and compared to other PCA approaches, as well as to a hypothetical oracle PCA that 'knows' the truly relevant features in advance and thus finds optimal, unbiased sparse PCs.
	S4VDPCA is computationally efficient and performs best in simulations regarding parameter estimation consistency and feature selection consistency.
	Furthermore, S4VDPCA is applied to a publicly available gene expression data set of medulloblastoma brain tumors.
	Features contributing to the first two estimated sparse PCs represent genes significantly over-represented in pathways typically deregulated between molecular subgroups of medulloblastoma.
	Availability and implementation: Software is available at https://github.com/mwsill/s4vdpca.Contact: m.sill@dkfz.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: High-throughput microscopy data require a diversity of analytical approaches.
	However, the construction of workflows that use algorithms from different software packages is difficult owing to a lack of interoperability.
	To overcome this limitation, we present CellH5, an HDF5 data format for cell-based assays in high-throughput microscopy, which stores high-dimensional image data along with inter-object relations in graphs.
	CellH5Browser, an interactive gallery image browser, demonstrates the versatility and performance of the file format on live imaging data of dividing human cells.
	CellH5 provides new opportunities for integrated data analysis by multiple software platforms.
	Availability: Source code is freely available at www.github.com/cellh5 under the GPL license and at www.bioconductor.org/packages/ release/bioc/html/rhdf5.html under the Artistic-2.0 license.
	Demo datasets and the CellH5Browser are available at www.cellh5.org.
	A Fiji importer for cellh5 will be released soon.
	Contact: daniel.gerlich@imba.oeaw.ac.at or christoph.sommer@ imba.oeaw.ac.at Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: A perennial problem in the analysis of environmental sequence information is the assignment of reads or assembled sequences, e.g.
	contigs or scaffolds, to discrete taxonomic bins.
	In the absence of reference genomes for most environmental microorganisms, the use of intrinsic nucleotide patterns and phylogenetic anchors can improve assembly-dependent binning needed for more accurate taxonomic and functional annotation in communities of microorganisms, and assist in identifying mobile genetic elements or lateral gene transfer events.
	Results: Here, we present a statistic called LCA* inspired by Information and Voting theories that uses the NCBI Taxonomic Database hierarchy to assign taxonomy to contigs assembled from environmental sequence information.
	The LCA* algorithm identifies a sufficiently strong majority on the hierarchy while minimizing entropy changes to the observed taxonomic distribution resulting in improved statistical properties.
	Moreover, we apply results from the order-statistic literature to formulate a likelihood-ratio hypothesis test and P-value for testing the supremacy of the assigned LCA* taxonomy.
	Using simulated and real-world datasets, we empirically demonstrate that votingbased methods, majority vote and LCA*, in the presence of known reference annotations, are consistently more accurate in identifying contig taxonomy than the lowest common ancestor algorithm popularized by MEGAN, and that LCA* taxonomy strikes a balance between specificity and confidence to provide an estimate appropriate to the available information in the data.
	Availability and Implementation: The LCA* has been implemented as a stand-alone Python library compatible with the MetaPathways pipeline; both of which are available on GitHub with installation instructions and use-cases (http://www.github.com/hallamlab/LCAStar/).Contact: shallam@mail.ubc.ca Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Next generation sequencing technologies have provided us with a wealth of information on genetic variation, but predi cting the functional significance of this variation is a difficult task.
	While many comparative genomics studies have focused on gene flux and large scale changes, relatively little attention has been paid to quantifying the effects of single nucleotide polymorphisms and indels on protein function, particularly in bacterial genomics.
	Results: We present a hidden Markov model based approach we call delta-bitscore (DBS) for identifying orthologous proteins that have diverged at the amino acid sequence level in a way that is likely to impact biological function.
	We benchmark this approach with several widely used datasets and apply it to a proof-of-concept study of orthologous proteomes in an investigation of host adaptation in Salmonella enterica.
	We highlight the value of the method in identifying functional divergence of genes, and suggest that this tool may be a better approach than the commonly used dN/dS metric for identifying functionally significant genetic changes occurring in recently diverged organisms.
	Availability and Implementation: A program implementing DBS for pairwise genome comparisons is freely available at: https://github.com/UCanCompBio/deltaBS.Contact: nicole.wheeler@pg.canterbury.ac.nz or lars.barquist@uni-wuerzburg.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Genotype imputation is now commonly performed following genome-wide genotyping experiments.
	Imputation increases the density of analyzed genotypes in the dataset, enabling finemapping across the genome.
	However, the process of imputation using the most recent publicly available reference datasets can require considerable computation power and the management of hundreds of large intermediate files.
	We have developed genipe, a complete genome-wide imputation pipeline which includes automatic reporting, imputed data indexing and management, and a suite of statistical tests for imputed data commonly used in genetic epidemiology (Sequence Kernel Association Test, Cox proportional hazards for survival analysis, and linear mixed models for repeated measurements in longitudinal studies).
	Availability and Implementation: The genipe package is an open source Python software and is freely available for non-commercial use (CC BY-NC 4.0) at https://github.com/pgxcentre/genipe.Documentation and tutorials are available at http://pgxcentre.github.io/genipe.Contact: louis-philippe.lemieux.perreault@statgen.org or marie-pierre.dube@statgen.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Simple Sequence Repeats (SSRs) are used to address a variety of research questions in a variety of fields (e.g.
	population genetics, phylogenetics, forensics, etc.
	), due to their high mutability within and between species.
	Here, we present an innovative algorithm, SA-SSR, based on suffix and longest common prefix arrays for efficiently detecting SSRs in large sets of sequences.
	Existing SSR detection applications are hampered by one or more limitations (i.e.
	speed, accuracy, ease-of-use, etc.).
	Our algorithm addresses these challenges while being the most comprehensive and correct SSR detection software available.
	SA-SSR is 100% accurate and detected >1000 more SSRs than the second best algorithm, while offering greater control to the user than any existing software.
	Availability and implementation: SA-SSR is freely available at http://github.com/ridgelab/SA-SSR Contact: perry.ridge@byu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: LongISLND is a software package designed to simulate sequencing data according to the characteristics of third generation, single-molecule sequencing technologies.
	The general software architecture is easily extendable, as demonstrated by the emulation of Pacific Biosciences (PacBio) multi-pass sequencing with P5 and P6 chemistries, producing data in FASTQ, H5, and the latest PacBio BAM format.
	We demonstrate its utility by downstream processing with consensus building and variant calling.
	Availability and Implementation: LongISLND is implemented in Java and available at http://bioin form.github.io/longislnd Contact: hugo.lam@roche.com Supplementary information: Supplementary data are available at Bioinformatics online.
	As microbial ecologists take advantage of high-throughput analytical techniques to describe microbial communities across everincreasing numbers of samples, the need for new analysis tools that reveal the intrinsic spatial patterns and structures of these populations is crucial.
	Here we present SitePainter, an interactive graphical tool that allows investigators to create or upload pictures of their study site, load diversity analyses data and display both diversity and taxonomy results in a spatial context.
	Features of SitePainter include: visualizing Î±-diversity, using taxonomic summaries; visualizing Î²-diversity, using results from multidimensional scaling methods; and animating relationships among microbial taxa or pathways overtime.
	SitePainter thus increases the visual power and ability to explore spatially explicit studies.
	Availability: https://sourceforge.net/projects/sitepainter Supplementary information: Supplementary data are available at Bioinformatics online.
	Contact: antoniog@colorado.edu, Rob.Knight@colorado.edu
	Motivation: RUbioSeq has been developed to facilitate the primary and secondary analysis of re-sequencing projects by providing an integrated software suite of parallelized pipelines to detect exome variants (single-nucleotide variants and copy number variations) and to perform bisulfite-seq analyses automatically.
	RUbioSeq's variant analysis results have been already validated and published.
	Availability: http://rubioseq.sourceforge.net/.Contact: mrubioc@cnio.es
	Summary: The increasing availability of high-throughput sequencing technologies has led to thousands of human genomes having been sequenced in the past years.
	Efforts such as the 1000 Genomes Project further add to the availability of human genome variation data.
	However, to date, there is no method that can map reads of a newly sequenced human genome to a large collection of genomes.
	Instead, methods rely on aligning reads to a single reference genome.
	This leads to inherent biases and lower accuracy.
	To tackle this problem, a new alignment tool BWBBLE is introduced in this article.
	We (i) introduce a new compressed representation of a collection of genomes, which explicitly tackles the genomic variation observed at every position, and (ii) design a new alignment algorithm based on the Burrows-Wheeler transform that maps short reads from a newly sequenced genome to an arbitrary collection of two or more (up to millions of) genomes with high accuracy and no inherent bias to one specific genome.
	Availability: http://viq854.github.com/bwbble.Contact: serafim@cs.stanford.edu
	Summary: BamView is an interactive Java application for visualizing the large amounts of data stored for sequence reads which are aligned against a reference genome sequence.
	It supports the BAM (Binary Alignment/Map) format.
	It can be used in a number of contexts including SNP calling and structural annotation.
	BamView has also been integrated into Artemis so that the reads can be viewed in the context of the nucleotide sequence and genomic features.
	Availability: BamView and Artemis are freely available (under a GPL licence) for download (for MacOSX, UNIX and Windows) at: http://bamview.sourceforge.net/Contact: artemis@sanger.ac.uk
	Motivation: For genetic studies, statistically significant variants explain far less trait variance than 'sub-threshold' association signals.
	To dimension follow-up studies, researchers need to accurately estimate 'true' effect sizes at each SNP, e.g.
	the true mean of odds ratios (ORs)/regression coefficients (RRs) or Z-score noncentralities.
	NaÄ±Â¨ve estimates of effect sizes incur winner's curse biases, which are reduced only by laborious winner's curse adjustments (WCAs).
	Given that Z-scores estimates can be theoretically translated on other scales, we propose a simple method to compute WCA for Z-scores, i.e.
	their true means/noncentralities.
	Results:WCA of Z-scores shrinks these towards zero while, on P-value scale, multiple testing adjustment (MTA) shrinks P-values toward one, which corresponds to the zero Z-score value.
	Thus, WCA on Z-scores scale is a proxy for MTA on P-value scale.
	Therefore, to estimate Z-score noncentralities for all SNPs in genome scans, we propose FDR Inverse Quantile Transformation (FIQT).
	It (i) performs the simpler MTA of P-values using FDR and (ii) obtains noncentralities by backtransforming MTA P-values on Z-score scale.
	When compared to competitors, realistic simulations suggest that FIQT is more (i) accurate and (ii) computationally efficient by orders of magnitude.
	Practical application of FIQT to Psychiatric Genetic Consortium schizophrenia cohort predicts a non-trivial fraction of sub-threshold signals which become significant in much larger supersamples.
	Conclusions: FIQT is a simple, yet accurate, WCA method for Z-scores (and ORs/RRs, via simple transformations).
	Availability and Implementation: A 10 lines R function implementation is available at https://github.com/bacanusa/FIQT.
	Contact: sabacanu@vcu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: One of the main goals of large scale methylation studies is to detect differentially methylated loci.
	One way is to approach this problem sitewise, i.e.
	to find differentially methylated positions (DMPs).
	However, it has been shown that methylation is regulated in longer genomic regions.
	So it is more desirable to identify differentially methylated regions (DMRs) instead of DMPs.
	The new high coverage arrays, like Illuminas 450k platform, make it possible at a reasonable cost.
	Few tools exist for DMR identification from this type of data, but there is no standard approach.
	Results: We propose a novel method for DMR identification that detects the region boundaries according to the minimum description length (MDL) principle, essentially solving the problem of model selection.
	The significance of the regions is established using linear mixed models.
	Using both simulated and large publicly available methylation datasets, we compare seqlm performance to alternative approaches.
	We demonstrate that it is both more sensitive and specific than competing methods.
	This is achieved with minimal parameter tuning and, surprisingly, quickest running time of all the tried methods.
	Finally, we show that the regional differential methylation patterns identified on sparse array data are confirmed by higher resolution sequencing approaches.
	Availability and Implementation: The methods have been implemented in R package seqlm that is available through Github: https://github.com/raivokolde/seqlm Contact: rkolde@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Synthetic biology has become a widely used technology, and expanding applications in research, education and industry require progress tracking for team-based DNA synthesis projects.
	Although some vendors are beginning to supply multi-kilobase sequence-verified constructs, synthesis workflows starting with short oligos remain important for cost savings and pedagogical benefit.
	We developed BIOPARTSDB as an open source, extendable workflow management system for synthetic biology projects with entry points for oligos and larger DNA constructs and ending with sequence-verified clones.
	Availability and Implementation: BIOPARTSDB is released under the MIT license and available for download at https://github.com/baderzone/biopartsdb.
	Additional documentation and video tutorials are available at https://github.com/baderzone/biopartsdb/wiki.
	An Amazon Web Services image is available from the AWS Market Place (ami-a01d07c8).
	Contact: joel.bader@jhu.edu
	Summary: One of the major issues in genome-wide association studies is to solve the missing heritability problem.
	While considering epistatic interactions among multiple SNPs may contribute to solving this problem, existing software cannot detect statistically significant high-order interactions.
	We propose software named LAMPLINK, which employs a cutting-edge method to enumerate statistically significant SNP combinations from genome-wide case-control data.
	LAMPLINK is implemented as a set of additional functions to PLINK, and hence existing procedures with PLINK can be applicable.
	Applied to the 1000 Genomes Project data, LAMPLINK detected a combination of five SNPs that are statistically significantly accumulated in the Japanese population.
	Availability and Implementation: LAMPLINK is available at http://a-terada.github.io/lamplink/.Contact: terada@cbms.k.u-tokyo.ac.jp or sese.jun@aist.go.jp Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Permutational non-Euclidean analysis of variance, PERMANOVA, is routinely used in exploratory analysis of multivariate datasets to draw conclusions about the significance of patterns visualized through dimension reduction.
	This method recognizes that pairwise distance matrix between observations is sufficient to compute within and between group sums of squares necessary to form the (pseudo) F statistic.
	Moreover, not only Euclidean, but arbitrary distances can be used.
	This method, however, suffers from loss of power and type I error inflation in the presence of heteroscedasticity and sample size imbalances.
	Results: We develop a solution in the form of a distance-based Welch t-test, T W2, for two sample potentially unbalanced and heteroscedastic data.
	We demonstrate empirically the desirable type I error and power characteristics of the new test.
	We compare the performance of PERMANOVA and T W2 in reanalysis of two existing microbiome datasets, where the methodology has originated.
	Availability and Implementation: The source code for methods and analysis of this article is available at https://github.com/alekseyenko/Tw2.
	Further guidance on application of these methods can be obtained from the author.
	Contact: alekseye@musc.edu
	Motivation: To provide consistent computable descriptions of phenotype data, PomBase is developing a formal ontology of phenotypes observed in fission yeast.
	Results: The fission yeast phenotype ontology (FYPO) is a modular ontology that uses several existing ontologies from the open biological and biomedical ontologies (OBO) collection as building blocks, including the phenotypic quality ontology PATO, the Gene Ontology and Chemical Entities of Biological Interest.
	Modular ontology development facilitates partially automated effective organization of detailed phenotype descriptions with complex relationships to each other and to underlying biological phenomena.
	As a result, FYPO supports sophisticated querying, computational analysis and comparison between different experiments and even between species.
	Availability: FYPO releases are available from the Subversion repository at the PomBase SourceForge project page (https://sourceforge.net/p/pombase/code/HEAD/tree/phenotype_ontology/).
	The current version of FYPO is also available on the OBO Foundry Web site (http://obofoundry.org/).Contact: mah79@cam.ac.uk or vw253@cam.ac.uk
	Summary: Pathview is a novel tool set for pathway-based data integration and visualization.
	It maps and renders user data on relevant pathway graphs.
	Users only need to supply their data and specify the target pathway.
	Pathview automatically downloads the pathway graph data, parses the data file, maps and integrates user data onto the pathway and renders pathway graphs with the mapped data.
	Although built as a stand-alone program, Pathview may seamlessly integrate with pathway and functional analysis tools for large-scale and fully automated analysis pipelines.
	Availability: The package is freely available under the GPLv3 license through Bioconductor and R-Forge.
	It is available at http://bioconduc tor.org/packages/release/bioc/html/pathview.html and at http://Pathview.r-forge.r-project.org/.
	Contact: luo_weijun@yahoo.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Drawing genomic features in attractive and informative ways is a key task in visualization of genomics data.
	Scalable Vector Graphics (SVG) format is a modern and flexible open standard that provides advanced features including modular graphic design, advanced web interactivity and animation within a suitable client.
	SVGs do not suffer from loss of image quality on re-scaling and provide the ability to edit individual elements of a graphic on the whole object level independent of the whole image.
	These features make SVG a potentially useful format for the preparation of publication quality figures including genomic objects such as genes or sequencing coverage and for web applications that require rich user-interaction with the graphical elements.
	Results: SVGenes is a Ruby-language library that uses SVG primitives to render typical genomic glyphs through a simple and flexible Ruby interface.
	The library implements a simple Page object that spaces and contains horizontal Track objects that in turn style, colour and positions features within them.
	Tracks are the level at which visual information is supplied providing the full styling capability of the SVG standard.
	Genomic entities like genes, transcripts and histograms are modelled in Glyph objects that are attached to a track and take advantage of SVG primitives to render the genomic features in a track as any of a selection of defined glyphs.
	The feature model within SVGenes is simple but flexible and not dependent on particular existing gene feature formats meaning graphics for any existing datasets can easily be created without need for conversion.
	Availability: The library is provided as a Ruby Gem from https://rubygems.org/gems/bio-svgenes under the MIT license, and open source code is available at https://github.com/danmaclean/bioruby-svgenes also under the MIT License.
	Contact: dan.maclean@tsl.ac.uk
	Summary: We present Mutascope, a sequencing analysis pipeline specifically developed for the identification of somatic variants present at low-allelic fraction from high-throughput sequencing of amplicons from matched tumor-normal specimen.
	Using datasets reproducing tumor genetic heterogeneity, we demonstrate that Mutascope has a higher sensitivity and generates fewer false-positive calls than tools designed for shotgun sequencing or diploid genomes.
	Availability: Freely available on the web at http://sourceforge.net/projects/mutascope/.
	Contact: oharismendy@ucsd.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Protein-protein interaction (PPI) studies have dramatically expanded our knowledge about cellular behaviour and development in different conditions.
	A multitude of high-throughput PPI techniques have been developed to achieve proteome-scale coverage for PPI studies, including the microarray based Mammalian Protein-Protein Interaction Trap (MAPPIT) system.
	Because such high-throughput techniques typically report thousands of interactions, managing and analysing the large amounts of acquired data is a challenge.
	We have therefore built the MAPPIT cell microArray Protein Protein Interaction-Data management & Analysis Tool (MAPPI-DAT) as an automated data management and analysis tool for MAPPIT cell microarray experiments.
	MAPPI-DAT stores the experimental data and metadata in a systematic and structured way, automates data analysis and interpretation, and enables the meta-analysis of MAPPIT cell microarray data across all stored experiments.
	Availability and Implementation: MAPPI-DAT is developed in Python, using R for data analysis and MySQL as data management system.
	MAPPI-DAT is cross-platform and can be ran on Microsoft Windows, Linux and OS X/macOS.
	The source code and a Microsoft Windows executable are freely available under the permissive Apache2 open source license at https://github.com/compomics/MAPPI-DAT.
	Contact: jan.tavernier@vib-ugent.be or lennart.martens@vib-ugent.be Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Most RNA molecules form internal base pairs, leading to a folded secondary structure.
	Some of these structures have been demonstrated to be functionally significant.
	High-throughput RNA structure chemical probing methods generate millions of sequencing reads to provide structural constraints for RNA secondary structure prediction.
	At present, processed data from these experiments are difficult to access without computational expertise.
	Here we present FoldAtlas, a web interface for accessing raw and processed structural data across thousands of transcripts.
	FoldAtlas allows a researcher to easily locate, view, and retrieve probing data for a given RNA molecule.
	We also provide in silico and in vivo secondary structure predictions for comparison, visualized in the browser as circle plots and topology diagrams.
	Data currently integrated into FoldAtlas are from a new high-depth Structure-seq data analysis in Arabidopsis thaliana, released with this work.
	Availability and Implementation: The FoldAtlas website can be accessed at www.foldatlas.com.
	Source code is freely available at github.com/mnori/foldatlas under the MIT license.
	Raw reads data are available under the NCBI SRA accession SRP066985.
	Contact: yiliang.ding@jic.ac.uk or matthew.norris@jic.ac.uk.
	Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The highly portable Oxford Nanopore MinION sequencer has enabled new applications of genome sequencing directly in the field.
	However, the MinION currently relies on a cloud computing platform, Metrichor (metrichor.com), for translating locally generated sequencing data into basecalls.
	Results: To allow offline and private analysis of MinION data, we created Nanocall.
	Nanocall is the first freely available, open-source basecaller for Oxford Nanopore sequencing data and does not require an internet connection.
	Using R7.3 chemistry, on two E.coli and two human samples, with natural as well as PCR-amplified DNA, Nanocall reads have 68% identity, directly comparable to Metrichor '1D' data.
	Further, Nanocall is efficient, processing 2500 Kbp of sequence per core hour using the fastest settings, and fully parallelized.
	Using a 4 core desktop computer, Nanocall could basecall a MinION sequencing run in real time.
	Metrichor provides the ability to integrate the '1D' sequencing of template and complement strands of a single DNA molecule, and create a '2D' read.
	Nanocall does not currently integrate this technology, and addition of this capability will be an important future development.
	In summary, Nanocall is the first open-source, freely available, off-line basecaller for Oxford Nanopore sequencing data.
	Availability and Implementation: Nanocall is available at github.com/mateidavid/nanocall, released under the MIT license.
	Contact: matei.david@oicr.on.ca Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: DAPAR and ProStaR are software tools to perform the statistical analysis of label-free XIC-based quantitative discovery proteomics experiments.
	DAPAR contains procedures to filter, normalize, impute missing value, aggregate peptide intensities, perform null hypothesis significance tests and select the most likely differentially abundant proteins with a corresponding false discovery rate.
	ProStaR is a graphical user interface that allows friendly access to the DAPAR functionalities through a web browser.
	Availability and implementation: DAPAR and ProStaR are implemented in the R language and are available on the website of the Bioconductor project (http://www.bioconductor.org/).
	A complete tutorial and a toy dataset are accompanying the packages.
	Contact: samuel.wieczorek@cea.fr, florence.combes@cea.fr, thomas.burger@cea.fr
	Summary: We introduce the caspo toolbox, a python package implementing a workflow for reasoning on logical networks families.
	Our software allows researchers to (i) learn a family of logical networks derived from a given topology and explaining the experimental response to various perturbations; (ii) classify all logical networks in a given family by their input-output behaviors; (iii) predict the response of the system to every possible perturbation based on the ensemble of predictions; (iv) design new experimental perturbations to discriminate among a family of logical networks; and (v) control a family of logical networks by finding all interventions strategies forcing a set of targets into a desired steady state.
	Availability and Implementation: caspo is open-source software distributed under the GPLv3 license.
	Source code is publicly hosted at http://github.com/bioasp/caspo.Contact: anne.siegel@irisa.fr
	Motivation: Deep metagenomic sequencing of biological samples has the potential to recover otherwise difficult-to-detect microorganisms and accurately characterize biological samples with limited prior knowledge of sample contents.
	Existing metagenomic taxonomic classification algorithms, however, do not scale well to analyze large metagenomic datasets, and balancing classification accuracy with computational efficiency presents a fundamental challenge.
	Results: A method is presented to shift computational costs to an offline computation by creating a taxonomy/genome index that supports scalable metagenomic classification.
	Scalable performance is demonstrated on real and simulated data to show accurate classification in the presence of novel organisms on samples that include viruses, prokaryotes, fungi and protists.
	Taxonomic classification of the previously published 150 giga-base Tyrolean Iceman dataset was found to take 520 h on a single node 40 core large memory machine and provide new insights on the metagenomic contents of the sample.
	Availability: Software was implemented in CÃ¾Ã¾ and is freely available at http://sourceforge.net/projects/lmat Contact: allen99@llnl.gov Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: RNA sequencing is now widely performed to study differential expression among experimental conditions.
	As tests are performed on a large number of genes, stringent false-discovery rate control is required at the expense of detection power.
	Ad hoc filtering techniques are regularly used to moderate this correction by removing genes with low signal, with little attention paid to their impact on downstream analyses.
	Results: We propose a data-driven method based on the Jaccard similarity index to calculate a filtering threshold for replicated RNA sequencing data.
	In comparisons with alternative data filters regularly used in practice, we demonstrate the effectiveness of our proposed method to correctly filter lowly expressed genes, leading to increased detection power for moderately to highly expressed genes.
	Interestingly, this data-driven threshold varies among experiments, highlighting the interest of the method proposed here.
	Availability: The proposed filtering method is implemented in the R package HTSFilter available on Bioconductor.
	Contact: andrea.rau@jouy.inra.fr Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: DMEAS is the first user-friendly tool dedicated to analyze the distribution of DNA methylation patterns for the quantification of epigenetic heterogeneity.
	It supports the analysis of both locus-specific and genome-wide bisulfite sequencing data.
	DMEAS progressively scans the mapping results of bisulfite sequencing reads to extract DNA methylation patterns for contiguous CpG dinucleotides.
	It determines the DNA methylation level and calculates methylation entropy for genomic segments to enable the quantitative assessment of DNA methylation variations observed in cell populations.
	Availability and implementation: DMEAS program, user guide and all the testing data are freely available from http://sourceforge.net/projects/dmeas/files/ Contact: davidxie@vt.edu Supplementary Information: Supplementary data are available at Bioinformatics online.
	Summary: We have developed Cake, a bioinformatics software pipeline that integrates four publicly available somatic variant-calling algorithms to identify single nucleotide variants with higher sensitivity and accuracy than any one algorithm alone.
	Cake can be run on a highperformance computer cluster or used as a stand-alone application.
	Availabilty: Cake is open-source and is available from http://cakeso matic.sourceforge.net/ Contact: da1@sanger.ac.uk Supplementary Information: Supplementary data are available at Bioinformatics online.
	Motivation: The simplifying assumptions that are used widely in theoretical population genetics may not always be appropriate for empirical population genetics.
	General computational approaches that do not require the assumptions of classical theory are therefore quite desirable.
	One such general approach is provided by the theory of absorbing Markov chains, which can be used to obtain exact results by directly analyzing population genetic Markov models, such as the classic bi-allelic Wright-Fisher model.
	Although these approaches are sometimes used, they are usually forgone in favor of simulation methods, due to the perception that they are too computationally burdensome.
	Here we show that, surprisingly, direct analysis of virtually any Markov chain model in population genetics can be made quite efficient by exploiting transition matrix sparsity and by solving restricted systems of linear equations, allowing a wide variety of exact calculations (within machine precision) to be easily and rapidly made on modern workstation computers.
	Results: We introduce Wright-Fisher Exact Solver (WFES), a fast and scalable method for direct analysis of Markov chain models in population genetics.
	WFES can rapidly solve for both longterm and transient behaviours including fixation and extinction probabilities, expected times to fixation or extinction, sojourn times, expected allele age and variance, and others.
	Our implementation requires only seconds to minutes of runtime on modern workstations and scales to biological population sizes ranging from humans to model organisms.
	Availability and Implementation: The code is available at https://github.com/dekoning-lab/wfes Contact: jason.dekoning@ucalgary.ca Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Codon models are widely used to identify the signature of selection at the molecular level and to test for changes in selective pressure during the evolution of genes encoding proteins.
	The large size of the state space of the Markov processes used to model codon evolution makes it difficult to use these models with large biological datasets.
	We propose here to use state aggregation to reduce the state space of codon models and, thus, improve the computational performance of likelihood estimation on these models.
	Results: We show that this heuristic speeds up the computations of the M0 and branch-site models up to 6.8 times.
	We also show through simulations that state aggregation does not introduce a detectable bias.
	We analyzed a real dataset and show that aggregation provides highly correlated predictions compared to the full likelihood computations.
	Finally, state aggregation is a very general approach and can be applied to any continuous-time Markov process-based model with large state space, such as amino acid and coevolution models.
	We therefore discuss different ways to apply state aggregation to Markov models used in phylogenetics.
	Availability and Implementation: The heuristic is implemented in the godon package (https://bit bucket.org/Davydov/godon) and in a version of FastCodeML (https://gitlab.isb-sib.ch/phylo/fastcodeml).
	Contact: nicolas.salamin@unil.ch Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Flux balance analysis and its variants are widely used methods for predicting steadystate reaction rates in biochemical reaction networks.
	The exploration of high dimensional networks with such methods is currently hampered by software performance limitations.
	Results: DistributedFBA.jl is a high-level, high-performance, open-source implementation of flux balance analysis in Julia.
	It is tailored to solve multiple flux balance analyses on a subset or all the reactions of large and huge-scale networks, on any number of threads or nodes.
	Availability and Implementation: The code is freely available on github.com/opencobra/COBRA.jl.
	The documentation can be found at opencobra.github.io/COBRA.jl.
	Contact: ronan.mt.fleming@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: The Web Ontology Language (OWL) provides a sophisticated language for building complex domain ontologies and is widely used in bio-ontologies such as the Gene Ontology.
	The Prot eÂ´g eÂ´-OWL ontology editing tool provides a query facility that allows composition and execution of queries with the human-readable Manchester OWL syntax, with syntax checking and entity label lookup.
	No equivalent query facility such as the ProteÂ´ g eÂ´ Description Logics (DL) query yet exists in web form.
	However, many users interact with bio-ontologies such as chemical entities of biological interest and the Gene Ontology using their online Web sites, within which DL-based querying functionality is not available.
	To address this gap, we introduce the OntoQuery web-based query utility.
	Availability and implementation: The source code for this implementation together with instructions for installation is available at http://github.com/IlincaTudose/OntoQuery.
	OntoQuery software is fully compatible with all OWL-based ontologies and is available for download (CC-0 license).
	The ChEBI installation, ChEBI OntoQuery, is available at http://www.ebi.ac.uk/chebi/tools/ontoquery.Contact: hastings@ebi.ac.uk
	Motivation: Gene set enrichment (GSE) analysis allows researchers to efficiently extract biological insight from long lists of differentially expressed genes by interrogating them at a systems level.
	In recent years, there has been a proliferation of GSE analysis methods and hence it has become increasingly difficult for researchers to select an optimal GSE tool based on their particular dataset.
	Moreover, the majority of GSE analysis methods do not allow researchers to simultaneously compare gene set level results between multiple experimental conditions.
	Results: The ensemble of genes set enrichment analyses (EGSEA) is a method developed for RNA-sequencing data that combines results from twelve algorithms and calculates collective gene set scores to improve the biological relevance of the highest ranked gene sets.
	EGSEA's gene set database contains around 25 000 gene sets from sixteen collections.
	It has multiple visualization capabilities that allow researchers to view gene sets at various levels of granularity.
	EGSEA has been tested on simulated data and on a number of human and mouse datasets and, based on biologists' feedback, consistently outperforms the individual tools that have been combined.
	Our evaluation demonstrates the superiority of the ensemble approach for GSE analysis, and its utility to effectively and efficiently extrapolate biological functions and potential involvement in disease processes from lists of differentially regulated genes.
	Availability and Implementation: EGSEA is available as an R package at http://www.bioconductor.org/packages/EGSEA/.
	The gene sets collections are available in the R package EGSEAdata from http://www.bioconductor.org/packages/EGSEAdata/.Contacts:monther.alhamdoosh@csl.com.au ormritchie@wehi.edu.au Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Spatial Kappa is a simulator of models written in a variant of the rule-based stochastic modelling language Kappa, with spatial extensions.
	Availability: The spatial kappa simulator is an open-source project licensed under the LGPLv3, with Java source, binaries and manual available at http://github.com/lptolik/SpatialKappa.Contact: oksana.sorokina@ed.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Many bioinformatics algorithms are designed for the analysis of sequences of some uniform length, conventionally referred to as k-mers.
	These include de Bruijn graph assembly methods and sequence alignment tools.
	An efficient algorithm to enumerate the number of unique k-mers, or even better, to build a histogram of k-mer frequencies would be desirable for these tools and their downstream analysis pipelines.
	Among other applications, estimated frequencies can be used to predict genome sizes, measure sequencing error rates, and tune runtime parameters for analysis tools.
	However, calculating a k-mer histogram from large volumes of sequencing data is a challenging task.
	Results: Here, we present ntCard, a streaming algorithm for estimating the frequencies of k-mers in genomics datasets.
	At its core, ntCard uses the ntHash algorithm to efficiently compute hash values for streamed sequences.
	It then samples the calculated hash values to build a reduced representation multiplicity table describing the sample distribution.
	Finally, it uses a statistical model to reconstruct the population distribution from the sample distribution.
	We have compared the performance of ntCard and other cardinality estimation algorithms.
	We used three datasets of 480 GB, 500 GB and 2.4 TB in size, where the first two representing whole genome shotgun sequencing experiments on the human genome and the last one on the white spruce genome.
	Results show ntCard estimates k-mer coverage frequencies >15 faster than the state-of-the-art algorithms, using similar amount of memory, and with higher accuracy rates.
	Thus, our benchmarks demonstrate ntCard as a potentially enabling technology for large-scale genomics applications.
	Availability and Implementation: ntCard is written in C Ã¾Ã¾ and is released under the GPL license.
	It is freely available at https://github.com/bcgsc/ntCard.Contact: hmohamadi@bcgsc.ca or ibirol@bcgsc.ca Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Recent transcriptome studies have revealed that total transcript numbers vary by cell type and condition; therefore, the statistical assumptions for single-cell transcriptome studies must be revisited.
	SAMstrt is an extension code for SAMseq, which is a statistical method for differential expression, to enable spike-in normalization and statistical testing based on the estimated absolute number of transcripts per cell for single-cell RNA-seq methods.
	Availability and Implementation: SAMstrt is implemented on R and available in github (https://github.com/shka/R-SAMstrt).Contact: shintaro.katayama@ki.se Supplementary Information: Supplementary data are available at Bioinformatics online.
	Motivation: The ability to centralize and store data for long periods on an end user's computational resources is increasingly difficult for many scientific disciplines.
	For example, genomics data is increasingly large and distributed, and the data needs to be moved into workflow execution sites ranging from lab workstations to the cloud.
	However, the typical user is not always informed on emerging network technology or the most efficient methods to move and share data.
	Thus, the user defaults to using inefficient methods for transfer across the commercial internet.
	Results: To accelerate large data transfer, we created a tool called the Big Data Smart Socket (BDSS) that abstracts data transfer methodology from the user.
	The user provides BDSS with a manifest of datasets stored in a remote storage repository.
	BDSS then queries a metadata repository for curated data transfer mechanisms and optimal path to move each of the files in the manifest to the site of workflow execution.
	BDSS functions as a standalone tool or can be directly integrated into a computational workflow such as provided by the Galaxy Project.
	To demonstrate applicability, we use BDSS within a biological context, although it is applicable to any scientific domain.
	Availability and Implementation: BDSS is available under version 2 of the GNU General Public License at https://github.com/feltus/BDSS.Contact: ffeltus@clemson.edu
	Summary: Ancient DNA has emerged as a remarkable tool to infer the history of extinct species and past populations.
	However, many of its characteristics, such as extensive fragmentation, damage and contamination, can influence downstream analyses.
	To help investigators measure how these could impact their analyses in silico, we have developed gargammel, a package that simulates ancient DNA fragments given a set of known reference genomes.
	Our package simulates the entire molecular process from post-mortem DNA fragmentation and DNA damage to experimental sequencing errors, and reproduces most common bias observed in ancient DNA datasets.
	Availability and Implementation: The package is publicly available on github: https://grenaud.github.io/gargammel/ and released under the GPL.
	Contact: gabriel.renaud@snm.ku.dk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Fast and accurate quality control is essential for studies involving next-generation sequencing data.
	Whilst numerous tools exist to quantify QC metrics, there is no common approach to flexibly integrate these across tools and large sample sets.
	Assessing analysis results across an entire project can be time consuming and error prone; batch effects and outlier samples can easily be missed in the early stages of analysis.
	Results: We present MultiQC, a tool to create a single report visualising output from multiple tools across many samples, enabling global trends and biases to be quickly identified.
	MultiQC can plot data from many common bioinformatics tools and is built to allow easy extension and customization.
	Availability and implementation: MultiQC is available with an GNU GPLv3 license on GitHub, the Python Package Index and Bioconda.
	Documentation and example reports are available at http://multiqc.info Contact: phil.ewels@scilifelab.se
	Motivation: Although several methods exist to relate high-dimensional gene expression data to various clinical phenotypes, finding combinations of features in such input remains a challenge, particularly when fitting complex statistical models such as those used for survival studies.
	Results: Our proposed method builds on existing 'regularization pathfollowing' techniques to produce regression models that can extract arbitrarily complex patterns of input features (such as gene combinations) from large-scale data that relate to a known clinical outcome.
	Through the use of the data's structure and itemset mining techniques, we are able to avoid combinatorial complexity issues typically encountered with such methods, and our algorithm performs in similar orders of duration as single-variable versions.
	Applied to data from various clinical studies of cancer patient survival time, our method was able to produce a number of promising gene-interaction candidates whose tumour-related roles appear confirmed by literature.
	Availability: An R implementation of the algorithm described in this article can be found at https://github.com/david-duverle/regularisa tion-path-following Contact: dave.duverle@aist.go.jp Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Database search is the most widely used approach for peptide and protein identification in mass spectrometry-based proteomics studies.
	Our previous study showed that sample-specific protein databases derived from RNA-Seq data can better approximate the real protein pools in the samples and thus improve protein identification.
	More importantly, single nucleotide variations, short insertion and deletions and novel junctions identified from RNA-Seq data make protein database more complete and sample-specific.
	Here, we report an R package customProDB that enables the easy generation of customized databases from RNA-Seq data for proteomics search.
	This work bridges genomics and proteomics studies and facilitates crossomics data integration.
	Availability and implementation: customProDB and related documents are freely available at http://bioconductor.org/packages/2.13/bioc/html/customProDB.html.
	Contact: bing.zhang@vanderbilt.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The application of a genomics assay to samples from a cohort is a frequently applied experimental design in cancer genomics studies.
	The collection and analysis of cancer sequencing data in the clinical setting is an elaborate process that may involve consenting patients, obtaining possibly-multiple DNA samples, sequencing and analysis.
	Many of these steps are manual.
	At any stage mistakes can occur that cause a DNA sample to be labelled incorrectly.
	However, there is a paucity of methods in the literature to identify such swaps specifically in cancer studies.
	Results: Here, we introduce a simple method, HYSYS, to estimate the relatedness of samples and test for sample swaps and contamination.
	The test uses the concordance of homozygous SNPs between samples.
	The method is motivated by the observation that homozygous germline population variants rarely change in the disease and are not affected by loss of heterozygosity.
	Our tools include visualization and a testing framework to flag possible sample swaps.
	We demonstrate the utility of this approach on a small cohort.
	Availability and Implementation:http://github.com/PapenfussLab/HaveYouSwappedYourSamples Contact: papenfuss@wehi.edu.au Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Leveraging gene expression data through large-scale integrative analyses for multicellular organisms is challenging because most samples are not fully annotated to their tissue/cell-type of origin.
	A computational method to classify samples using their entire gene expression profiles is needed.
	Such a method must be applicable across thousands of independent studies, hundreds of gene expression technologies and hundreds of diverse human tissues and cell-types.
	Results: We present Unveiling RNA Sample Annotation (URSA) that leverages the complex tissue/cell-type relationships and simultaneously estimates the probabilities associated with hundreds of tissues/cell-types for any given gene expression profile.
	URSA provides accurate and intuitive probability values for expression profiles across independent studies and outperforms other methods, irrespective of data preprocessing techniques.
	Moreover, without re-training, URSA can be used to classify samples from diverse microarray platforms and even from next-generation sequencing technology.
	Finally, we provide a molecular interpretation for the tissue and cell-type models as the biological basis for URSA's classifications.
	Availability and implementation: An interactive web interface for using URSA for gene expression analysis is available at: ursa.prince ton.edu.
	The source code is available at https://bitbucket.org/youngl/ursa_backend.
	Contact: ogt@cs.princeton.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The past several years have seen the development of methodologies to identify genomic variation within a fetus through the non-invasive sequencing of maternal blood plasma.
	These methods are based on the observation that maternal plasma contains a fraction of DNA (typically 5-15%) originating from the fetus, and such methodologies have already been used for the detection of wholechromosome events (aneuploidies), and to a more limited extent for smaller (typically several megabases long) copy number variants (CNVs).
	Results: Here we present a probabilistic method for non-invasive analysis of de novo CNVs in fetal genome based on maternal plasma sequencing.
	Our novel method combines three types of information within a unified Hidden Markov Model: the imbalance of allelic ratios at SNP positions, the use of parental genotypes to phase nearby SNPs and depth of coverage to better differentiate between various types of CNVs and improve precision.
	Our simulation results, based on in silico introduction of novel CNVs into plasma samples with 13% fetal DNA concentration, demonstrate a sensitivity of 90% for CNVs 4400 kb (with 13 calls in an unaffected genome), and 40% for 50-400 kb CNVs (with 108 calls in an unaffected genome).
	Availability and implementation: Implementation of our model and data simulation method is available at http://github.com/compbioUofT/fCNV.
	Contact: brudno@cs.toronto.edu
	Motivation: Plasmids and other mobile elements are central contributors to microbial evolution and genome innovation.
	Recently, they have been found to have important roles in antibiotic resistance and in affecting production of metabolites used in industrial and agricultural applications.
	However, their characterization through deep sequencing remains challenging, in spite of rapid drops in cost and throughput increases for sequencing.
	Here, we attempt to ameliorate this situation by introducing a new circular element assembly algorithm, leveraging assembly graphs provided by a conventional de novo assembler and alignments of paired-end reads to assemble cyclic sequences likely to be plasmids, phages and other circular elements.
	Results: We introduce Recycler, the first tool that can extract complete circular contigs from sequence data of isolate microbial genomes, plasmidome and metagenome sequence data.
	We show that Recycler greatly increases the number of true plasmids recovered relative to other approaches while remaining highly accurate.
	We demonstrate this trend via simulations of plasmidomes, comparisons of predictions with reference data for isolate samples, and assessments of annotation accuracy on metagenome data.
	In addition, we provide validation by DNA amplification of 77 plasmids predicted by Recycler from the different sequenced samples in which Recycler showed mean accuracy of 89% across all data types-isolate, microbiome and plasmidome.
	Availability and Implementation: Recycler is available at http://github.com/Shamir-Lab/Recycler Contact: imizrahi@bgu.ac.il Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Recent advances in sequence technology result in large datasets of sequence variants.
	For the human genome, several tools are available to predict the impact of these variants on gene and protein functions.
	However, for model organisms such as yeast such tools are lacking, specifically to predict the effect of protein sequence altering variants on the protein level.
	We present a python framework that enables users to map in a fully automated fashion large set of variants to protein functional regions and post-translationally modified residues.
	Furthermore, we provide the user with the possibility to retrieve predicted functional information on modified residues from other resources for example that are predicted to play a role in protein-protein interactions.
	The results are complemented by statistical tests to highlight the significance of underlying functions and pathways affected by mutations.
	We show the application of this package on a yeast dataset derived from a recent evolutionary experiment on adaptation to ethanol.
	Availability and Implementation: The package is available from https://github.com/CSB-KUL/yMap and is implemented in Python.
	Contact: vera.vannoort@biw.kuleuven.be Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: One of the key characteristics of any genetic variant is its geographic distribution.
	The geographic distribution can shed light on where an allele first arose, what populations it has spread to, and in turn on how migration, genetic drift, and natural selection have acted.
	The geographic distribution of a genetic variant can also be of great utility for medical/clinical geneticists and collectively many genetic variants can reveal population structure.
	Here we develop an interactive visualization tool for rapidly displaying the geographic distribution of genetic variants.
	Through a REST API and dynamic front-end, the Geography of Genetic Variants (GGV) browser (http://popgen.uchicago.edu/ggv/) provides maps of allele frequencies in populations distributed across the globe.
	Availability and Implementation: GGV is implemented as a website (http://popgen.uchicago.edu/ggv/) which employs an API to access frequency data (http://popgen.uchicago.edu/freq_api/).Python and javascript source code for the website and the API are available at: http://github.com/NovembreLab/ggv/ and http://github.com/NovembreLab/ggv-api/.Contact: jnovembre@uchicago.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: High-throughput technologies have led to an explosion of genomic data available for automated analysis.
	The consequent possibility to simultaneously sample multiple layers of variation along the gene expression flow requires computational methods integrating raw information from different '-omics'.
	It has been recently demonstrated that translational control is a widespread phenomenon, with profound and still underestimated regulation capabilities.
	Although detecting changes in the levels of total messenger RNAs (mRNAs; the transcriptome), of polysomally loaded mRNAs (the translatome) and of proteins (the proteome) is experimentally feasible in a high-throughput way, the integration of these levels is still far from being robustly approached.
	Here we introduce tRanslatome, a new R/Bioconductor package, which is a complete platform for the simultaneous pairwise analysis of transcriptome, translatome and proteome data.
	The package includes most of the available statistical methods developed for the analysis of high-throughput data, allowing the parallel comparison of differentially expressed genes and the corresponding differentially enriched biological themes.
	Notably, it also enables the prediction of translational regulatory elements on mRNA sequences.
	The utility of this tool is demonstrated with two case studies.
	Availability and implementation: tRanslatome is available in Bioconductor.
	Contact: t.tebaldi@unitn.it Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: DNA enrichment followed by sequencing is a versatile tool in molecular biology, with a wide variety of applications including genome-wide analysis of epigenetic marks and mechanisms.
	A common requirement of these diverse applications is a comparison of read coverage between experimental conditions.
	The amount of samples generated for such comparisons ranges from few replicates to hundreds of samples per condition for epigenome-wide association studies.
	Consequently, there is an urgent need for software that allows for fast and simple processing and comparison of sequencing data derived from enriched DNA.
	Results: Here, we present a major update of the R/Bioconductor package MEDIPS, which allows for an arbitrary number of replicates per group and integrates sophisticated statistical methods for the detection of differential coverage between experimental conditions.
	Our approach can be applied to a diversity of quantitative sequencing data.
	In addition, our update adds novel functionality to MEDIPS, including correlation analysis between samples, and takes advantage of Bioconductor's annotation databases to facilitate annotation of specific genomic regions.
	Availability and implementation: The latest version of MEDIPS is available as version 1.12.0 and part of Bioconductor 2.13.
	The package comes with a manual containing detailed description of its functionality and is available at http://www.bioconductor.org.Contact: lienhard@molgen.mpg.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Hadoop MapReduce-based approaches have become increasingly popular due to their scalability in processing large sequencing datasets.
	However, as these methods typically require in-depth expertise in Hadoop and Java, they are still out of reach of many bioinformaticians.
	To solve this problem, we have created SeqPig, a library and a collection of tools to manipulate, analyze and query sequencing datasets in a scalable and simple manner.
	SeqPigscripts use the Hadoop-based distributed scripting engine Apache Pig, which automatically parallelizes and distributes data processing tasks.
	We demonstrate SeqPig's scalability over many computing nodes and illustrate its use with example scripts.
	Availability and Implementation: Available under the open source MIT license at http://sourceforge.net/projects/seqpig/Contact: andre.schumacher@yahoo.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Phylowood is a web service that uses JavaScript to generate in-browser animations of biogeographic and phylogeographic histories from annotated phylogenetic input.
	The animations are interactive, allowing the user to adjust spatial and temporal resolution, and highlight phylogenetic lineages of interest.
	Availability and implementation: All documentation and source code for Phylowood is freely available at https://github.com/mlandis/phylo wood, and a live web application is available at https://mlandis.github.io/phylowood.
	Contact: mlandis@berkeley.edu
	Summary: Computational evaluation of variability across DNA or RNA sequencing datasets is a crucial step in genomic science, as it allows both to evaluate reproducibility of biological or technical replicates, and to compare different datasets to identify their potential correlations.
	Here we present fCCAC, an application of functional canonical correlation analysis to assess covariance of nucleic acid sequencing datasets such as chromatin immunoprecipitation followed by deep sequencing (ChIP-seq).
	We show how this method differs from other measures of correlation, and exemplify how it can reveal shared covariance between histone modifications and DNA binding proteins, such as the relationship between the H3K4me3 chromatin mark and its epigenetic writers and readers.
	Availability and Implementation: An R/Bioconductor package is available at http://bioconductor.org/packages/fCCAC/.
	Contact: pmb59@cam.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: The minfi package is widely used for analyzing Illumina DNA methylation array data.
	Here we describe modifications to the minfi package required to support the HumanMethylationEPIC ('EPIC') array from Illumina.
	We discuss methods for the joint analysis and normalization of data from the HumanMethylation450 ('450k') and EPIC platforms.
	We introduce the single-sample Noob (ssNoob) method, a normalization procedure suitable for incremental preprocessing of individual methylation arrays and conclude that this method should be used when integrating data from multiple generations of Infinium methylation arrays.
	We show how to use reference 450k datasets to estimate cell type composition of samples on EPIC arrays.
	The cumulative effect of these updates is to ensure that minfi provides the tools to best integrate existing and forthcoming Illumina methylation array data.
	Availability and Implementation: The minfi package version 1.19.12 or higher is available for all platforms from the Bioconductor project.
	Contact: khansen@jhsph.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Regulatory elements regulate gene transcription, and their location and accessibility is cell-type specific, particularly for enhancers.
	Mapping and comparing chromatin accessibility between different cell types may identify mechanisms involved in cellular development and disease progression.
	To streamline and simplify differential analysis of regulatory elements genome-wide using chromatin accessibility data, such as DNase-seq, ATAC-seq, we developed ALTRE (ALTered Regulatory Elements), an R package and associated R Shiny web app.
	ALTRE makes such analysis accessible to a wide range of users-from novice to practiced computational biologists.
	Availability and Implementation:https://github.com/Mathelab/ALTRE Contact: ewy.mathe@osumc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Systematic bias in mass measurement adversely affects data quality and negates the advantages of high precision instruments.
	Results: We introduce the mzRefinery tool for calibration of mass spectrometry data files.
	Using confident peptide spectrum matches, three different calibration methods are explored and the optimal transform function is chosen.
	After calibration, systematic bias is removed and the mass measurement errors are centered at 0 ppm.
	Because it is part of the ProteoWizard package, mzRefinery can read and write a wide variety of file formats.
	Availability and implementation: The mzRefinery tool is part of msConvert, available with the ProteoWizard open source package at http://proteowizard.sourceforge.net/Contact: samuel.payne@pnnl.gov Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Seasonal influenza viruses evolve rapidly, allowing them to evade immunity in their human hosts and reinfect previously infected individuals.
	Similarly, vaccines against seasonal influenza need to be updated frequently to protect against an evolving virus population.
	We have thus developed a processing pipeline and browser-based visualization that allows convenient exploration and analysis of the most recent influenza virus sequence data.
	This web-application displays a phylogenetic tree that can be decorated with additional information such as the viral genotype at specific sites, sampling location and derived statistics that have been shown to be predictive of future virus dynamics.
	In addition, mutation, genotype and clade frequency trajectories are calculated and displayed.
	Availability and implementation: Python and Javascript source code is freely available from https://github.com/blab/nextflu, while the web-application is live at http://nextflu.org.Contact: tbedford@fredhutch.org
	Motivation: Drug repositioning is the discovery of new indications for compounds that have already been approved and used in a clinical setting.
	Recently, some computational approaches have been suggested to unveil new opportunities in a systematic fashion, by taking into consideration gene expression signatures or chemical features for instance.
	We present here a novel method based on knowledge integration using semantic technologies, to capture the functional role of approved chemical compounds.
	Results: In order to computationally generate repositioning hypotheses, we used the Web Ontology Language to formally define the semantics of over 20 000 terms with axioms to correctly denote various modes of action (MoA).
	Based on an integration of public data, we have automatically assigned over a thousand of approved drugs into these MoA categories.
	The resulting new resource is called the Functional Therapeutic Chemical Classification System and was further evaluated against the content of the traditional Anatomical Therapeutic Chemical Classification System.
	We illustrate how the new classification can be used to generate drug repurposing hypotheses, using Alzheimers disease as a use-case.
	Availability: https://www.ebi.ac.uk/chembl/ftc; https://github.com/loopasam/ftc.
	Contact: croset@ebi.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: In T-cell lymphoma, malignant T cells arising from a founding clone share an identical T cell receptor (TCR) and can be identified by the over-representation of this TCR relative to TCRs from the patient's repertoire of normal T cells.
	Here, we demonstrate that TCR information extracted from RNA-seq data can provide a higher resolution view of peripheral T cell lymphomas (PTCLs) than that provided by conventional methods.
	Results: For 60 subjects with PTCL, flow cytometry/FACS was used to identify and sort aberrant T cell populations from diagnostic lymph node cell suspensions.
	For samples that did not appear to contain aberrant T cell populations, T helper (TH), T follicular helper (TFH) and cytotoxic T lymphocyte (CTL) subsets were sorted.
	RNA-seq was performed on sorted T cell populations, and TCR alpha and beta chain sequences were extracted and quantified directly from the RNA-seq data.
	96% of the immunophenotypically aberrant samples had a dominant T cell clone readily identifiable by RNA-seq.
	Of the samples where no aberrant population was found by flow cytometry, 80% had a dominant clone by RNA-seq.
	This demonstrates the increased sensitivity and diagnostic ability of RNA-seq over flow cytometry and shows that the presence of a normal immunophenotype does not exclude clonality.
	Availability and Implementation: R scripts used in the processing of the data are available online at https://www.github.com/scottdbrown/RNAseq-TcellClonality Contacts: rholt@bcgsc.ca or ksavage@bccancer.bc.ca Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: myChEMBL is a completely open platform, which combines public domain bioactivity data with open source database and cheminformatics technologies.
	myChEMBL consists of a Linux (Ubuntu) Virtual Machine featuring a PostgreSQL schema with the latest version of the ChEMBL database, as well as the latest RDKit cheminformatics libraries.
	In addition, a self-contained web interface is available, which can be modified and improved according to user specifications.
	Availability and implementation: The VM is available at: ftp://ftp.ebi.
	ac.uk/pub/databases/chembl/VM/myChEMBL/current.
	The web interface and web services code is available at: https://github.com/rochoa85/myChEMBL.
	Contact: jpo@ebi.ac.uk
	Summary: Illumina's recently released Nextera Long Mate Pair (LMP) kit enables production of jumping libraries of up to 12 kb.
	The LMP libraries are an invaluable resource for carrying out complex assemblies and other downstream bioinformatics analyses such as the characterization of structural variants.
	However, LMP libraries are intrinsically noisy and to maximize their value, post-sequencing data analysis is required.
	Standardizing laboratory protocols and the selection of sequenced reads for downstream analysis are non-trivial tasks.
	NextClip is a tool for analyzing reads from LMP libraries, generating a comprehensive quality report and extracting good quality trimmed and deduplicated reads.
	Availability and implementation: Source code, user guide and example data are available from https://github.com/richardmleggett/nextclip/.
	Contact: Richard.Leggett@tgac.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Transcriptional profiling still remains one of the most popular techniques for identifying relevant biomarkers in patient samples.
	However, heterogeneity in the population leads to poor statistical evidence for selection of most relevant biomarkers to pursue.
	In particular, human transcriptional differences can be subtle, making it difficult to tease out real differentially expressed biomarkers from the variability inherent in the population.
	To address this issue, we propose a simple statistical technique that identifies differentially expressed probes in heterogeneous populations as compared with controls.
	Availability and implementation: The algorithm has been implemented in Java and available at www.sourceforge.net/projects/ probeselect.
	Contact: jbienkowska@gmail.com or jadwiga@csail.mit.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: With the wealth of available genome sequences, a difficult and tedious part of inferring phylogenomic trees is now to select genomes with an appropriate taxon density in the different parts of the tree.
	The package described here offers tools to easily select the most representative organisms, following a set of simple rules based on taxonomy and assembly quality, to retrieve the genomes from public databases (NCBI, JGI), to annotate them if necessary, to identify given markers in these, and to prepare files for multiple sequence alignment.
	Availability and Implementation: phyloSkeleton is a Perl module and is freely available under GPLv3 at https://bitbucket.org/lionelguy/phyloskeleton/.Contact: lionel.guy@imbim.uu.se
	Motivation: Bayesian inference is widely used nowadays and relies largely on Markov chain Monte Carlo (MCMC) methods.
	Evolutionary biology has greatly benefited from the developments of MCMC methods, but the design of more complex and realistic models and the ever growing availability of novel data is pushing the limits of the current use of these methods.
	Results: We present a parallel Metropolis-Hastings (M-H) framework built with a novel combination of enhancements aimed towards parameter-rich and complex models.
	We show on a parameterrich macroevolutionary model increases of the sampling speed up to 35 times with 32 processors when compared to a sequential M-H process.
	More importantly, our framework achieves up to a twentyfold faster convergence to estimate the posterior probability of phylogenetic trees using 32 processors when compared to the well-known software MrBayes for Bayesian inference of phylogenetic trees.
	Availability and Implementation: https://bitbucket.org/XavMeyer/hogan Contact: nicolas.salamin@unil.ch Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Detecting significant associations between genetic variants and disease may prove particularly challenging when the variants are rare in the population and/or act together with other variants to cause the disease.
	We have developed a statistical framework named Mutation Enrichment Gene set Analysis of Variants (MEGA-V) that specifically detects the enrichments of genetic alterations within a process in a cohort of interest.
	By focusing on the mutations of several genes contributing to the same function rather than on those affecting a single gene, MEGA-V increases the power to detect statistically significant associations.
	Availability and Implementation: MEGA-V is available at https://github.com/ciccalab/MEGA Contact: francesca.ciccarelli@kcl.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: The Sample avAILability system-SAIL-is a web based application for searching, browsing and annotating biological sample collections or biobank entries.
	By providing individual-level information on the availability of specific data types (phenotypes, genetic or genomic data) and samples within a collection, rather than the actual measurement data, resource integration can be facilitated.
	A flexible data structure enables the collection owners to provide descriptive information on their samples using existing or custom vocabularies.
	Users can query for the available samples by various parameters combining them via logical expressions.
	The system can be scaled to hold data from millions of samples with thousands of variables.
	Availability: SAIL is available under Aferro-GPL open source license: https://github.com/sail.Contact: gostev@ebi.ac.uk, support@simbioms.org Supplementary information : Supplementary data are available at Bioinformatics online and from http://www.simbioms.org.
	Summary: Track data hubs provide an efficient mechanism for visualizing remotely hosted Internet-accessible collections of genome annotations.
	Hub datasets can be organized, configured and fully integrated into the University of California Santa Cruz (UCSC) Genome Browser and accessed through the familiar browser interface.
	For the first time, individuals can use the complete browser feature set to view custom datasets without the overhead of setting up and maintaining a mirror.
	Availability and implementation: Source code for the BigWig, BigBed and Genome Browser software is freely available for noncommercial use at http://hgdownload.cse.ucsc.edu/admin/jksrc.zip, implemented in C and supported on Linux.
	Binaries for the BigWig and BigBed creation and parsing utilities may be downloaded at http://hgdownload.cse.ucsc.edu/admin/exe/.
	Binary Alignment/Map (BAM) and Variant Call Format (VCF)/tabix utilities are available from http://samtools.sourceforge.net/ and http://vcftools.sourceforge.net/.
	The UCSC Genome Browser is publicly accessible at http://genome.ucsc.edu.
	Contact: donnak@soe.ucsc.edu
	Motivation: Variant calling from next-generation sequencing (NGS) data is susceptible to false positive calls due to sequencing, mapping and other errors.
	To better distinguish true from false positive calls, we present a method that uses genotype array data from the sequenced samples, rather than public data such as HapMap or dbSNP, to train an accurate classifier using Random Forests.
	We demonstrate our method on a set of variant calls obtained from 642 African-ancestry genomes from the Consortium on Asthma among African-ancestry Populations in the Americas (CAAPA), sequenced to high depth (30X).
	Results: We have applied our classifier to compare call sets generated with different calling methods, including both single-sample and multi-sample callers.
	At a False Positive Rate of 5%, our method determines true positive rates of 97.5%, 95% and 99% on variant calls obtained using Illuminas singlesample caller CASAVA, Real Time Genomics multisample variant caller, and the GATK UnifiedGenotyper, respectively.
	Since NGS sequencing data may be accompanied by genotype data for the same samples, either collected concurrent to sequencing or from a previous study, our method can be trained on each dataset to provide a more accurate computational validation of site calls compared to generic methods.
	Moreover, our method allows for adjustment based on allele frequency (e.g.
	a different set of criteria to determine quality for rare versus common variants) and thereby provides insight into sequencing characteristics that indicate call quality for variants of different frequencies.
	Motivation: Large multiple genome alignments and inferred ancestral genomes are ideal resources for comparative studies of molecular evolution, and advances in sequencing and computing technology are making them increasingly obtainable.
	These structures can provide a rich understanding of the genetic relationships between all subsets of species they contain.
	Current formats for storing genomic alignments, such as XMFA and MAF, are all indexed or ordered using a single reference genome, however, which limits the information that can be queried with respect to other species and clades.
	This loss of information grows with the number of species under comparison, as well as their phylogenetic distance.
	Results: We present HAL, a compressed, graph-based hierarchical alignment format for storing multiple genome alignments and ancestral reconstructions.
	HAL graphs are indexed on all genomes they contain.
	Furthermore, they are organized phylogenetically, which allows for modular and parallel access to arbitrary subclades without fragmentation because of rearrangements that have occurred in other lineages.
	HAL graphs can be created or read with a comprehensive CÃ¾Ã¾ API.
	A set of tools is also provided to perform basic operations, such as importing and exporting data, identifying mutations and coordinate mapping (liftover).
	Availability: All documentation and source code for the HAL API and tools are freely available at http://github.com/glennhickey/hal.Contact: hickey@soe.ucsc.edu or haussler@soe.ucsc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Using high-throughput sequencing, researchers are now generating hundreds of whole-genome assays to measure various features such as transcription factor binding, histone marks, DNA methylation or RNA transcription.
	Displaying so much data generally leads to a confusing accumulation of plots.
	We describe here a multithreaded library that computes statistics on large numbers of datasets (Wiggle, BigWig, Bed, BigBed and BAM), generating statistical summaries within minutes with limited memory requirements, whether on the whole genome or on selected regions.
	Availability and Implementation: The code is freely available under Apache 2.0 license at www.github.com/Ensembl/Wiggletools Contact: zerbino@ebi.ac.uk or flicek@ebi.ac.uk
	Motivation: Pseudotime analyses of single-cell RNA-seq data have become increasingly common.
	Typically, a latent trajectory corresponding to a biological process of interest-such as differentiation or cell cycle-is discovered.
	However, relatively little attention has been paid to modelling the differential expression of genes along such trajectories.
	Results: We present switchde, a statistical framework and accompanying R package for identifying switch-like differential expression of genes along pseudotemporal trajectories.
	Our method includes fast model fitting that provides interpretable parameter estimates corresponding to how quickly a gene is up or down regulated as well as where in the trajectory such regulation occurs.
	It also reports a P-value in favour of rejecting a constant-expression model for switch-like differential expression and optionally models the zero-inflation prevalent in single-cell data.
	Availability and Implementation: The R package switchde is available through the Bioconductor project at https://bioconductor.org/packages/switchde.Contact: kieran.campbell@sjc.ox.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Flow, hyperspectral and mass cytometry are experimental techniques measuring cell marker expressions at the single cell level.
	The recent increase of the number of markers simultaneously measurable has led to the development of new automatic gating algorithms.
	Especially, the SPADE algorithm has been proposed as a novel way to identify clusters of cells having similar phenotypes in high-dimensional cytometry data.
	While SPADE or other cell clustering algorithms are powerful approaches, complementary analysis features are needed to better characterize the identified cell clusters.
	Results: We have developed SPADEVizR, an R package designed for the visualization, analysis and integration of cell clustering results.
	The available statistical methods allow highlighting cell clusters with relevant biological behaviors or integrating them with additional biological variables.
	Moreover, several visualization methods are available to better characterize the cell clusters, such as volcano plots, streamgraphs, parallel coordinates, heatmaps, or distograms.
	SPADEVizR can also generate linear, Cox or random forest models to predict biological outcomes, based on the cell cluster abundances.
	Additionally, SPADEVizR has several features allowing to quantify and to visualize the quality of the cell clustering results.
	These analysis features are essential to better interpret the behaviors and phenotypes of the identified cell clusters.
	Importantly, SPADEVizR can handle clustering results from other algorithms than SPADE.
	Availability and Implementation: SPADEVizR is distributed under the GPL-3 license and is available at https://github.com/tchitchek-lab/SPADEVizR.Contact: nicolas.tchitchek@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: RNA sequencing has provided unprecedented resolution of alternative splicing and splicing quantitative trait loci (sQTL).
	However, there are few tools available for visualizing the genotypedependent effects of splicing at a population level.
	SplicePlot is a simple command line utility that produces intuitive visualization of sQTLs and their effects.
	SplicePlot takes mapped RNA sequencing reads in BAM format and genotype data in VCF format as input and outputs publication-quality Sashimi plots, hive plots and structure plots, enabling better investigation and understanding of the role of genetics on alternative splicing and transcript structure.
	Availability and implementation: Source code and detailed documentation are available at http://montgomerylab.stanford.edu/splice plot/index.html under Resources and at Github.
	SplicePlot is implemented in Python and is supported on Linux and Mac OS.
	A VirtualBox virtual machine running Ubuntu with SplicePlot already installed is also available.
	Contact: wu.eric.g@gmail.com or smontgom@stanford.edu
	Summary: Here we present SVScore, a tool for in silico structural variation (SV) impact prediction.
	SVScore aggregates per-base single nucleotide polymorphism (SNP) pathogenicity scores across relevant genomic intervals for each SV in a manner that considers variant type, gene features and positional uncertainty.
	We show that the allele frequency spectrum of high-scoring SVs is strongly skewed toward lower frequencies, suggesting that they are under purifying selection, and that SVScore identifies deleterious variants more effectively than alternative methods.
	Notably, our results also suggest that duplications are under surprisingly strong selection relative to deletions, and that there are a similar number of strongly pathogenic SVs and SNPs in the human population.
	Availability and Implementation: SVScore is implemented in Perl and available freely at {{http://www.github.com/lganel/SVScore}} for use under the MIT license.
	Contact: ihall@wustl.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: The goal of this work is to offer a computational framework for exploring data from the Recon2 human metabolic reconstruction model.
	Advanced user access features have been developed using the Neo4j graph database technology and this paper describes key features such as efficient management of the network data, examples of the network querying for addressing particular tasks, and how query results are converted back to the Systems Biology Markup Language (SBML) standard format.
	The Neo4j-based metabolic framework facilitates exploration of highly connected and comprehensive human metabolic data and identification of metabolic subnetworks of interest.
	A Java-based parser component has been developed to convert query results (available in the JSON format) into SBML and SIF formats in order to facilitate further results exploration, enhancement or network sharing.
	Availability and Implementation: The Neo4j-based metabolic framework is freely available from: https://diseaseknowledgebase.etriks.org/metabolic/browser/.
	The java code files developed for this work are available from the following url: https://github.com/ibalaur/MetabolicFramework.Contact: ibalaur@eisbm.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Targeted resequencing of cancer genes in large cohorts of patients is important to understand the biological and clinical consequences of mutations.
	Cancers are often clonally heterogeneous, and the detection of subclonal mutations is important from a diagnostic point of view, but presents strong statistical challenges.
	Results: Here we present a novel statistical approach for calling mutations from large cohorts of deeply resequenced cancer genes.
	These data allow for precisely estimating local error profiles and enable detecting mutations with high sensitivity and specificity.
	Our probabilistic method incorporates knowledge about the distribution of variants in terms of a prior probability.
	We show that our algorithm has a high accuracy of calling cancer mutations and demonstrate that the detected clonal and subclonal variants have important prognostic consequences.
	Availability: Code is available as part of the Bioconductor package deepSNV.
	Contact: mg14@sanger.ac.uk; pc8@sanger.ac.uk
	Motivation: Identification of genomic regions of interest in ChIPseq data, commonly referred to as peak-calling, aims to find the locations of transcription factor binding sites, modified histones or nucleosomes.
	The BayesPeak algorithm was developed to model the data structure using Bayesian statistical techniques and was shown to be a reliable method, but did not have a full-genome implementation.
	Results: In this note we present BayesPeak, an R package for genome-wide peak-calling that provides a flexible implementation of the BayesPeak algorithm and is compatible with downstream BioConductor packages.
	The BayesPeak package introduces a new method for summarizing posterior probability output, along with methods for handling overfitting and support for parallel processing.
	We briefly compare the package with other common peak-callers.
	Availability: Available as part of BioConductor version 2.6.
	URL: http://bioconductor.org/packages/release/bioc/html/BayesPeak.html Contact: jonathan.cairns@cancer.org.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Computational genomics seeks to draw biological inferences from genomic datasets, often by integrating and contextualizing next-generation sequencing data.
	CGAT provides an extensive suite of tools designed to assist in the analysis of genome scale data from a range of standard file formats.
	The toolkit enables filtering, comparison, conversion, summarization and annotation of genomic intervals, gene sets and sequences.
	The tools can both be run from the Unix command line and installed into visual workflow builders, such as Galaxy.
	Availability: The toolkit is freely available from http://github.com/CGATOxford/cgat Contact: andreas.heger@dpag.ox.ac.uk
	Motivation: Current advances in DNA synthesis, cloning and sequencing technologies afford high-throughput implementation of artificial sequences into living cells.
	However, flexible computational tools for multi-objective sequence design are lacking, limiting the potential of these technologies.
	Results: We developed DNA-Tailor (D-Tailor), a fully extendable software framework, for property-based design of synthetic DNA sequences.
	D-Tailor permits the seamless integration of multiple sequence analysis tools into a generic Monte Carlo simulation that evolves sequences toward any combination of rationally defined properties.
	As proof of principle, we show that D-Tailor is capable of designing sequence libraries comprising all possible combinations among three different sequence properties influencing translation efficiency in Escherichia coli.
	The capacity to design artificial sequences that systematically sample any given parameter space should support the implementation of more rigorous experimental designs.
	Availability: Source code is available for download at https://source forge.net/projects/dtailor/ Contact: aparkin@lbl.gov or cambray.guillaume@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online (D-Tailor Tutorial).
	Motivation: Experimental spatial proteomics, i.e.
	the high-throughput assignment of proteins to sub-cellular compartments based on quantitative proteomics data, promises to shed new light on many biological processes given adequate computational tools.
	Results: Here we present pRoloc, a complete infrastructure to support and guide the sound analysis of quantitative massspectrometry-based spatial proteomics data.
	It provides functionality for unsupervised and supervised machine learning for data exploration and protein classification and novelty detection to identify new putative sub-cellular clusters.
	The software builds upon existing infrastructure for data management and data processing.
	Availability: pRoloc is implemented in the R language and available under an open-source license from the Bioconductor project (http://www.bioconductor.org/).
	A vignette with a complete tutorial describing data import/export and analysis is included in the package.
	Test data is available in the companion package pRolocdata.
	Contact: lg390@cam.ac.uk
	Motivation: De novo assembly of whole genome shotgun (WGS) next-generation sequencing (NGS) data benefits from high-quality input with high coverage.
	However, in practice, determining the quality and quantity of useful reads quickly and in a reference-free manner is not trivial.
	Gaining a better understanding of the WGS data, and how that data is utilized by assemblers, provides useful insights that can inform the assembly process and result in better assemblies.
	Results: We present the K-mer Analysis Toolkit (KAT): a multi-purpose software toolkit for reference-free quality control (QC) of WGS reads and de novo genome assemblies, primarily via their k-mer frequencies and GC composition.
	KAT enables users to assess levels of errors, bias and contamination at various stages of the assembly process.
	In this paper we highlight KAT's ability to provide valuable insights into assembly composition and quality of genome assemblies through pairwise comparison of k-mers present in both input reads and the assemblies.
	Availability and Implementation: KAT is available under the GPLv3 license at: https://github.com/TGAC/KAT.
	Contact: bernardo.clavijo@earlham.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The aim of this study is to assess the performance of RNA-RNA interaction prediction tools for all domains of life.
	Results: Minimum free energy (MFE) and alignment methods constitute most of the current RNA interaction prediction algorithms.
	The MFE tools that include accessibility (i.e.
	RNAup, IntaRNA and RNAplex) to the final predicted binding energy have better true positive rates (TPRs) with a high positive predictive values (PPVs) in all datasets than other methods.
	They can also differentiate almost half of the native interactions from background.
	The algorithms that include effects of internal binding energies to their model and alignment methods seem to have high TPR but relatively low associated PPV compared to accessibility based methods.
	Availability and Implementation: We shared our wrapper scripts and datasets at Github (github.com/UCanCompBio/RNA_Interactions_Benchmark).
	All parameters are documented for personal use.
	Contact: sinan.umu@pg.canterbury.ac.nz Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: As applications of genome sequencing, including exomes and whole genomes, are expanding, there is a need for analysis tools that are scalable to large sets of samples and/or ultra-deep coverage.
	Many current tool chains are based on the widely used file formats BAM and VCF or VCF-derivatives.
	However, for some desirable analyses, data management with these formats creates substantial implementation overhead, and much time is spent parsing files and collating data.
	We observe that a tally data structure, i.e.
	the table of counts of nucleotides samples strands genomic positions, provides a reasonable intermediate level of abstraction for many genomics analyses, including single nucleotide variant (SNV) and InDel calling, copynumber estimation and mutation spectrum analysis.
	Here we present h5vc, a data structure and associated software for managing tallies.
	The software contains functionality for creating tallies from BAM files, flexible and scalable data visualization, data quality assessment, computing statistics relevant to variant calling and other applications.
	Through the simplicity of its API, we envision making low-level analysis of large sets of genome sequencing data accessible to a wider range of researchers.
	Availability and implementation: The package h5vc for the statistical environment R is available through the Bioconductor project.
	The HDF5 system is used as the core of our implementation.
	Contact: pyl@embl.de or whuber@embl.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Phylogenies are increasingly used in all fields of medical and biological research.
	Moreover, because of the next-generation sequencing revolution, datasets used for conducting phylogenetic analyses grow at an unprecedented pace.
	RAxML (Randomized Axelerated Maximum Likelihood) is a popular program for phylogenetic analyses of large datasets under maximum likelihood.
	Since the last RAxML paper in 2006, it has been continuously maintained and extended to accommodate the increasingly growing input datasets and to serve the needs of the user community.
	Results: I present some of the most notable new features and extensions of RAxML, such as a substantial extension of substitution models and supported data types, the introduction of SSE3, AVX and AVX2 vector intrinsics, techniques for reducing the memory requirements of the code and a plethora of operations for conducting postanalyses on sets of trees.
	In addition, an up-to-date 50-page user manual covering all new RAxML options is available.
	Availability and implementation: The code is available under GNU GPL at https://github.com/stamatak/standard-RAxML.Contact: alexandros.stamatakis@h-its.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The de novo assembly of large, complex genomes is a significant challenge with currently available DNA sequencing technology.
	While many de novo assembly software packages are available, comparatively little attention has been paid to assisting the user with the assembly.
	Results: This article addresses the practical aspects of de novo assembly by introducing new ways to perform quality assessment on a collection of sequence reads.
	The software implementation calculates per-base error rates, paired-end fragment-size distributions and coverage metrics in the absence of a reference genome.
	Additionally, the software will estimate characteristics of the sequenced genome, such as repeat content and heterozygosity that are key determinants of assembly difficulty.
	Availability: The software described is freely available online (https://github.com/jts/sga) and open source under the GNU Public License.
	Contact: jared.simpson@oicr.on.ca Supplementary Information: Supplementary data are available at Bioinformatics online.
	Summary: Arcadia translates text-based descriptions of biological networks (SBML files) into standardized diagrams (SBGN PD maps).
	Users can view the same model from different perspectives and easily alter the layout to emulate traditional textbook representations.
	Availability and Implementation: Arcadia is written in C++.
	The source code is available (along with Mac OS and Windows binaries) under the GPL from http://arcadiapathways.sourceforge.net/Contact: alice.villeger@manchester.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: We have developed geneAttribution, an R package that assigns candidate causal gene(s) to a risk variant identified by a genetic association study such as a GWAS.
	The method combines user-supplied functional annotation such as expression quantitative trait loci (eQTL) or Hi-C genome conformation data and reports the most likely candidate genes.
	In the absence of annotation data, geneAttribution relies on the distances between the genes and the input variant.
	Availability and Implementation: The package is freely available from http://www.bioconductor.org/.
	A quick-start vignette is included with the package.
	Contact: wustera@gene.com
	Motivation: With the rapid advances in DNA synthesis and sequencing technologies and the continuing decline in the associated costs, high-throughput experiments can be performed to investigate the regulatory role of thousands of oligonucleotide sequences simultaneously.
	Nevertheless, designing high-throughput reporter assay experiments such as massively parallel reporter assays (MPRAs) and similar methods remains challenging.
	Results: We introduce MPRAnator, a set of tools that facilitate rapid design of MPRA experiments.
	With MPRA Motif design, a set of variables provides fine control of how motifs are placed into sequences, thereby allowing the investigation of the rules that govern transcription factor (TF) occupancy.
	MPRA single-nucleotide polymorphism design can be used to systematically examine the functional effects of single or combinations of single-nucleotide polymorphisms at regulatory sequences.
	Finally, the Transmutation tool allows for the design of negative controls by permitting scrambling, reversing, complementing or introducing multiple random mutations in the input sequences or motifs.
	Availability and implementation: MPRAnator tool set is implemented in Python, Perl and Javascript and is freely available at www.genomegeek.com and www.sanger.ac.uk/science/tools/mpranator.
	The source code is available on www.github.com/hemberg-lab/MPRAnator/ under the MIT license.
	The REST API allows programmatic access to MPRAnator using simple URLs.
	Contact: igs@sanger.ac.uk or mh26@sanger.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Deep sequencing based ribosome footprint profiling can provide novel insights into the regulatory mechanisms of protein translation.
	However, the observed ribosome profile is fundamentally confounded by transcriptional activity.
	In order to decipher principles of translation regulation, tools that can reliably detect changes in translation efficiency in case-control studies are needed.
	Results: We present a statistical framework and an analysis tool, RiboDiff, to detect genes with changes in translation efficiency across experimental treatments.
	RiboDiff uses generalized linear models to estimate the over-dispersion of RNA-Seq and ribosome profiling measurements separately, and performs a statistical test for differential translation efficiency using both mRNA abundance and ribosome occupancy.
	Availability and Implementation: RiboDiff webpage http://bioweb.me/ribodiff.
	Source code including scripts for preprocessing the FASTQ data are available at http://github.com/ratschlab/ribodiff.Contacts: zhongy@cbio.mskcc.org or raetsch@inf.ethz.ch Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Optical mapping is a technique for capturing fluorescent signal patterns of long DNA molecules (in the range of 0.1-1 Mbp).
	Recently, it has been complementing the widely used short-read sequencing technology by assisting with scaffolding and detecting large and complex structural variations (SVs).
	Here, we introduce a fast, robust and accurate tool called OMBlast for aligning optical maps, the set of signal locations on the molecules generated from optical mapping.
	Our method is based on the seed-and-extend approach from sequence alignment, with modifications specific to optical mapping.
	Results: Experiments with both synthetic and our real data demonstrate that OMBlast has higher accuracy and faster mapping speed than existing alignment methods.
	Our tool also shows significant improvement when aligning data with SVs.
	Availability and Implementation: OMBlast is implemented for Java 1.7 and is released under a GPL license.
	OMBlast can be downloaded from https://github.com/aldenleung/OMBlast and run directly on machines equipped with a Java virtual machine.
	Contact: kevinyip@cse.cuhk.edu.hk and tf.chan@cuhk.edu.hk Supplementary information: Supplementary data are available at Bioinformatics online
	Motivation: BioClojure is an open-source library for the manipulation of biological sequence data written in the language Clojure.
	BioClojure aims to provide a functional framework for the processing of biological sequence data that provides simple mechanisms for concurrency and lazy evaluation of large datasets.
	Results: BioClojure provides parsers and accessors for a range of biological sequence formats, including UniProtXML, Genbank XML, FASTA and FASTQ.
	In addition, it provides wrappers for key analysis programs, including BLAST, SignalP, TMHMM and InterProScan, and parsers for analyzing their output.
	All interfaces leverage Clojure's functional style and emphasize laziness and composability, so that BioClojure, and user-defined, functions can be chained into simple pipelines that are thread-safe and seamlessly integrate lazy evaluation.
	Availability and implementation: BioClojure is distributed under the Lesser GPL, and the source code is freely available from GitHub (https://github.com/s312569/clj-biosequence).Contact: jason.mulvenna@qimrberghofer.edu.au or jason.mulvenna@ qimr.edu.au
	Motivation: Quantitative real-time PCR (qPCR) is one of the most widely used methods to measure gene expression.
	Despite extensive research in qPCR laboratory protocols, normalization and statistical analysis, little attention has been given to qPCR non-detects-those reactions failing to produce a minimum amount of signal.
	Results: We show that the common methods of handling qPCR nondetects lead to biased inference.
	Furthermore, we show that nondetects do not represent data missing completely at random and likely represent missing data occurring not at random.
	We propose a model of the missing data mechanism and develop a method to directly model non-detects as missing data.
	Finally, we show that our approach results in a sizeable reduction in bias when estimating both absolute and differential gene expression.
	Availability and implementation: The proposed algorithm is implemented in the R package, nondetects.
	This package also contains the raw data for the three example datasets used in this manuscript.
	The package is freely available at http://mnmccall.com/software and as part of the Bioconductor project.
	Contact: mccallm@gmail.com
	Summary: We introduce a simple-to-use graphical tool that enables researchers to easily prepare time-of-flight mass spectrometry data for analysis.
	For ease of use, the graphical executable provides default parameter settings, experimentally determined to work well in most situations.
	These values, if desired, can be changed by the user.
	PrepMS is a stand-alone application made freely available (open source), and is under the General Public License (GPL).
	Its graphical user interface, default parameter settings, and display plots allow PrepMS to be used effectively for data preprocessing, peak detection and visual data quality assessment.
	Availability: Stand-alone executable files and Matlab toolbox are available for download at: http://sourceforge.net/projects/prepms Contact: ykarpi@mdanderson.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: New sequence data useful for phylogenetic and evolutionary analyses continues to be added to public databases.
	The construction of multiple sequence alignments and inference of huge phylogenies comprising large taxonomic groups are expensive tasks, both in terms of man hours and computational resources.
	Therefore, maintaining comprehensive phylogenies, based on representative and up-to-date molecular sequences, is challenging.
	PUmPER is a framework that can perpetually construct multi-gene alignments (with PHLAWD) and phylogenetic trees (with ExaML or RAxML-Light) for a given NCBI taxonomic group.
	When sufficient numbers of new gene sequences for the selected taxonomic group have accumulated in GenBank, PUmPER automatically extends the alignment and infers extended phylogenetic trees by using previously inferred smaller trees as starting topologies.
	Using our framework, large phylogenetic trees can be perpetually updated without human intervention.
	Importantly, resulting phylogenies are not statistically significantly worse than trees inferred from scratch.
	Availability and implementation: PUmPER can run in stand-alone mode on a single server, or offload the computationally expensive phylogenetic searches to a parallel computing cluster.
	Source code, documentation, and tutorials are available at https://github.com/fizquierdo/perpetually-updated-trees.
	Contact: Fernando.Izquierdo@h-its.org Supplementary information: Supplementary Material is available at Bioinformatics online.
	Summary: The initial steps in the analysis of next-generation sequencing data can be automated by way of software 'pipelines'.
	However, individual components depreciate rapidly because of the evolving technology and analysis methods, often rendering entire versions of production informatics pipelines obsolete.
	Constructing pipelines from Linux bash commands enables the use of hot swappable modular components as opposed to the more rigid program call wrapping by higher level languages, as implemented in comparable published pipelining systems.
	Here we present Next Generation Sequencing ANalysis for Enterprises (NGSANE), a Linux-based, high-performance-computing-enabled framework that minimizes overhead for set up and processing of new projects, yet maintains full flexibility of custom scripting when processing raw sequence data.
	Availability and implementation: NGSANE is implemented in bash and publicly available under BSD (3-Clause) licence via GitHub at https://github.com/BauerLab/ngsane.
	Contact: Denis.Bauer@csiro.au Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Gene-set enrichment analysis (GSEA) can be greatly enhanced by linear model (regression) diagnostic techniques.
	Diagnostics can be used to identify outlying or influential samples, and also to evaluate model fit and explore model expansion.
	Results: We demonstrate this methodology on an adult acute lymphoblastic leukemia (ALL) dataset, using GSEA based on chromosome-band mapping of genes.
	Individual residuals, grouped or aggregated by chromosomal loci, indicate problematic samples and potential data-entry errors, and help identify hyperdiploidy as a factor playing a key role in expression for this dataset.
	Subsequent analysis pinpoints suspected DNA copy number abnormalities of specific samples and chromosomes (most prevalent are chromosomes X, 21 and 14), and also reveals significant expression differences between the hyperdiploid and diploid groups on other chromosomes (most prominently 19, 22, 3 and 13)differences which are apparently not associated with copy number.
	Availability: Software for the statistical tools demonstrated in this article is available as Bioconductor package GSEAlm.
	Contact: assaf.oron@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We present the first public release of our proteogenomic annotation pipeline.
	We have previously used our original unreleased implementation to improve the annotation of 46 diverse prokaryotic genomes by discovering novel genes, post-translational modifications and correcting the erroneous annotations by analyzing proteomic mass-spectrometry data.
	This public version has been redesigned to run in a wide range of parallel Linux computing environments and provided with the automated configuration, build and testing facilities for easy deployment and portability.
	Availability and implementation: Source code is freely available from https://bitbucket.org/andreyto/proteogenomics under GPL license.
	It is implemented in Python and CÃ¾Ã¾.
	It bundles the Makeflow engine to execute the workflows.
	Contact: atovtchi@jcvi.org
	Summary: The current methods available to detect chromosomal abnormalities from DNA microarray expression data are cumbersome and inflexible.
	CAFE has been developed to alleviate these issues.
	It is implemented as an R package that analyzes Affymetrix *.CEL files and comes with flexible plotting functions, easing visualization of chromosomal abnormalities.
	Availability and implementation: CAFE is available from https://bit bucket.org/cob87icW6z/cafe/ as both source and compiled packages for Linux and Windows.
	It is released under the GPL version 3 license.
	CAFE will also be freely available from Bioconductor.
	Contact: sander.h.bollen@gmail.com or nancy.mah@mdc-berlin.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Discussion of point mutations is ubiquitous in biomedical literature, and manually compiling databases or literature on mutations in specific genes or proteins is tedious.
	We present an open-source, rule-based system, MutationFinder, for extracting point mutation mentions from text.
	On blind test data, it achieves nearly perfect precision and a markedly improved recall over a baseline.
	Availability: MutationFinder, along with a high-quality gold standard data set, and a scoring script for mutation extraction systems have been made publicly available.
	Implementations, source code and unit tests are available in Python, Perl and Java.
	MutationFinder can be used as a stand-alone script, or imported by other applications.
	Project URL: http://bionlp.sourceforge.net Contact: gregcaporaso@gmail.com MutationFinder
	Motivation: Repetitive sequences account for approximately half of the human genome.
	Accurately ascertaining sequences in these regions with next generation sequencers is challenging, and requires a different set of analytical techniques than for reads originating from unique sequences.
	Complicating the matter are repetitive regions subject to programmed rearrangements, as is the case with the antigen-binding domains in the Immunoglobulin (Ig) and T-cell receptor (TCR) loci.
	Results: We developed a probability-based score and visualization method to aid in distinguishing true structural variants from alignment artifacts.
	We demonstrate the usefulness of this method in its ability to separate real structural variants from false positives generated with existing upstream analysis tools.
	We validated our approach using both target-capture and whole-genome experiments.
	Capture sequencing reads were generated from primary lymphoid tumors, cancer cell lines and an EBV-transformed lymphoblast cell line over the Ig and TCR loci.
	Whole-genome sequencing reads were from a lymphoblastoid cell-line.
	Availability: We implement our method as an R package available at https://github.com/Eitan177/targetSeqView.
	Code to reproduce the figures and results are also available.
	Contact: ehalper2@jhmi.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Numerous competing algorithms for prediction in highdimensional settings have been developed in the statistical and machine-learning literature.
	Learning algorithms and the prediction models they generate are typically evaluated on the basis of crossvalidation error estimates in a few exemplary datasets.
	However, in most applications, the ultimate goal of prediction modeling is to provide accurate predictions for independent samples obtained in different settings.
	Cross-validation within exemplary datasets may not adequately reflect performance in the broader application context.
	Methods: We develop and implement a systematic approach to 'cross-study validation', to replace or supplement conventional cross-validation when evaluating high-dimensional prediction models in independent datasets.
	We illustrate it via simulations and in a collection of eight estrogen-receptor positive breast cancer microarray gene-expression datasets, where the objective is predicting distant metastasis-free survival (DMFS).
	We computed the C-index for all pairwise combinations of training and validation datasets.
	We evaluate several alternatives for summarizing the pairwise validation statistics, and compare these to conventional cross-validation.
	Results: Our data-driven simulations and our application to survival prediction with eight breast cancer microarray datasets, suggest that standard cross-validation produces inflated discrimination accuracy for all algorithms considered, when compared to cross-study validation.
	Furthermore, the ranking of learning algorithms differs, suggesting that algorithms performing best in cross-validation may be suboptimal when evaluated through independent validation.
	Availability: The survHD: Survival in High Dimensions package (http://www.bitbucket.org/lwaldron/survhd) will be made available through Bioconductor.
	Contact: levi.waldron@hunter.cuny.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Illumina DNA sequencing is now the predominant source of raw genomic data, and data volumes are growing rapidly.
	Bioinformatic analysis pipelines are having trouble keeping pace.
	A common bottleneck in such pipelines is the requirement to read, write, sort and compress large BAM files multiple times.
	Results: We present SAMBLASTER, a tool that reduces the number of times such costly operations are performed.
	SAMBLASTER is designed to mark duplicates in read-sorted SAM files as a piped postpass on DNA aligner output before it is compressed to BAM.
	In addition, it can simultaneously output into separate files the discordant read-pairs and/or split-read mappings used for structural variant calling.
	As an alignment post-pass, its own runtime overhead is negligible, while dramatically reducing overall pipeline complexity and runtime.
	As a stand-alone duplicate marking tool, it performs significantly better than PICARD or SAMBAMBA in terms of both speed and memory usage, while achieving nearly identical results.
	Availability and implementation: SAMBLASTER is open-source C++ code and freely available for download from https://github.com/GregoryFaust/samblaster.
	Contact: imh4y@virginia.edu
	Summary: This article introduces a new forward population genetic simulation program that can efficiently generate samples from populations with complex demographic histories under various models of natural selection.
	The program (SFS_CODE) is highly flexible, allowing the user to simulate realistic genomic regions with several loci evolving according to a variety of mutation models (from simple to context-dependent), and allows for insertions and deletions.
	Each locus can be annotated as either coding or noncoding, sex-linked or autosomal, selected or neutral, and have an arbitrary linkage structure (from completely linked to independent).
	Availability: The source code (written in the C programming language) is available at http://sfscode.sourceforge.net, and a web server (http://cbsuapps.tc.cornell.edu/sfscode.aspx) allows the user to perform simulations using the high-performance computing cluster hosted by the Cornell University Computational Biology Service Unit.
	Contact: rhernandez@uchicago.edu Supplementary information: An extensive user's manual, performance statistics, and comparisons of patterns of genetic variation generated by SFS_CODE to theoretical expectations under various non-stationary demographic histories and models of natural selection are available on the project website: http://sfscode.sourceforge.net.
	Summary: Associations between DNA polymorphisms and mRNA abundance are a natural target of genetic investigations, and microarrays facilitate genome-wide and transcriptome-wide surveys of these associations.
	This work is motivated by emerging requirements for data architectures and algorithm interfaces to allow flexible exploration of public and private archives of genotyping and expression arrays.
	Using R/Bioconductor facilities, Phase II HapMap genotypes and Illumina 47K expression assay results archived on multiple populations may be interactively explored and analyzed using commodity hardware.
	Availability and Implementation: Open Source.
	Bioconductor 2.3 packages GGtools, GGBase, GGdata, hmyriB36.
	Freely available on the web at http://www.bioconductor.org.Contact: stvjc@channing.harvard.edu Page: 1447
	Motivation: Metaproteomic analysis allows studying the interplay of organisms or functional groups and has become increasingly popular also for diagnostic purposes.
	However, difficulties arise owing to the high sequence similarity between related organisms.
	Further, the state of conservation of proteins between species can be correlated with their expression level, which can lead to significant bias in results and interpretation.
	These challenges are similar but not identical to the challenges arising in the analysis of metagenomic samples and require specific solutions.
	Results: We introduce Pipasic (peptide intensity-weighted proteome abundance similarity correction) as a tool that corrects identification and spectral counting-based quantification results using peptide similarity estimation and expression level weighting within a non-negative lasso framework.
	Pipasic has distinct advantages over approaches only regarding unique peptides or aggregating results to the lowest common ancestor, as demonstrated on examples of viral diagnostics and an acid mine drainage dataset.
	Availability and implementation: Pipasic source code is freely available from https://sourceforge.net/projects/pipasic/.Contact: RenardB@rki.de Supplementary information: Supplementary data are available at Bioinformatics online
	Motivation: High-throughput screens (HTS) by RNAi or small molecules are among the most promising tools in functional genomics.
	They enable researchers to observe detailed reactions to experimental perturbations on a genome-wide scale.
	While there is a core set of computational approaches used in many publications to analyze these data, a specialized software combining them and making them easily accessible has so far been missing.
	Results: Here we describe HTSanalyzeR, a flexible software to build integrated analysis pipelines for HTS data that contains overrepresentation analysis, gene set enrichment analysis, comparative gene set analysis and rich sub-network identification.
	HTSanalyzeR interfaces with commonly used pre-processing packages for HTS data and presents its results as HTML pages and network plots.
	Availability: Our software is written in the R language and freely available via the Bioconductor project at http://www.bioconductor .org.
	Contact: florian.markowetz@cancer.org.uk
	Summary: Here, we present PRINSEQ for easy and rapid quality control and data preprocessing of genomic and metagenomic datasets.
	Summary statistics of FASTA (and QUAL) or FASTQ files are generated in tabular and graphical form and sequences can be filtered, reformatted and trimmed by a variety of options to improve downstream analysis.
	Availability and Implementation: This open-source application was implemented in Perl and can be used as a stand alone version or accessed online through a user-friendly web interface.
	The source code, user help and additional information are available at http://prinseq.sourceforge.net/.Contact: rschmied@sciences.sdsu.edu; redwards@cs.sdsu.edu
	Summary: Computer simulations play an important role in studies of non-random mating populations.
	Because of implementation difficulties, only very limited types of non-random mating schemes are provided in the currently available simulation programs.
	Starting with version 0.8.5, simuPOP provides a few mating schemes that can be used to simulate arbitrary non-random mating models.
	This article describes the concepts and methods behind these mating schemes and demonstrates their uses in a few examples, including partial self-mating, positive assortative mating, non-random outbreeding, and simulation of overlapping generations in agestructured populations.
	Availability: simuPOP is freely available at http://simupop.sourceforge.net, distributed under a GPL license.
	Cited examples are in the doc/cookbook directory of a simuPOP distribution.
	Contact: bpeng@mdanderson.org
	Summary: Bacterial genomes are simpler than mammalian ones, and yet assembling the former from the data currently generated by highthroughput short-read sequencing machines still results in hundreds of contigs.
	To improve assembly quality, recent studies have utilized longer Pacific Biosciences (PacBio) reads or jumping libraries to connect contigs into larger scaffolds or help assemblers resolve ambiguities in repetitive regions of the genome.
	However, their popularity in contemporary genomic research is still limited by high cost and error rates.
	In this work, we explore the possibility of improving assemblies by using complete genomes from closely related species/strains.
	We present Ragout, a genome rearrangement approach, to address this problem.
	In contrast with most reference-guided algorithms, where only one reference genome is used, Ragout uses multiple references along with the evolutionary relationship among these references in order to determine the correct order of the contigs.
	Additionally, Ragout uses the assembly graph and multi-scale synteny blocks to reduce assembly gaps caused by small contigs from the input assembly.
	In simulations as well as real datasets, we believe that for common bacterial species, where many complete genome sequences from related strains have been available, the current high-throughput short-read sequencing paradigm is sufficient to obtain a single highquality scaffold for each chromosome.
	Availability: The Ragout software is freely available at: https://github.com/fenderglass/Ragout.
	Contact: spham@salk.edu
	Motivation: The Expectation-Maximization (EM) algorithm has been successfully applied to the problem of transcription factor binding site (TFBS) motif discovery and underlies the most widely used motif discovery algorithms.
	In the wider field of probabilistic modelling, the stochastic EM (sEM) algorithm has been used to overcome some of the limitations of the EM algorithm; however, the application of sEM to motif discovery has not been fully explored.
	Results: We present MITSU (Motif discovery by ITerative Sampling and Updating), a novel algorithm for motif discovery, which combines sEM with an improved approximation to the likelihood function, which is unconstrained with regard to the distribution of motif occurrences within the input dataset.
	The algorithm is evaluated quantitatively on realistic synthetic data and several collections of characterized prokaryotic TFBS motifs and shown to outperform EM and an alternative sEM-based algorithm, particularly in terms of site-level positive predictive value.
	Availability and implementation: Java executable available for download at http://www.sourceforge.net/p/mitsu-motif/, supported on Linux/OS X.
	Contact: a.m.kilpatrick@sms.ed.ac.uk
	Motivation: Time-to-event regression models are a critical tool for associating survival time outcomes with molecular data.
	Despite mounting evidence that genetic subgroups of the same clinical disease exist, little attention has been given to exploring how this heterogeneity affects time-to-event model building and how to accommodate it.
	Methods able to diagnose and model heterogeneity should be valuable additions to the biomarker discovery toolset.
	Results: We propose a mixture of survival functions that classifies subjects with similar relationships to a time-to-event response.
	This model incorporates multivariate regression and model selection and can be fit with an expectation maximization algorithm, we call Coxassisted clustering.
	We illustrate a likely manifestation of genetic heterogeneity and demonstrate how it may affect survival models with little warning.
	An application to gene expression in ovarian cancer DNA repair pathways illustrates how the model may be used to learn new genetic subsets for risk stratification.
	We explore the implications of this model for censored observations and the effect on genomic predictors and diagnostic analysis.
	Availability and implementation: R implementation of CAC using standard packages is available at https://gist.github.com/programeng/8620b85146b14b6edf8f Data used in the analysis are publicly available.
	Contact: kevin.eng@roswellpark.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Assigning RNA-seq reads to their transcript of origin is a fundamental task in transcript expression estimation.
	Where ambiguities in assignments exist due to transcripts sharing sequence, e.g.
	alternative isoforms or alleles, the problem can be solved through probabilistic inference.
	Bayesian methods have been shown to provide accurate transcript abundance estimates compared with competing methods.
	However, exact Bayesian inference is intractable and approximate methods such as Markov chain Monte Carlo and Variational Bayes (VB) are typically used.
	While providing a high degree of accuracy and modelling flexibility, standard implementations can be prohibitively slow for large datasets and complex transcriptome annotations.
	Results: We propose a novel approximate inference scheme based on VB and apply it to an existing model of transcript expression inference from RNA-seq data.
	Recent advances in VB algorithmics are used to improve the convergence of the algorithm beyond the standard Variational Bayes Expectation Maximization algorithm.
	We apply our algorithm to simulated and biological datasets, demonstrating a significant increase in speed with only very small loss in accuracy of expression level estimation.
	We carry out a comparative study against seven popular alternative methods and demonstrate that our new algorithm provides excellent accuracy and inter-replicate consistency while remaining competitive in computation time.
	Availability and implementation: The methods were implemented in R and CÃ¾Ã¾, and are available as part of the BitSeq project at github.com/BitSeq.
	The method is also available through the BitSeq Bioconductor package.
	The source code to reproduce all simulation results can be accessed via github.com/BitSeq/BitSeqVB_benchmarking.
	Contact: james.hensman@sheffield.ac.uk or panagiotis.papastamoulis@manchester.ac.uk or Magnus.Rattray@manchester.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We describe BiopLib, a mature C programming library for manipulating protein structure, and BiopTools, a set of command-line tools which exploit BiopLib.
	The library also provides a small number of functions for handling protein sequence and general purpose programming and mathematics.
	BiopLib transparently handles PDBML (XML) format and standard PDB files.
	BiopTools provides facilities ranging from renumbering atoms and residues to calculation of solvent accessibility.
	Availability and implementation: BiopLib and BiopTools are implemented in standard ANSI C. The core of the BiopLib library is a reliable PDB parser that handles alternate occupancies and deals with compressed PDB files and PDBML files automatically.
	The library is designed to be as flexible as possible, allowing users to handle PDB data as a simple list of atoms, or in a structured form using chains, residues and atoms.
	Many of the BiopTools command-line tools act as filters, taking a PDB (or PDBML) file as input and producing a PDB (or PDBML) file as output.
	All code is open source and documented using Doxygen.
	It is provided under the GNU Public Licence and is available from the authors' web site or from GitHub.
	Contact: andrew@bioinf.org.uk
	Summary: Apollo is a genome annotation-editing tool with an easy to use graphical interface.
	It is a component of the GMOD project, with ongoing development driven by the community.
	Recent additions to the software include support for the generic feature format version 3 (GFF3), continuous transcriptome data, a full Chado database interface, integration with remote services for on-thefly BLAST and Primer BLAST analyses, graphical interfaces for configuring user preferences and full undo of all edit operations.
	Apollo's user community continues to grow, including its use as an educational tool for college and high-school students.
	Availability: Apollo is a Java application distributed under a free and open source license.
	Installers for Windows, Linux, Unix, Solaris and Mac OS X are available at http://apollo.berkeleybop.org, and the source code is available from the SourceForge CVS repository at http://gmod.cvs.sourceforge.net/gmod/apollo.Contact: elee@berkeleybop.org and Ensembl, Apollo is now maintained and developed by the Berkeley Bioinformatics Open Source Projects group.
	Motivation: De novo assemblies of genomes remain one of the most challenging applications in next-generation sequencing.
	Usually, their results are incomplete and fragmented into hundreds of contigs.
	Repeats in genomes and sequencing errors are the main reasons for these complications.
	With the rapidly growing number of sequenced genomes, it is now feasible to improve assemblies by guiding them with genomes from related species.
	Results: Here we introduce AlignGraph, an algorithm for extending and joining de novo-assembled contigs or scaffolds guided by closely related reference genomes.
	It aligns paired-end (PE) reads and preassembled contigs or scaffolds to a close reference.
	From the obtained alignments, it builds a novel data structure, called the PE multipositional de Bruijn graph.
	The incorporated positional information from the alignments and PE reads allows us to extend the initial assemblies, while avoiding incorrect extensions and early terminations.
	In our performance tests, AlignGraph was able to substantially improve the contigs and scaffolds from several assemblers.
	For instance, 28.7-62.3% of the contigs of Arabidopsis thaliana and human could be extended, resulting in improvements of common assembly metrics, such as an increase of the N50 of the extendable contigs by 89.9-94.5% and 80.3-165.8%, respectively.
	In another test, AlignGraph was able to improve the assembly of a published genome (Arabidopsis strain Landsberg) by increasing the N50 of its extendable scaffolds by 86.6%.
	These results demonstrate AlignGraph's efficiency in improving genome assemblies by taking advantage of closely related references.
	Availability and implementation: The AlignGraph software can be downloaded for free from this site: https://github.com/baoe/AlignGraph.
	Contact: thomas.girke@ucr.edu
	Summary: We describe an integrative software platform, Prequips, for comparative proteomics-based systems biology analysis that: (i) integrates all information generated from mass spectrometry (MS)based proteomics as well as from basic proteomics data analysis tools, (ii) visualizes such information for various proteomic analyses via graphical interfaces and (iii) links peptide and protein abundances to external tools often used in systems biology studies.
	Availability: http://prequips.sourceforge.net Contact: dhhwang@postech.ac.kr
	Motivation: While high-throughput sequencing (HTS) has been used successfully to discover tumor-specific mutant peptides (neoantigens) from somatic missense mutations, the field currently lacks a method for identifying which gene fusions may generate neoantigens.
	Results: We demonstrate the application of our gene fusion neoantigen discovery pipeline, called INTEGRATE-Neo, by identifying gene fusions in prostate cancers that may produce neoantigens.
	Availability and Implementation: INTEGRATE-Neo is implemented in C Ã¾Ã¾ and Python.
	Full source code and installation instructions are freely available from https://github.com/ChrisMaherLab/INTEGRATE-Neo.
	Contact: christophermaher@wustl.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: High-throughput single-cell quantitative real-time polymerase chain reaction (qPCR) is a promising technique allowing for new insights in complex cellular processes.
	However, the PCR reaction can be detected only up to a certain detection limit, whereas failed reactions could be due to low or absent expression, and the true expression level is unknown.
	Because this censoring can occur for high proportions of the data, it is one of the main challenges when dealing with single-cell qPCR data.
	Principal component analysis (PCA) is an important tool for visualizing the structure of high-dimensional data as well as for identifying subpopulations of cells.
	However, to date it is not clear how to perform a PCA of censored data.
	We present a probabilistic approach that accounts for the censoring and evaluate it for two typical datasets containing single-cell qPCR data.
	Results: We use the Gaussian process latent variable model framework to account for censoring by introducing an appropriate noise model and allowing a different kernel for each dimension.
	We evaluate this new approach for two typical qPCR datasets (of mouse embryonic stem cells and blood stem/progenitor cells, respectively) by performing linear and non-linear probabilistic PCA.
	Taking the censoring into account results in a 2D representation of the data, which better reflects its known structure: in both datasets, our new approach results in a better separation of known cell types and is able to reveal subpopulations in one dataset that could not be resolved using standard PCA.
	Availability and implementation: The implementation was based on the existing Gaussian process latent variable model toolbox (https://github.com/SheffieldML/GPmat); extensions for noise models and kernels accounting for censoring are available at http://icb.helmholtzmuenchen.de/censgplvm.
	Contact: fbuettner.phys@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Converting nucleotide sequences into short overlapping fragments of uniform length, k-mers, is a common step in many bioinformatics applications.
	While existing software packages count k-mers, few are optimized for speed, offer an application programming interface (API), a graphical interface or contain features that make it extensible and maintainable.
	We designed KAnalyze to compete with the fastest k-mer counters, to produce reliable output and to support future development efforts through well-architected, documented and testable code.
	Currently, KAnalyze can output k-mer counts in a sorted tab-delimited file or stream k-mers as they are read.
	KAnalyze can process large datasets with 2 GB of memory.
	This project is implemented in Java 7, and the command line interface (CLI) is designed to integrate into pipelines written in any language.
	Results: As a k-mer counter, KAnalyze outperforms Jellyfish, DSK and a pipeline built on Perl and Linux utilities.
	Through extensive unit and system testing, we have verified that KAnalyze produces the correct k-mer counts over multiple datasets and k-mer sizes.
	Availability and implementation: KAnalyze is available on SourceForge: https://sourceforge.net/projects/kanalyze/Contact: fredrik.vannberg@biology.gatech.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: High-throughput gene expression microarrays are currently the most efficient method for transcriptome-wide expression analyses.
	Consequently, gene expression data available through public repositories have largely been obtained from microarray experiments.
	However, the metadata associated with many publicly available expression microarray datasets often lacks sample sex information, therefore limiting the reuse of these data in new analyses or larger meta-analyses where the effect of sex is to be considered.
	Here, we present the massiR package, which provides a method for researchers to predict the sex of samples in microarray datasets.
	Using information from microarray probes representing Y chromosome genes, this package implements unsupervised clustering methods to classify samples into male and female groups, providing an efficient way to identify or confirm the sex of samples in mammalian microarray datasets.
	Availability and implementation: massiR is implemented as a Bioconductor package in R. The package and the vignette can be downloaded at bioconductor.org and are provided under a GPL-2 license.
	Contact: sam.buckberry@adelaide.edu.au Supplementary information: Supplementary data are available at Bioinformatics online
	Motivation: Several state-of-the-art methods for isoform identification and quantification are based on '1-regularized regression, such as the Lasso.
	However, explicitly listing the-possibly exponentially-large set of candidate transcripts is intractable for genes with many exons.
	For this reason, existing approaches using the '1-penalty are either restricted to genes with few exons or only run the regression algorithm on a small set of preselected isoforms.
	Results: We introduce a new technique called FlipFlop, which can efficiently tackle the sparse estimation problem on the full set of candidate isoforms by using network flow optimization.
	Our technique removes the need of a preselection step, leading to better isoform identification while keeping a low computational cost.
	Experiments with synthetic and real RNA-Seq data confirm that our approach is more accurate than alternative methods and one of the fastest available.
	Availability and implementation: Source code is freely available as an R package from the Bioconductor Web site (http://www.bioconductor.org/), and more information is available at http://cbio.ensmp.fr/flipflop.Contact: Jean-Philippe.Vert@mines.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Sequences produced by automated Sanger sequencing machines frequently contain fragments of the cloning vector on their ends.
	Software tools currently available for identifying and removing the vector sequence require knowledge of the vector sequence, specific splice sites and any adapter sequences used in the experiment-information often omitted from public databases.
	Furthermore, the clipping coordinates themselves are missing or incorrectly reported.
	As an example, within the 1.24 billion shotgun sequences deposited in the NCBI Trace Archive, as many as 735 million ( 60%) lack vector clipping information.
	Correct clipping information is essential to scientists attempting to validate, improve and even finish the increasingly large number of genomes released at a 'draft' quality level.
	Results: We present here Figaro, a novel software tool for identifying and removing the vector from raw sequence data without prior knowledge of the vector sequence.
	The vector sequence is automatically inferred by analyzing the frequency of occurrence of short oligo-nucleotides using Poisson statistics.
	We show that Figaro achieves 99.98% sensitivity when tested on 1.5 million shotgun reads from Drosophila pseudoobscura.
	We further explore the impact of accurate vector trimming on the quality of wholegenome assemblies by re-assembling two bacterial genomes from shotgun sequences deposited in the Trace Archive.
	Designed as a module in large computational pipelines, Figaro is fast, lightweight and flexible.
	Availability: Figaro is released under an open-source license through the AMOS package (http://amos.sourceforge.net/Figaro).Contact: mpop@umiacs.umd.edu
	Motivation: Many peak detection algorithms have been proposed for ChIP-seq data analysis, but it is not obvious which algorithm and what parameters are optimal for any given dataset.
	In contrast, regions with and without obvious peaks can be easily labeled by visual inspection of aligned read counts in a genome browser.
	We propose a supervised machine learning approach for ChIP-seq data analysis, using labels that encode qualitative judgments about which genomic regions contain or do not contain peaks.
	The main idea is to manually label a small subset of the genome, and then learn a model that makes consistent peak predictions on the rest of the genome.
	Results: We created 7 new histone mark datasets with 12 826 visually determined labels, and analyzed 3 existing transcription factor datasets.
	We observed that default peak detection parameters yield high false positive rates, which can be reduced by learning parameters using a relatively small training set of labeled data from the same experiment type.
	We also observed that labels from different people are highly consistent.
	Overall, these data indicate that our supervised labeling method is useful for quantitatively training and testing peak detection algorithms.
	Availability and Implementation: Labeled histone mark data http://cbio.ensmp.fr/~thocking/chipseq-chunk-db/, R package to compute the label error of predicted peaks https://github.com/tdhock/PeakError Contacts: toby.hocking@mail.mcgill.ca or guil.bourque@mcgill.ca Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Nested effects models (NEMs) are a class of probabilistic models introduced to analyze the effects of gene perturbation screens visible in high-dimensional phenotypes like microarrays or cell morphology.
	NEMs reverse engineer upstream/downstream relations of cellular signaling cascades.
	NEMs take as input a set of candidate pathway genes and phenotypic profiles of perturbing these genes.
	NEMs return a pathway structure explaining the observed perturbation effects.
	Here, we describe the package nem, an open-source software to efficiently infer NEMs from data.
	Our software implements several search algorithms for model fitting and is applicable to a wide range of different data types and representations.
	The methods we present summarize the current state-of-the-art in NEMs.
	Availability: Our software is written in the R language and freely available via the Bioconductor project at http://www.bioconductor.org.
	Contact: rainer.spang@klinik.uni-regensburg.de Â© The Author 2008.
	Published by Oxford University Press.
	All rights reserved.
	For Permissions, please email: journals.permissions@oxfordjournals.org
	Summary: Easyfig is a Python application for creating linear comparison figures of multiple genomic loci with an easy-to-use graphical user interface.
	BLAST comparisons between multiple genomic regions, ranging from single genes to whole prokaryote chromosomes, can be generated, visualized and interactively coloured, enabling a rapid transition between analysis and the preparation of publication quality figures.
	Availability: Easyfig is freely available (under a GPL license) for download (for Mac OS X, Unix and Microsoft Windows) from the SourceForge web site: http://easyfig.sourceforge.net/.Contact: s.beatson@uq.edu.au
	Motivation: Human immunodeficiency virus (HIV) and cancer require personalized therapies owing to their inherent heterogeneous nature.
	For both diseases, large-scale pharmacogenomic screens of molecularly characterized samples have been generated with the hope of identifying genetic predictors of drug susceptibility.
	Thus, computational algorithms capable of inferring robust predictors of drug responses from genomic information are of great practical importance.
	Most of the existing computational studies that consider drug susceptibility prediction against a panel of drugs formulate a separate learning problem for each drug, which cannot make use of commonalities between subsets of drugs.
	Results: In this study, we propose to solve the problem of drug susceptibility prediction against a panel of drugs in a multitask learning framework by formulating a novel Bayesian algorithm that combines kernel-based non-linear dimensionality reduction and binary classification (or regression).
	The main novelty of our method is the joint Bayesian formulation of projecting data points into a shared subspace and learning predictive models for all drugs in this subspace, which helps us to eliminate off-target effects and drug-specific experimental noise.
	Another novelty of our method is the ability of handling missing phenotype values owing to experimental conditions and quality control reasons.
	We demonstrate the performance of our algorithm via crossvalidation experiments on two benchmark drug susceptibility datasets of HIV and cancer.
	Our method obtains statistically significantly better predictive performance on most of the drugs compared with baseline single-task algorithms that learn drug-specific models.
	These results show that predicting drug susceptibility against a panel of drugs simultaneously within a multitask learning framework improves overall predictive performance over single-task learning approaches.
	Availability and implementation: Our Matlab implementations for binary classification and regression are available at https://github.com/mehmetgonen/kbmtl.
	Contact: mehmet.gonen@sagebase.org Supplementary Information: Supplementary data are available at Bioinformatics online.
	Summary: We have developed PathBuilder, an open-source web application to annotate biological information pertaining to signaling pathways and to create web-based pathway resources.
	PathBuilder enables annotation of molecular events including protein-protein interactions, enzyme-substrate relationships and protein translocation events either manually or through automated importing of data from other databases.
	Salient features of PathBuilder include automatic validation of data formats, built-in modules for visualization of pathways, automated import of data from other pathway resources, export of data in several standard data exchange formats and an application programming interface for retrieving existing pathway datasets.
	Availability: PathBuilder is freely available for download at http://pathbuilder.sourceforge.net/ under the terms of GNU lesser general public license (LGPL: http://www.gnu.org/copyleft/lesser.html).
	The software is platform independent and has been tested on Windows and Linux platforms.
	Contact: pandey@jhmi.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Eukaryotic gene expression is controlled through molecular logic circuits that combine regulatory signals of many different factors.
	In particular, complexation of transcription factors (TFs) and other regulatory proteins is a prevailing and highly conserved mechanism of signal integration within critical regulatory pathways and enables us to infer controlled genes as well as the exerted regulatory mechanism.
	Common approaches for protein complex prediction that only use protein interaction networks, however, are designed to detect selfcontained functional complexes and have difficulties to reveal dynamic combinatorial assemblies of physically interacting proteins.
	Results: We developed the novel algorithm DACO that combines protein-protein interaction networks and domain-domain interaction networks with the cluster-quality metric cohesiveness.
	The metric is locally maximized on the holistic level of protein interactions, and connectivity constraints on the domain level are used to account for the exclusive and thus inherently combinatorial nature of the interactions within such assemblies.
	When applied to predicting TF complexes in the yeast Saccharomyces cerevisiae, the proposed approach outperformed popular complex prediction methods by far.
	Furthermore, we were able to assign many of the predictions to target genes, as well as to a potential regulatory effect in agreement with literature evidence.
	Availability and implementation: A prototype implementation is freely available at https://sourceforge.net/projects/dacoalgorithm/.Contact: volkhard.helms@bioinformatik.uni-saarland.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Exome sequencing technologies have transformed the field of Mendelian genetics and allowed for efficient detection of genomic variants in protein-coding regions.
	The target enrichment process that is intrinsic to exome sequencing is inherently imperfect, generating large amounts of unintended off-target sequence.
	Off-target data are characterized by very low and highly heterogeneous coverage and are usually discarded by exome analysis pipelines.
	We posit that offtarget read depth is a rich, but overlooked, source of information that could be mined to detect intergenic copy number variation (CNV).
	We propose cnvOffseq, a novel normalization framework for off-target read depth that is based on local adaptive singular value decomposition (SVD).
	This method is designed to address the heterogeneity of the underlying data and allows for accurate and precise CNV detection and genotyping in off-target regions.
	Results: cnvOffSeq was benchmarked on whole-exome sequencing samples from the 1000 Genomes Project.
	In a set of 104 gold standard intergenic deletions, our method achieved a sensitivity of 57.5% and a specificity of 99.2%, while maintaining a low FDR of 5%.
	For gold standard deletions longer than 5 kb, cnvOffSeq achieves a sensitivity of 90.4% without increasing the FDR.
	cnvOffSeq outperforms both whole-genome and whole-exome CNV detection methods considerably and is shown to offer a substantial improvement over na\u20acÄ±ve local SVD.
	Availability and Implementation: cnvOffSeq is available at http://sourceforge.net/p/cnvoffseq/ Contact: evangelos.bellos09@imperial.ac.uk or l.coin@imb.uq.edu.au Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Model exchange in systems and synthetic biology has been standardized for computers with the Systems Biology Markup Language (SBML) and CellML, but specialized software is needed for the generation of models in these formats.
	Text-based model definition languages allow researchers to create models simply, and then export them to a common exchange format.
	Modular languages allow researchers to create and combine complex models more easily.
	We saw a use for a modular text-based language, together with a translation library to allow other programs to read the models as well.
	Summary: The Antimony language provides a way for a researcher to use simple text statements to create, import, and combine biological models, allowing complex models to be built from simpler models, and provides a special syntax for the creation of modular genetic networks.
	The libAntimony library allows other software packages to import these models and convert them either to SBML or their own internal format.
	Availability: The Antimony language specification and the libAntimony library are available under a BSD license from http://antimony.sourceforge.net/Contact: lpsmith@u.washington.edu Page: 2452
	Motivation: Statistically assessing the relation between a set of genomic regions and other genomic features is a common challenging task in genomic and epigenomic analyses.
	Randomization based approaches implicitly take into account the complexity of the genome without the need of assuming an underlying statistical model.
	Summary: regioneR is an R package that implements a permutation test framework specifically designed to work with genomic regions.
	In addition to the predefined randomization and evaluation strategies, regioneR is fully customizable allowing the use of custom strategies to adapt it to specific questions.
	Finally, it also implements a novel function to evaluate the local specificity of the detected association.
	Availability and implementation: regioneR is an R package released under Artistic-2.0 License.
	The source code and documents are freely available through Bioconductor (http://www.bioconductor.org/packages/regioneR).
	Contact: rmalinverni@carrerasresearch.org
	Page: 2573
	Motivation: Short Interspersed Nuclear Elements (SINEs) are transposable elements (TEs) that amplify through a copy-and-paste mode via RNA intermediates.
	The computational identification of new SINEs are challenging because of their weak structural signals and rapid diversification in sequences.
	Results: Here we report SINE_Scan, a highly efficient program to predict SINE elements in genomic DNA sequences.
	SINE_Scan integrates hallmark of SINE transposition, copy number and structural signals to identify a SINE element.
	SINE_Scan outperforms the previously published de novo SINE discovery program.
	It shows high sensitivity and specificity in 19 plant and animal genome assemblies, of which sizes vary from 120 Mb to 3.5 Gb.
	It identifies numerous new families and substantially increases the estimation of the abundance of SINEs in these genomes.
	Availability and Implementation: The code of SINE_Scan is freely available at http://github.com/maohlzj/SINE_Scan, implemented in PERL and supported on Linux.
	Contact: wangh8@fudan.edu.cn Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Automated analysis of flow cytometry (FCM) data is essential for it to become successful as a high throughput technology.
	We believe that the principles of Trellis graphics can be adapted to provide useful visualizations that can aid such automation.
	In this article, we describe the R/Bioconductor package flowViz that implements such visualizations.
	Availability: flowViz is available as an R package from the Bioconductor project: http://bioconductor.org Contact: dsarkar@fhcrc.org
	Motivation: Variant detection from next-generation sequencing (NGS) data is an increasingly vital aspect of disease diagnosis, treatment and research.
	Commonly used NGS-variant analysis tools generally rely on accurately mapped short reads to identify somatic variants and germline genotypes.
	Existing NGS read mappers have difficulty accurately mapping short reads containing complex variation (i.e.
	more than a single base change), thus making identification of such variants difficult or impossible.
	Insertions and deletions (indels) in particular have been an area of great difficulty.
	Indels are frequent and can have substantial impact on function, which makes their detection all the more imperative.
	Results: We present ABRA, an assembly-based realigner, which uses an efficient and flexible localized de novo assembly followed by global realignment to more accurately remap reads.
	This results in enhanced performance for indel detection as well as improved accuracy in variant allele frequency estimation.
	Availability and implementation: ABRA is implemented in a combination of Java and C/C++ and is freely available for download at https://github.com/mozack/abra.Contact: lmose@unc.edu; parkerjs@email.unc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Somatic amplification of particular genomic regions and selection of cellular lineages with such amplifications drives tumor development.
	However, pinpointing genes under such selection has been difficult due to the large span of these regions.
	Our recentlydeveloped method, the amplification distortion test (ADT), identifies specific nucleotide alleles and haplotypes that confer better survival for tumor cells when somatically amplified.
	In this work, we focus on evaluating ADT's power to detect such causal variants across a variety of tumor dataset scenarios.
	Results: Towards this end, we generated multiple parameter-based, synthetic datasets-derived from real data-that contain somatic copy number aberrations (CNAs) of various lengths and frequencies over germline single nucleotide polymorphisms (SNPs) genomewide.
	Gold-standard causal sub-regions were assigned within these CNAs, followed by an assessment of ADT's ability to detect these sub-regions.
	Results indicate that ADT possesses high sensitivity and specificity in large sample sizes across most parameter cases, including those that more closely reflect existing SNP and CNA cancer data.
	Availability: ADT is implemented in the Java software HADiT and can be downloaded through the SVN repository (via Developâ†’ Codeâ†’SVN Browse) at: http://sourceforge.net/projects/hadit/.Contact: ninad.dewal@dbmi.columbia.edu Supplementary Information: Supplementary data are available at Bioinformatics online.
	Motivation: Exome sequencing (exome-seq) data, which are typically used for calling exonic mutations, have also been utilized in detecting DNA copy number variations (CNVs).
	Despite the existence of several CNV detection tools, there is still a great need for a sensitive and an accurate CNV-calling algorithm with built-in QC steps, and does not require a paired reference for each sample.
	Results: We developed a novel method named PatternCNV, which (i) accounts for the read coverage variations between exons while leveraging the consistencies of this variability across different samples; (ii) reduces alignment BAM files to WIG format and therefore greatly accelerates computation; (iii) incorporates multiple QC measures designed to identify outlier samples and batch effects; and (iv) provides a variety of visualization options including chromosome, gene and exon-level views of CNVs, along with a tabular summarization of the exon-level CNVs.
	Compared with other CNV-calling algorithms using data from a lymphoma exome-seq study, PatternCNV has higher sensitivity and specificity.
	Availability and implementation: The software for PatternCNV is implemented using Perl and R, and can be used in Mac or Linux environments.
	Software and user manual are available at http://bioinformaticstools.mayo.edu/research/patterncnv/, and R package at https://github.com/topsoil/patternCNV/.Contact: Asmann.Yan@mayo.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: BioBlend.objects is a new component of the BioBlend package, adding an object-oriented interface for the Galaxy RESTbased application programming interface.
	It improves support for metacomputing on Galaxy entities by providing higher-level functionality and allowing users to more easily create programs to explore, query and create Galaxy datasets and workflows.
	Availability and implementation: BioBlend.objects is available online at https://github.com/afgane/bioblend.
	The new object-oriented API is implemented by the galaxy/objects subpackage.
	Contact: simone.leo@crs4.it
	Motivation: Genome-wide association studies (GWAS) are used to discover genes underlying complex, heritable disorders for which less powerful study designs have failed in the past.
	The number of GWAS has skyrocketed recently with findings reported in top journals and the mainstream media.
	Microarrays are the genotype calling technology of choice in GWAS as they permit exploration of more than a million single nucleotide polymorphisms (SNPs) simultaneously.
	The starting point for the statistical analyses used by GWAS to determine association between loci and disease is making genotype calls (AA, AB or BB).
	However, the raw data, microarray probe intensities, are heavily processed before arriving at these calls.
	Various sophisticated statistical procedures have been proposed for transforming raw data into genotype calls.
	We find that variability in microarray output quality across different SNPs, different arrays and different sample batches have substantial influence on the accuracy of genotype calls made by existing algorithms.
	Failure to account for these sources of variability can adversely affect the quality of findings reported by the GWAS.
	Results: We developed a method based on an enhanced version of the multi-level model used by CRLMM version 1.
	Two key differences are that we now account for variability across batches and improve the call-specific assessment of each call.
	The new model permits the development of quality metrics for SNPs, samples and batches of samples.
	Using three independent datasets, we demonstrate that the CRLMM version 2 outperforms CRLMM version 1 and the algorithm provided by Affymetrix, Birdseed.
	The main advantage of the new approach is that it enables the identification of low-quality SNPs, samples and batches.
	Availability: Software implementing of the method described in this article is available as free and open source code in the crlmm R/BioConductor package.
	Contact: rafa@jhu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Accurate haplotyping-determining from which parent particular portions of the genome are inherited-is still mostly an unresolved problem in genomics.
	This problem has only recently started to become tractable, thanks to the development of new long read sequencing technologies.
	Here, we introduce ProbHap, a haplotyping algorithm targeted at such technologies.
	The main algorithmic idea of ProbHap is a new dynamic programming algorithm that exactly optimizes a likelihood function specified by a probabilistic graphical model and which generalizes a popular objective called the minimum error correction.
	In addition to being accurate, ProbHap also provides confidence scores at phased positions.
	Results: On a standard benchmark dataset, ProbHap makes 11% fewer errors than current state-of-the-art methods.
	This accuracy can be further increased by excluding low-confidence positions, at the cost of a small drop in haplotype completeness.
	Availability: Our source code is freely available at: https://github.com/kuleshov/ProbHap.
	Contact: kuleshov@stanford.edu
	Summary: SensA is a web-based application for sensitivity analysis of mathematical models.
	The sensitivity analysis is based on metabolic control analysis, computing the local, global and time-dependent properties of model components.
	Interactive visualization facilitates interpretation of usually complex results.
	SensA can contribute to the analysis, adjustment and understanding of mathematical models for dynamic systems.
	Availability and implementation: SensA is available at http://gofid.biologie.hu-berlin.de/ and can be used with any modern browser.
	The source code can be found at https://bitbucket.org/floettma/sensa/(MIT license) Contact: max.floettmann@biologie.hu-berlin.de or thomas.spiesser@ biologie.hu-berlin.de
	Summary: MetaboSignal is an R package that allows merging metabolic and signaling pathways reported in the Kyoto Encyclopaedia of Genes and Genomes (KEGG).
	It is a network-based approach designed to navigate through topological relationships between genes (signaling- or metabolic-genes) and metabolites, representing a powerful tool to investigate the genetic landscape of metabolic phenotypes.
	Availability and Implementation: MetaboSignal is available from Bioconductor: https://bioconduc tor.org/packages/MetaboSignal/ Contact: m.dumas@imperial.ac.uk.
	Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We present Edlib, an open-source C/C Ã¾Ã¾ library for exact pairwise sequence alignment using edit distance.
	We compare Edlib to other libraries and show that it is the fastest while not lacking in functionality and can also easily handle very large sequences.
	Being easy to use, flexible, fast and low on memory usage, we expect it to be easily adopted as a building block for future bioinformatics tools.
	Availability and Implementation: Source code, installation instructions and test data are freely available for download at https://github.com/Martinsos/edlib, under the MIT licence.
	Edlib is implemented in C/C Ã¾Ã¾ and supported on Linux, MS Windows, and Mac OS.
	Contact: mile.sikic@fer.hr Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Recently it has been shown that the quality of protein contact prediction from evolutionary information can be improved significantly if direct and indirect information is separated.
	Given sufficiently large protein families, the contact predictions contain sufficient information to predict the structure of many protein families.
	However, since the first studies contact prediction methods have improved.
	Here, we ask how much the final models are improved if improved contact predictions are used.
	Results: In a small benchmark of 15 proteins, we show that the TMscores of top-ranked models are improved by on average 33% using PconsFold compared with the original version of EVfold.
	In a larger benchmark, we find that the quality is improved with 15-30% when using PconsC in comparison with earlier contact prediction methods.
	Further, using Rosetta instead of CNS does not significantly improve global model accuracy, but the chemistry of models generated with Rosetta is improved.
	Availability: PconsFold is a fully automated pipeline for ab initio protein structure prediction based on evolutionary information.
	PconsFold is based on PconsC contact prediction and uses the Rosetta folding protocol.
	Due to its modularity, the contact prediction tool can be easily exchanged.
	The source code of PconsFold is available on GitHub at https://www.github.com/ElofssonLab/pcons-fold under the MIT license.
	PconsC is available from http://c.pcons.net/.Contact: arne@bioinfo.se Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: In flux balance analysis of genome scale stoichiometric models of metabolism, the principal constraints are uptake or secretion rates, the steady state mass conservation assumption and reaction directionality.
	Here, we introduce an algorithmic pipeline for quantitative assignment of reaction directionality in multi-compartmental genome scale models based on an application of the second law of thermodynamics to each reaction.
	Given experimental or computationally estimated standard metabolite species Gibbs energy and metabolite concentrations, the algorithms bounds reaction Gibbs energy, which is transformed to in vivo pH, temperature, ionic strength and electrical potential.
	Results: This cross-platform MATLAB extension to the COnstraintBased Reconstruction and Analysis (COBRA) toolbox is computationally efficient, extensively documented and open source.
	Availability: http://opencobra.sourceforge.net Contact: ronan.mt.fleming@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The reference CRAM file format implementation is in Java.
	We present 'Scramble': a new C implementation of SAM, BAM and CRAM file I/O.
	Results: The C implementation of for CRAM is 1.5-1.7 slower than BAM at decoding but 1.8-2.6 faster at encoding.
	We see file size savings of 34-55%.
	Availability and implementation: Source code is available at http://sourceforge.net/projects/staden/files/io_lib/ under the BSD software licence.
	Contact: jkb@sanger.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Coordinated Gene Activity in Pattern Sets (CoGAPS) provides an integrated package for isolating gene expression driven by a biological process, enhancing inference of biological processes from transcriptomic data.
	CoGAPS improves on other enrichment measurement methods by combining a Markov chain Monte Carlo (MCMC) matrix factorization algorithm (GAPS) with a thresholdindependent statistic inferring activity on gene sets.
	The software is provided as open source C++ code built on top of JAGS software with an R interface.
	Availability: The R package CoGAPS and the C++ package GAPSJAGS are provided open source under the GNU Lesser Public License (GLPL) with a users manual containing installation and operating instructions.
	CoGAPS is available through Bioconductor and depends on the rjags package available through CRAN to interface CoGAPS with GAPS-JAGS.
	URL: http://www.cancerbiostats.onc.jhmi.edu/cogaps.cfm Contact: ejfertig@jhmi.edu; mfo@jhu.edu Supplementary Information: Supplementary data is available at Bioinformatics online.
	Motivation: The increasing availability of mitochondria-targeted and off-target sequencing data in whole-exome and whole-genome sequencing studies (WXS and WGS) has risen the demand of effective pipelines to accurately measure heteroplasmy and to easily recognize the most functionally important mitochondrial variants among a huge number of candidates.
	To this purpose, we developed MToolBox, a highly automated pipeline to reconstruct and analyze human mitochondrial DNA from high-throughput sequencing data.
	Results: MToolBox implements an effective computational strategy for mitochondrial genomes assembling and haplogroup assignment also including a prioritization analysis of detected variants.
	MToolBox provides a Variant Call Format file featuring, for the first time, allele-specific heteroplasmy and annotation files with prioritized variants.
	MToolBox was tested on simulated samples and applied on 1000 Genomes WXS datasets.
	Availability and implementation: MToolBox package is available at https://sourceforge.net/projects/mtoolbox/.Contact: marcella.attimonelli@uniba.it Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The availability of flexible open source software for the analysis of gene expression raw level data has greatly facilitated the development of widely used preprocessing methods for these technologies.
	However, the expansion of microarray applications has exposed the limitation of existing tools.
	Results: We developed the oligo package to provide a more general solution that supports a wide range of applications.
	The package is based on the BioConductor principles of transparency, reproducibility and efficiency of development.
	It extends the existing tools and leverages existing code for visualization, accessing data and widely used preprocessing routines.
	The oligo package implements a unified paradigm for preprocessing data and interfaces with other BioConductor tools for downstream analysis.
	Our infrastructure is general and can be used by other BioConductor packages.
	Availability: The oligo package is freely available through BioConductor, http://www.bioconductor.org.Contact: benilton.carvalho@cancer.org.uk; rafa@jhu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Circleator is a Perl application that generates circular figures of genome-associated data.
	It leverages BioPerl to support standard annotation and sequence file formats and produces publication-quality SVG output.
	It is designed to be both flexible and easy to use.
	It includes a library of circular track types and predefined configuration files for common use-cases, including.
	(i) visualizing gene annotation and DNA sequence data from a GenBank flat file, (ii) displaying patterns of gene conservation in related microbial strains, (iii) showing Single Nucleotide Polymorphisms (SNPs) and indels relative to a reference genome and gene set and (iv) viewing RNA-Seq plots.
	Availability and implementation: Circleator is freely available under the Artistic License 2.0 from http://jonathancrabtree.github.io/Circleator/ and is integrated with the CloVR cloud-based sequence analysis Virtual Machine (VM), which can be downloaded from http://clovr.org or run on Amazon EC2.Contact: jcrabtree@som.umaryland.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Recent breakthroughs in protein residue-residue contact prediction have made reliable de novo prediction of protein structures possible.
	The key was to apply statistical methods that can distinguish direct couplings between pairs of columns in a multiple sequence alignment from merely correlated pairs, i.e.
	to separate direct from indirect effects.
	Two classes of such methods exist, either relying on regularized inversion of the covariance matrix or on pseudo-likelihood maximization (PLM).
	Although PLM-based methods offer clearly higher precision, available tools are not sufficiently optimized and are written in interpreted languages that introduce additional overheads.
	This impedes the runtime and large-scale contact prediction for larger protein families, multi-domain proteins and protein-protein interactions.
	Results: Here we introduce CCMpred, our performance-optimized PLM implementation in C and CUDA C. Using graphics cards in the price range of current six-core processors, CCMpred can predict contacts for typical alignments 35-113 times faster and with the same precision as the most accurate published methods.
	For users without a CUDA-capable graphics card, CCMpred can also run in a CPU mode that is still 4-14 times faster.
	Thanks to our speed-ups (http://dictionary.cambridge.org/dictionary/british/speed-up) contacts for typical protein families can be predicted in 15-60 s on a consumer-grade GPU and 1-6 min on a six-core CPU.
	Availability and implementation: CCMpred is free and open-source software under the GNU Affero General Public License v3 (or later) available at https://bitbucket.org/soedinglab/ccmpred Contact: johannes.soeding@mpibpc.mpg.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We present Vacceed, a highly configurable and scalable framework designed to automate the process of high-throughput in silico vaccine candidate discovery for eukaryotic pathogens.
	Given thousands of protein sequences from the target pathogen as input, the main output is a ranked list of protein candidates determined by a set of machine learning algorithms.
	Vacceed has the potential to save time and money by reducing the number of false candidates allocated for laboratory validation.
	Vacceed, if required, can also predict protein sequences from the pathogen's genome.
	Availability and implementation: Vacceed is tested on Linux and can be freely downloaded from https://github.com/sgoodswe/vacceed/re leases (includes a worked example with sample data).
	Vacceed User Guide can be obtained from https://github.com/sgoodswe/vacceed.Contact: John.Ellis@uts.edu.au Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Population structure significantly affects evolutionary dynamics.
	Such structure may be due to spatial segregation, but may also reflect any other gene-flow-limiting aspect of a model.
	In combination with the structured coalescent, this fact can be used to inform phylogenetic tree reconstruction, as well as to infer parameters such as migration rates and subpopulation sizes from annotated sequence data.
	However, conducting Bayesian inference under the structured coalescent is impeded by the difficulty of constructing Markov Chain Monte Carlo (MCMC) sampling algorithms (samplers) capable of efficiently exploring the state space.
	Results: In this article, we present a new MCMC sampler capable of sampling from posterior distributions over structured trees: timed phylogenetic trees in which lineages are associated with the distinct subpopulation in which they lie.
	The sampler includes a set of MCMC proposal functions that offer significant mixing improvements over a previously published method.
	Furthermore, its implementation as a BEAST 2 package ensures maximum flexibility with respect to model and prior specification.
	We demonstrate the usefulness of this new sampler by using it to infer migration rates and effective population sizes of H3N2 influenza between New Zealand, New York and Hong Kong from publicly available hemagglutinin (HA) gene sequences under the structured coalescent.
	Availability and implementation: The sampler has been implemented as a publicly available BEAST 2 package that is distributed under version 3 of the GNU General Public License at http://compevol.github.io/MultiTypeTree.
	Contact: tgvaughan@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Associate Editor: Dmitrij Frishman Summary: Tabix is the first generic tool that indexes position sorted files in TAB-delimited formats such as GFF, BED, PSL, SAM and SQL export, and quickly retrieves features overlapping specified regions.
	Tabix features include few seek function calls per query, data compression with gzip compatibility and direct FTP/HTTP access.
	Tabix is implemented as a free command-line tool as well as a library in C, Java, Perl and Python.
	It is particularly useful for manually examining local genomic features on the command line and enables genome viewers to support huge data files and remote custom tracks over networks.
	Availability and Implementation: http://samtools.sourceforge.net.Contact: hengli@broadinstitute.org
	Summary: I propose a new application of profile Hidden Markov Models in the area of SNP discovery from resequencing data, to greatly reduce false SNP calls caused by misalignments around insertions and deletions (indels).
	The central concept is per-Base Alignment Quality, which accurately measures the probability of a read base being wrongly aligned.
	The effectiveness of BAQ has been positively confirmed on large datasets by the 1000 Genomes Project analysis subgroup.
	Availability: http://samtools.sourceforge.net Contact: hengli@broadinstitute.org
	Motivation: Analysis of genomic sequencing data requires efficient, easy-to-use access to alignment results and flexible data management tools (e.g.
	filtering, merging, sorting, etc.).
	However, the enormous amount of data produced by current sequencing technologies is typically stored in compressed, binary formats that are not easily handled by the text-based parsers commonly used in bioinformatics research.
	Results: We introduce a software suite for programmers and end users that facilitates research analysis and data management using BAM files.
	BamTools provides both the first C++ API publicly available for BAM file support as well as a command-line toolkit.
	Availability: BamTools was written in C++, and is supported on Linux, Mac OSX and MS Windows.
	Source code and documentation are freely available at http://github.org/pezmaster31/bamtools.Contact: barnetde@bc.edu The API FEATURES AND METHODS
	Summary: OTUbase is an R package designed to facilitate the analysis of operational taxonomic unit (OTU) data and sequence classification (taxonomic) data.
	Currently there are programs that will cluster sequence data into OTUs and/or classify sequence data into known taxonomies.
	However, there is a need for software that can take the summarized output of these programs and organize it into easily accessed and manipulated formats.
	OTUbase provides this structure and organization within R, to allow researchers to easily manipulate the data with the rich library of R packages currently available for additional analysis.
	Availability: OTUbase is an R package available through Bioconductor.
	It can be found at http://www.bioconductor.org/packages/release/bioc/html/OTUbase.html.
	Contact: msettles@uidaho.edu
	Motivation: Retrieval and reproducible functional annotation of genomic data are crucial in biology.
	However, the current poor usability and transparency of retrieval methods hinders reproducibility.
	Here we present an open source R package, biomartr, which provides a comprehensive easy-to-use framework for automating data retrieval and functional annotation for meta-genomic approaches.
	The functions of biomartr achieve a high degree of clarity, transparency and reproducibility of analyses.
	Results: The biomartr package implements straightforward functions for bulk retrieval of all genomic data or data for selected genomes, proteomes, coding sequences and annotation files present in databases hosted by the National Center for Biotechnology Information (NCBI) and European Bioinformatics Institute (EMBL-EBI).
	In addition, biomartr communicates with the BioMart database for functional annotation of retrieved sequences.
	Comprehensive documentation of biomartr functions and five tutorial vignettes provide step-by-step instructions on how to use the package in a reproducible manner.
	Availability and Implementation: The open source biomartr package is available at https://github.com/HajkD/biomartr and https://cran.r-project.org/web/packages/biomartr/index.html.Contact: hgd23@cam.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Epistasis analysis is an essential tool of classical genetics for inferring the order of function of genes in a common pathway.
	Typically, it considers single and double mutant phenotypes and for a pair of genes observes whether a change in the first gene masks the effects of the mutation in the second gene.
	Despite the recent emergence of biotechnology techniques that can provide gene interaction data on a large, possibly genomic scale, few methods are available for quantitative epistasis analysis and epistasis-based network reconstruction.
	Results: We here propose a conceptually new probabilistic approach to gene network inference from quantitative interaction data.
	The approach is founded on epistasis analysis.
	Its features are joint treatment of the mutant phenotype data with a factorized model and probabilistic scoring of pairwise gene relationships that are inferred from the latent gene representation.
	The resulting gene network is assembled from scored pairwise relationships.
	In an experimental study, we show that the proposed approach can accurately reconstruct several known pathways and that it surpasses the accuracy of current approaches.
	Availability and implementation: Source code is available at http://github.com/biolab/red.
	Contact: blaz.zupan@fri.uni-lj.si Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Discovering variation among high-throughput sequenced genomes relies on efficient and effective mapping of sequence reads.
	The speed, sensitivity and accuracy of read mapping are crucial to determining the full spectrum of single nucleotide variants (SNVs) as well as structural variants (SVs) in the donor genomes analyzed.
	Results: We present drFAST, a read mapper designed for di-base encoded 'color-space' sequences generated with the AB SOLiD platform.
	drFAST is specially designed for better delineation of structural variants, including segmental duplications, and is able to return all possible map locations and underlying sequence variation of short reads within a user-specified distance threshold.
	We show that drFAST is more sensitive in comparison to all commonly used aligners such as Bowtie, BFAST and SHRiMP.
	drFAST is also faster than both BFAST and SHRiMP and achieves a mapping speed comparable to Bowtie.
	Availability: The source code for drFAST is available at http://drfast.sourceforge.net Contact: calkan@u.washington.edu
	Summary: The large number of genomes that will be sequenced will need to be annotated with genes and other functional features.
	Aligning gene sequences from a related species to the target genome is an economical and highly reliable method to identify genes; unfortunately, existing tools have been lacking in sensitivity and speed.
	A program we reported, sim4cc, was shown to be highly accurate but is limited to comparing one cDNA with one genomic sequence.
	We present here an optimization of the tool, implemented in the packages sim4db and leaff.
	The new tool performs batch alignments of cDNA and genomic sequences in a fraction of the time required by its predecessor, and thus is very well suited for genome-wide analyses.
	Availability: Sim4db and leaff are written in C, C++ and Perl for Linux and other Unix platforms.
	Source code is distributed free of charge from http://sourceforge.net/projects/kmer/.Contact: florea@umiacs.umd.edu Supplementary information: Supplementary data are available at Bioinformatics Online.
	Summary: Non-targeted metabolomics technologies often yield data in which abundance for any given metabolite is observed and quantified for some samples and reported as missing for other samples.
	Apparent missingness can be due to true absence of the metabolite in the sample or presence at a level below detectability.
	Mixture-model analysis can formally account for metabolite 'missingness' due to absence or undetectability, but software for this type of analysis in the high-throughput setting is limited.
	The R package metabomxtr has been developed to facilitate mixture-model analysis of non-targeted metabolomics data in which only a portion of samples have quantifiable abundance for certain metabolites.
	Availability and implementation: metabomxtr is available through Bioconductor.
	It is released under the GPL-2 license.
	Contact: dscholtens@northwestern.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The Oxford Nanopore MinION device represents a unique sequencing technology.
	As a mobile sequencing device powered by the USB port of a laptop, the MinION has huge potential applications.
	To enable these applications, the bioinformatics community will need to design and build a suite of tools specifically for MinION data.
	Results: Here we present poRe, a package for R that enables users to manipulate, organize, summarize and visualize MinION nanopore sequencing data.
	As a package for R, poRe has been tested on Windows, Linux and MacOSX.
	Crucially, the Windows version allows users to analyse MinION data on the Windows laptop attached to the device.
	Availability and implementation: poRe is released as a package for R at http://sourceforge.net/projects/rpore/.
	A tutorial and further information are available at https://sourceforge.net/p/rpore/wiki/Home/Contact: mick.watson@roslin.ed.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Sensitivity analysis and parameter tuning are important processes in large-scale image analysis.
	They are very costly because the image analysis workflows are required to be executed several times to systematically correlate output variations with parameter changes or to tune parameters.
	An integrated solution with minimum user interaction that uses effective methodologies and high performance computing is required to scale these studies to large imaging datasets and expensive analysis workflows.
	Results: The experiments with two segmentation workflows show that the proposed approach can (i) quickly identify and prune parameters that are non-influential; (ii) search a small fraction (about 100 points) of the parameter search space with billions to trillions of points and improve the quality of segmentation results (Dice and Jaccard metrics) by as much as 1.42 compared to the results from the default parameters; (iii) attain good scalability on a high performance cluster with several effective optimizations.
	Conclusions: Our work demonstrates the feasibility of performing sensitivity analyses, parameter studies and auto-tuning with large datasets.
	The proposed framework can enable the quantification of error estimations and output variations in image segmentation pipelines.
	Availability and Implementation: Source code: https://github.com/SBU-BMI/region-templates/.Contact: teodoro@unb.br Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Gene-gene interactions are of potential biological and medical interest, as they can shed light on both the inheritance mechanism of a trait and on the underlying biological mechanisms.
	Evidence of epistatic interactions has been reported in both humans and other organisms.
	Unlike single-locus genome-wide association studies (GWAS), which proved efficient in detecting numerous genetic loci related with various traits, interaction-based GWAS have so far produced very few reproducible discoveries.
	Such studies introduce a great computational and statistical burden by necessitating a large number of hypotheses to be tested including all pairs of single nucleotide polymorphisms (SNPs).
	Thus, many software tools have been developed for interaction-based case-control studies, some leading to reliable discoveries.
	For quantitative data, on the other hand, only a handful of tools exist, and the computational burden is still substantial.
	Results: We present an efficient algorithm for detecting epistasis in quantitative GWAS, achieving a substantial runtime speedup by avoiding the need to exhaustively test all SNP pairs using metric embedding and random projections.
	Unlike previous metric embedding methods for case-control studies, we introduce a new embedding, where each SNP is mapped to two Euclidean spaces.
	We implemented our method in a tool named EPIQ (EPIstasis detection for Quantitative GWAS), and we show by simulations that EPIQ requires hours of processing time where other methods require days and sometimes weeks.
	Applying our method to a dataset from the Ludwigshafen risk and cardiovascular health study, we discovered a pair of SNPs with a near-significant interaction (P = 2.2 10 13), in only 1.5 h on 10 processors.
	Availability: https://github.com/yaarasegre/EPIQ Contact: heran@post.tau.ac.il
	Summary: Chimera is a Bioconductor package that organizes, annotates, analyses and validates fusions reported by different fusion detection tools; current implementation can deal with output from bellerophontes, chimeraScan, deFuse, fusionCatcher, FusionFinder, FusionHunter, FusionMap, mapSplice, Rsubread, tophat-fusion and STAR.
	The core of Chimera is a fusion data structure that can store fusion events detected with any of the aforementioned tools.
	Fusions are then easily manipulated with standard R functions or through the set of functionalities specifically developed in Chimera with the aim of supporting the user in managing fusions and discriminating falsepositive results.
	Availability and implementation: Chimera is implemented as a Bioconductor package in R. The package and the vignette can be downloaded at bioconductor.org.
	Contact: raffaele.calogero@unito.it Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: If a cancer patient develops multiple tumors, it is sometimes impossible to determine whether these tumors are independent or clonal based solely on pathological characteristics.
	Investigators have studied how to improve this diagnostic challenge by comparing the presence of loss of heterozygosity (LOH) at selected genetic locations of tumor samples, or by comparing genomewide copy number array profiles.
	We have previously developed statistical methodology to compare such genomic profiles for an evidence of clonality.
	We assembled the software for these tests in a new R package called 'Clonality'.
	For LOH profiles, the package contains significance tests.
	The analysis of copy number profiles includes a likelihood ratio statistic and reference distribution, as well as an option to produce various plots that summarize the results.
	Availability: Bioconductor (http://bioconductor.org/packages/release/bioc/html/Clonality.html) and http://www.mskcc.org/mskcc/html/13287.cfm.
	Contact: ostrovni@mskcc.org
	Motivation: The analysis of large biological datasets often requires complex processing pipelines that run for a long time on large computational infrastructures.
	We designed and implemented a simple script-like programming language with a clean and minimalist syntax to develop and manage pipeline execution and provide robustness to various types of software and hardware failures as well as portability.
	Results: We introduce the BigDataScript (BDS) programming language for data processing pipelines, which improves abstraction from hardware resources and assists with robustness.
	Hardware abstraction allows BDS pipelines to run without modification on a wide range of computer architectures, from a small laptop to multi-core servers, server farms, clusters and clouds.
	BDS achieves robustness by incorporating the concepts of absolute serialization and lazy processing, thus allowing pipelines to recover from errors.
	By abstracting pipeline concepts at programming language level, BDS simplifies implementation, execution and management of complex bioinformatics pipelines, resulting in reduced development and debugging cycles as well as cleaner code.
	Availability and implementation: BigDataScript is available under open-source license at http://pcingola.github.io/BigDataScript.Contact: pablo.e.cingolani@gmail.com
	Motivation: Next-generation sequencing experiments, such as RNASeq, play an increasingly important role in biological research.
	One complication is that the power and accuracy of such experiments depend substantially on the number of reads sequenced, so it is important and challenging to determine the optimal read depth for an experiment or to verify whether one has adequate depth in an existing experiment.
	Results: By randomly sampling lower depths from a sequencing experiment and determining where the saturation of power and accuracy occurs, one can determine what the most useful depth should be for future experiments, and furthermore, confirm whether an existing experiment had sufficient depth to justify its conclusions.
	We introduce the subSeq R package, which uses a novel efficient approach to perform this subsampling and to calculate informative metrics at each depth.
	Availability and Implementation: The subSeq R package is available at http://github.com/StoreyLab/subSeq/.Contact: dgrtwo@princeton.edu or jstorey@princeton.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: We present a Web service to access Ensembl data using Representational State Transfer (REST).
	The Ensembl REST server enables the easy retrieval of a wide range of Ensembl data by most programming languages, using standard formats such as JSON and FASTA while minimizing client work.
	We also introduce bindings to the popular Ensembl Variant Effect Predictor tool permitting large-scale programmatic variant analysis independent of any specific programming language.
	Availability and implementation: The Ensembl REST API can be accessed at http://rest.ensembl.org and source code is freely available under an Apache 2.0 license from http://github.com/Ensembl/ensembl-rest.
	Contact: ayates@ebi.ac.uk or flicek@ebi.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: StochKit2 is the first major upgrade of the popular StochKit stochastic simulation software package.
	StochKit2 provides highly efficient implementations of several variants of Gillespie's stochastic simulation algorithm (SSA), and tau-leaping with automatic step size selection.
	StochKit2 features include automatic selection of the optimal SSA method based on model properties, event handling, and automatic parallelism on multicore architectures.
	The underlying structure of the code has been completely updated to provide a flexible framework for extending its functionality.
	Availability: StochKit2 runs on Linux/Unix, Mac OS X and Windows.
	It is freely available under GPL version 3 and can be downloaded from http://sourceforge.net/projects/stochkit/.Contact: petzold@engineering.ucsb.edu
	Motivation: MethylCoder is a software program that generates per-base methylation data given a set of bisulfite-treated reads.
	It provides the option to use either of two existing short-read aligners, each with different strengths.
	It accounts for soft-masked alignments and overlapping paired-end reads.
	MethylCoder outputs data in text and binary formats in addition to the final alignment in SAM format, so that common high-throughput sequencing tools can be used on the resulting output.
	It is more flexible than existing software and competitive in terms of speed and memory use.
	Availability: MethylCoder requires only a python interpreter and a C compiler to run.
	Extensive documentation and the full source code are available under the MIT license at: https://github.com/brentp /methylcode.
	Contact: bpederse@gmail.com
	Summary: Methyl-Analyzer is a python package that analyzes genome-wide DNA methylation data produced by the MethylMAPS (methylation mapping analysis by paired-end sequencing) method.
	Methyl-MAPS is an enzymatic-based method that uses both methylation-sensitive and -dependent enzymes covering >80% of CpG dinucleotides within mammalian genomes.
	It combines enzymatic-based approaches with high-throughput next-generation sequencing technology to provide whole genome DNA methylation profiles.
	Methyl-Analyzer processes and integrates sequencing reads from methylated and unmethylated compartments and estimates CpG methylation probabilities at single base resolution.
	Availability and implementation: Methyl-Analyzer is available at http://github.com/epigenomics/methylmaps.
	Sample dataset is available for download at http://epigenomicspub.columbia.edu/methylanalyzer_data.html.
	Contact: fgh3@columbia.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Biological sequence variants are commonly represented in scientific literature, clinical reports and databases of variation using the mutation nomenclature guidelines endorsed by the Human Genome Variation Society (HGVS).
	Despite the widespread use of the standard, no freely available and comprehensive programming libraries are available.
	Here we report an open-source and easy-to-use Python library that facilitates the parsing, manipulation, formatting and validation of variants according to the HGVS specification.
	The current implementation focuses on the subset of the HGVS recommendations that precisely describe sequence-level variation relevant to the application of high-throughput sequencing to clinical diagnostics.
	Availability and implementation: The package is released under the Apache 2.0 open-source license.
	Source code, documentation and issue tracking are available at http://bitbucket.org/hgvs/hgvs/.Python packages are available at PyPI (https://pypi.python.org/pypi/hgvs).
	Contact: reecehart@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We report CRdata.org, a cloud-based, free, open-source web server for running analyses and sharing data and R scripts with others.
	In addition to using the free, public service, CRdata users can launch their own private Amazon Elastic Computing Cloud (EC2) nodes and store private data and scripts on Amazon's Simple Storage Service (S3) with user-controlled access rights.
	All CRdata services are provided via point-and-click menus.
	Availability and Implementation: CRdata is open-source and free under the permissive MIT License (opensource.org/licenses/mitlicense.php).
	The source code is in Ruby (ruby-lang.org/en/) and available at: github.com/seerdata/crdata.
	Contact: hbolouri@fhcrc.org
	Motivation: PIWI-interacting RNAs (piRNAs), 23-36 nt small silencing RNAs, repress transposon expression in the metazoan germ line, thereby protecting the genome.
	Although high-throughput sequencing has made it possible to examine the genome and transcriptome at unprecedented resolution, extracting useful information from gigabytes of sequencing data still requires substantial computational skills.
	Additionally, researchers may analyze and interpret the same data differently, generating results that are difficult to reconcile.
	To address these issues, we developed a coordinated set of pipelines, 'piPipes', to analyze piRNA and transposon-derived RNAs from a variety of high-throughput sequencing libraries, including small RNA, RNA, degradome or 7-methyl guanosine cap analysis of gene expression (CAGE), chromatin immunoprecipitation (ChIP) and genomic DNA-seq.
	piPipes can also produce figures and tables suitable for publication.
	By facilitating data analysis, piPipes provides an opportunity to standardize computational methods in the piRNA field.
	Supplementary information: Supplementary information, including flowcharts and example figures for each pipeline, are available at Bioinformatics online.
	Availability and implementation: piPipes is implemented in Bash, C++, Python, Perl and R. piPipes is free, open-source software distributed under the GPLv3 license and is available at http://bowhan.github.io/piPipes/.
	Contact: Phillip.Zamore@umassmed.edu or Zhiping.Weng@umass med.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Animal models are widely used in biomedical research for reasons ranging from practical to ethical.
	An important issue is whether rodent models are predictive of human biology.
	This has been addressed recently in the framework of a series of challenges designed by the systems biology verification for Industrial Methodology for Process Verification in Research (sbv IMPROVER) initiative.
	In particular, one of the sub-challenges was devoted to the prediction of protein phosphorylation responses in human bronchial epithelial cells, exposed to a number of different chemical stimuli, given the responses in rat bronchial epithelial cells.
	Participating teams were asked to make inter-species predictions on the basis of available training examples, comprising transcriptomics and phosphoproteomics data.
	Results: Here, the two best performing teams present their datadriven approaches and computational methods.
	In addition, post hoc analyses of the datasets and challenge results were performed by the participants and challenge organizers.
	The challenge outcome indicates that successful prediction of protein phosphorylation status in human based on rat phosphorylation levels is feasible.
	However, within the limitations of the computational tools used, the inclusion of gene expression data does not improve the prediction quality.
	The post hoc analysis of time-specific measurements sheds light on the signaling pathways in both species.
	Availability and implementation: A detailed description of the dataset, challenge design and outcome is available at www.sbvimprover.
	com.
	The code used by team IGB is provided under http://github.com/uci-igb/improver2013.
	Implementations of the algorithms applied by team AMG are available at http://bhanot.biomaps.rutgers.edu/wiki/AMG-sc2-code.zip.
	Contact: meikelbiehl@gmail.com
	Motivation: Genome-wide association studies (GWAS) have identified many loci implicated in disease susceptibility.
	Integration of GWAS summary statistics (P-values) and functional genomic datasets should help to elucidate mechanisms.
	Results: We extended a non-parametric SNP set enrichment method to test for enrichment of GWAS signals in functionally defined loci to a situation where only GWAS P-values are available.
	The approach is implemented in VSEAMS, a freely available software pipeline.
	We use VSEAMS to identify enrichment of type 1 diabetes (T1D) GWAS associations near genes that are targets for the transcription factors IKZF3, BATF and ESRRA.
	IKZF3 lies in a known T1D susceptibility region, while BATF and ESRRA overlap other immune disease susceptibility regions, validating our approach and suggesting novel avenues of research for T1D.
	Availability and implementation: VSEAMS is available for download (http://github.com/ollyburren/vseams).Contact: chris.wallace@cimr.cam.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We present GeneNet Toolbox for MATLAB (also available as a set of standalone applications for Linux).
	The toolbox, available as command-line or with a graphical user interface, enables biologists to assess connectivity among a set of genes of interest ('seed-genes') within a biological network of their choosing.
	Two methods are implemented for calculating the significance of connectivity among seed-genes: 'seed randomization' and 'network permutation'.
	Options include restricting analyses to a specified subnetwork of the primary biological network, and calculating connectivity from the seed-genes to a second set of interesting genes.
	Pre-analysis tools help the user choose the best connectivity-analysis algorithm for their network.
	The toolbox also enables visualization of the connections among seed-genes.
	GeneNet Toolbox functions execute in reasonable time for very large networks ( 10 million edges) on a desktop computer.
	Availability and implementation: GeneNet Toolbox is open source and freely available from http://avigailtaylor.github.io/gntat14.Supplementary information: Supplementary data are available at Bioinformatics online.
	Contact: avigail.taylor@dpag.ox.ac.uk
	Motivation: Nanopore sequencing may be the next disruptive technology in genomics, owing to its ability to detect single DNA molecules without prior amplification, lack of reliance on expensive optical components, and the ability to sequence long fragments.
	The MinIONTM from Oxford Nanopore Technologies (ONT) is the first nanopore sequencer to be commercialized and is now available to early-access users.
	The MinIONTM is a USB-connected, portable nanopore sequencer that permits real-time analysis of streaming event data.
	Currently, the research community lacks a standardized toolkit for the analysis of nanopore datasets.
	Results: We introduce poretools, a flexible toolkit for exploring datasets generated by nanopore sequencing devices from MinIONTM for the purposes of quality control and downstream analysis.
	Poretools operates directly on the native FAST5 (an application of the HDF5 standard) file format produced by ONT and provides a wealth of format conversion utilities and data exploration and visualization tools.
	Availability and implementation: Poretools is an open-source software and is written in Python as both a suite of command line utilities and a Python application programming interface.
	Source code is freely available in Github at https://www.github.com/arq5x/poretools Contact: n.j.loman@bham.ac.uk and aaronquinlan@gmail.com Supplementary information: An IPython notebook demonstrating the functionality of poretools is in Github.
	Complete documentation is available at http://poretools.readthedocs.org.
	Summary: In this article we present Simple Exploration of Ecological Data (Seed), a data exploration tool for microbial communities.
	Seed is written in R using the Shiny library.
	This provides access to powerful R-based functions and libraries through a simple user interface.
	Seed allows users to explore ecological datasets using principal coordinate analyses, scatter plots, bar plots, hierarchal clustering and heatmaps.
	Availability and implementation: Seed is open source and available at https://github.com/danlbek/Seed.Contact: danlbek@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Associate Editor: Jeffrey Barrett
	Summary: SysGenSIM is a software package to simulate Systems Genetics (SG) experiments in model organisms, for the purpose of evaluating and comparing statistical and computational methods and their implementations for analyses of SG data [e.g.
	methods for expression quantitative trait loci (eQTL) mapping and network inference].
	SysGenSIM allows the user to select a variety of network topologies, genetic and kinetic parameters to simulate SG data ( genotyping, gene expression and phenotyping) with large gene networks with thousands of nodes.
	The software is encoded in MATLAB, and a user-friendly graphical user interface is provided.
	Availability: The open-source software code and user manual can be downloaded at: http://sysgensim.sourceforge.net/Contact: alf@crs4.it
	Summary: The survcomp package provides functions to assess and statistically compare the performance of survival/risk prediction models.
	It implements state-of-the-art statistics to (i) measure the performance of risk prediction models; (ii) combine these statistical estimates from multiple datasets using a meta-analytical framework; and (iii) statistically compare the performance of competitive models.
	Availability: The R/Bioconductor package survcomp is provided open source under the Artistic-2.0 License with a user manual containing installation, operating instructions and use case scenarios on real datasets.
	survcomp requires R version 2.13.0 or higher.
	http://bioconductor.org/packages/release/bioc/html/survcomp.html Contact: bhaibeka@jimmy.harvard.edu; mschroed@jimmy.harvard.edu Supplementary Information: Supplementary data are available at Bioinformatics online.
	Summary: PPDMs is a resource that maps small molecule bioactivities to protein domains from the Pfam-A collection of protein families.
	Small molecule bioactivities mapped to protein domains add important precision to approaches that use protein sequence searches alignments to assist applications in computational drug discovery and systems and chemical biology.
	We have previously proposed a mapping heuristic for a subset of bioactivities stored in ChEMBL with the Pfam-A domain most likely to mediate small molecule binding.
	We have since refined this mapping using a manual procedure.
	Here, we present a resource that provides up-to-date mappings and the possibility to review assigned mappings as well as to participate in their assignment and curation.
	We also describe how mappings provided through the PPDMs resource are made accessible through the main schema of the ChEMBL database.
	Availability and implementation: The PPDMs resource and curation interface is available at https://www.ebi.ac.uk/chembl/research/ppdms/pfam_maps.
	The source-code for PPDMs is available under the Apache license at https://github.com/chembl/pfam_maps.
	Source code is available at https://github.com/chembl/pfam_map_loader to demonstrate the integration process with the main schema of ChEMBL.
	Contact: jpo@ebi.ac.uk
	Summary: Current strategies for SNP and INDEL discovery incorporate sequence alignments from multiple individuals to maximize sensitivity and specificity.
	It is widely accepted that this approach also improves structural variant (SV) detection.
	However, multisample SV analysis has been stymied by the fundamental difficulties of SV calling, e.g.
	library insert size variability, SV alignment signal integration and detecting long-range genomic rearrangements involving disjoint loci.
	Extant tools suffer from poor scalability, which limits the number of genomes that can be co-analyzed and complicates analysis workflows.
	We have developed an approach that enables multisample SV analysis in hundreds to thousands of human genomes using commodity hardware.
	Here, we describe Hydra-Multi and measure its accuracy, speed and scalability using publicly available datasets provided by The 1000 Genomes Project and by The Cancer Genome Atlas (TCGA).
	Availability and implementation: Hydra-Multi is written in CÃ¾Ã¾ and is freely available at https://github.com/arq5x/Hydra.
	Contact: aaronquinlan@gmail.com or ihall@genome.wustl.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Single nucleotide polymorphism (SNP) discovery is an important preliminary for understanding genetic variation.
	With current sequencing methods, we can sample genomes comprehensively.
	SNPs are found by aligning sequence reads against longer assembled references.
	De Bruijn graphs are efficient data structures that can deal with the vast amount of data from modern technologies.
	Recent work has shown that the topology of these graphs captures enough information to allow the detection and characterization of genetic variants, offering an alternative to alignment-based methods.
	Such methods rely on depth-first walks of the graph to identify closing bifurcations.
	These methods are conservative or generate many false-positive results, particularly when traversing highly inter-connected (complex) regions of the graph or in regions of very high coverage.
	Results: We devised an algorithm that calls SNPs in converted De Bruijn graphs by enumerating 2k Ã¾ 2 cycles.
	We evaluated the accuracy of predicted SNPs by comparison with SNP lists from alignment-based methods.
	We tested accuracy of the SNP calling using sequence data from 16 ecotypes of Arabidopsis thaliana and found that accuracy was high.
	We found that SNP calling was even across the genome and genomic feature types.
	Using sequence-based attributes of the graph to train a decision tree allowed us to increase accuracy of SNP calls further.
	Together these results indicate that our algorithm is capable of finding SNPs accurately in complex sub-graphs and potentially comprehensively from whole genome graphs.
	Availability and implementation: The source code for a CÃ¾Ã¾ implementation of our algorithm is available under the GNU Public Licence v3 at: https://github.com/danmaclean/2kplus2.
	The datasets used in this study are available at the European Nucleotide Archive, reference ERP00565, http://www.ebi.ac.uk/ena/data/view/ERP000565 Contact: dan.maclean@tsl.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Next-generation sequencing (NGS) is an ideal framework for the characterization of highly variable pathogens, with a deep resolution able to capture minority variants.
	However, the reconstruction of all variants of a viral population infecting a host is a challenging task for genome regions larger than the average NGS read length.
	QuRe is a program for viral quasispecies reconstruction, specifically developed to analyze long read (>100 bp) NGS data.
	The software performs alignments of sequence fragments against a reference genome, finds an optimal division of the genome into sliding windows based on coverage and diversity and attempts to reconstruct all the individual sequences of the viral quasispecies-along with their prevalence-using a heuristic algorithm, which matches multinomial distributions of distinct viral variants overlapping across the genome division.
	QuRe comes with a built-in Poisson error correction method and a post-reconstruction probabilistic clustering, both parameterized on given error rates in homopolymeric and non-homopolymeric regions.
	Availability: QuRe is platform-independent, multi-threaded software implemented in Java.
	It is distributed under the GNU General Public License, available at https://sourceforge.net/projects/qure/.Contact: ahnven@yahoo.it; ahnven@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: MR-Tandem adapts the popular X!Tandem peptide search engine to work with Hadoop MapReduce for reliable parallel execution of large searches.
	MR-Tandem runs on any Hadoop cluster but offers special support for Amazon Web Services for creating inexpensive on-demand Hadoop clusters, enabling search volumes that might not otherwise be feasible with the compute resources a researcher has at hand.
	MR-Tandem is designed to drop in wherever X!Tandem is already in use and requires no modification to existing X!Tandem parameter files, and only minimal modification to X!Tandem-based workflows.
	Availability and implementation: MR-Tandem is implemented as a lightly modified X!Tandem C++ executable and a Python script that drives Hadoop clusters including Amazon Web Services (AWS) Elastic Map Reduce (EMR), using the modified X!Tandem program as a Hadoop Streaming mapper and reducer.
	The modified X!Tandem C++ source code is Artistic licensed, supports pluggable scoring, and is available as part of the Sashimi project at http://sashimi.svn.sourceforge.net/viewvc/sashimi/trunk/trans _proteomic_pipeline/extern/xtandem/.
	The MR-Tandem Python script is Apache licensed and available as part of the Insilicos Cloud Army project at http://ica.svn.sourceforge.net/viewvc/ica/trunk/mrtandem/.
	Full documentation and a windows installer that configures MR-Tandem, Python and all necessary packages are available at this same URL.
	Contact: brian.pratt@insilicos.com
	Motivation: DNA methylation is an intensely studied epigenetic mark implicated in many biological processes of direct clinical relevance.
	Although sequencing-based technologies are increasingly allowing high-resolution measurements of DNA methylation, statistical modelling of such data is still challenging.
	In particular, statistical identification of differentially methylated regions across different conditions poses unresolved challenges in accounting for spatial correlations within the statistical testing procedure.
	Results: We propose a non-parametric, kernel-based method, M3D, to detect higher order changes in methylation profiles, such as shape, across pre-defined regions.
	The test statistic explicitly accounts for differences in coverage levels between samples, thus handling in a principled way a major confounder in the analysis of methylation data.
	Empirical tests on real and simulated datasets show an increased power compared to established methods, as well as considerable robustness with respect to coverage and replication levels.
	Availability and implementation: R/Bioconductor package M3D.
	Contact: G.Sanguinetti@ed.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: No individual assembly algorithm addresses all the known limitations of assembling short-length sequences.
	Overall reduced sequence contig length is the major problem that challenges the usage of these assemblies.
	We describe an algorithm to take advantages of different assembly algorithms or sequencing platforms to improve the quality of next-generation sequence (NGS) assemblies.
	Results: The algorithm is implemented as a graph accordance assembly (GAA) program.
	The algorithm constructs an accordance graph to capture the mapping information between the target and query assemblies.
	Based on the accordance graph, the contigs or scaffolds of the target assembly can be extended, merged or bridged together.
	Extra constraints, including gap sizes, mate pairs, scaffold order and orientation, are explored to enforce those accordance operations in the correct context.
	We applied GAA to various chicken NGS assemblies and the results demonstrate improved contiguity statistics and higher genome and gene coverage.
	Availability: GAA is implemented in OO perl and is available here: http://sourceforge.net/projects/gaa-wugi/.Contact: lye@genome.wustl.edu
	Summary: MetMSLine represents a complete collection of functions in the R programming language as an accessible GUI for biomarker discovery in large-scale liquid-chromatography high-resolution mass spectral datasets from acquisition through to final metabolite identification forming a backend to output from any peak-picking software such as XCMS.
	MetMSLine automatically creates subdirectories, data tables and relevant figures at the following steps: (i) signal smoothing, normalization, filtration and noise transformation (PreProc.QC.LSC.R); (ii) PCA and automatic outlier removal (Auto.PCA.R); (iii) automatic regression, biomarker selection, hierarchical clustering and cluster ion/artefact identification (Auto.MV.Regress.R); (iv) Biomarker-MS/MS fragmentation spectra matching and fragment/neutral loss annotation (Auto.MS.MS.match.R) and (v) semi-targeted metabolite identification based on a list of theoretical masses obtained from public databases (DBAnnotate.R).
	Availability and implementation: All source code and suggested parameters are available in an un-encapsulated layout on http://wmbedmands.github.io/MetMSLine/.
	Readme files and a synthetic dataset of both X-variables (simulated LC-MS data), Y-variables (simulated continuous variables) and metabolite theoretical masses are also available on our GitHub repository.
	Contact: ScalbertA@iarc.fr
	Summary: QuasR is a package for the integrated analysis of high-throughput sequencing data in R, covering all steps from read preprocessing, alignment and quality control to quantification.
	QuasR supports different experiment types (including RNA-seq, ChIP-seq and Bis-seq) and analysis variants (e.g.
	paired-end, stranded, spliced and allele-specific), and is integrated in Bioconductor so that its output can be directly processed for statistical analysis and visualization.
	Availability and implementation: QuasR is implemented in R and C/CÃ¾Ã¾.
	Source code and binaries for major platforms (Linux, OS X and MS Windows) are available from Bioconductor (www.bioconductor.org/packages/release/bioc/html/QuasR.html).
	The package includes a 'vignette' with stepby-step examples for typical work flows.
	Contact: michael.stadler@fmi.ch Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: RNA-Seq is a method for profiling transcription using high-throughput sequencing and is an important component of many research projects that wish to study transcript isoforms, condition specific expression and transcriptional structure.
	The methods, tools and technologies used to perform RNA-Seq analysis continue to change, creating a bioinformatics challenge for researchers who wish to exploit these data.
	Resources that bring together genomic data, analysis tools, educational material and computational infrastructure can minimize the overhead required of life science researchers.
	Results: RNA-Rocket is a free service that provides access to RNA-Seq and ChIP-Seq analysis tools for studying infectious diseases.
	The site makes available thousands of pre-indexed genomes, their annotations and the ability to stream results to the bioinformatics resources VectorBase, EuPathDB and PATRIC.
	The site also provides a combination of experimental data and metadata, examples of pre-computed analysis, step-by-step guides and a user interface designed to enable both novice and experienced users of RNA-Seq data.
	Availability and implementation: RNA-Rocket is available at rnaseq.pathogenportal.org.
	Source code for this project can be found at github.com/cidvbi/PathogenPortal.
	Contact: anwarren@vt.edu Supplementary information: Supplementary materials are available at Bioinformatics online.
	Summary: VarSim is a framework for assessing alignment and variant calling accuracy in highthroughput genome sequencing through simulation or real data.
	In contrast to simulating a random mutation spectrum, it synthesizes diploid genomes with germline and somatic mutations based on a realistic model.
	This model leverages information such as previously reported mutations to make the synthetic genomes biologically relevant.
	VarSim simulates and validates a wide range of variants, including single nucleotide variants, small indels and large structural variants.
	It is an automated, comprehensive compute framework supporting parallel computation and multiple read simulators.
	Furthermore, we developed a novel map data structure to validate read alignments, a strategy to compare variants binned in size ranges and a lightweight, interactive, graphical report to visualize validation results with detailed statistics.
	Thus far, it is the most comprehensive validation tool for secondary analysis in next generation sequencing.
	Availability and implementation: Code in Java and Python along with instructions to download the reads and variants is at http://bioinform.github.io/varsim.Contact: rd@bina.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: The volume of an internal protein pocket is fundamental to ligand accessibility.
	Few programs that compute such volumes manage dynamic data from molecular dynamics (MD) simulations.
	Limited performance often prohibits analysis of large datasets.
	We present Epock, an efficient command-line tool that calculates pocket volumes from MD trajectories.
	A plugin for the VMD program provides a graphical user interface to facilitate input creation, run Epock and analyse the results.
	Availability and implementation: Epock CÃ¾Ã¾ source code, Python analysis scripts, VMD Tcl plugin, documentation and installation instructions are freely available at http://epock.bitbucket.org.Contact: benoist.laurent@gmail.com or baaden@smplinux.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: ICMA, a software framework to create 3D finite element models of the left ventricle from cardiac ultrasound or magnetic resonance imaging (MRI) data, has been made available as an open-source code.
	The framework is hardware vendor independent and uses speckle tracking (endocardial border detection) on ultrasound (MRI) imaging data in the form of DICOM.
	Standard American Heart Association segment-based strain analysis can be performed using a browserbased interface.
	The speckle tracking, border detection and model fitting methods are implemented in CÃ¾Ã¾ using open-source tools.
	They are wrapped as web services and orchestrated via a JBOSSbased application server.
	Availability and implementation: The source code for ICMA is freely available under MPL 1.1 or GPL 2.0 or LGPL 2.1 license at https://github.com/ABI-Software-Laboratory/ICMA and a standalone virtual machine at http://goo.gl/M4lJKH for download.Contact: r.jagir@auckland.ac.nz Supplementary information: Supplementary materials are available at Bioinformatics online.
	Motivation: With rapidly increasing volumes of biological sequence data the functional analysis of new sequences in terms of similarities to known protein families challenges classical bioinformatics.
	Results: The ultrafast protein classification (UProC) toolbox implements a novel algorithm ('Mosaic Matching') for large-scale sequence analysis.
	UProC is by three orders of magnitude faster than profile-based methods and in a metagenome simulation study achieved up to 80% higher sensitivity on unassembled 100 bp reads.
	Availability and implementation: UProC is available as an open-source software at https://github.com/gobics/uproc.
	Precompiled databases (Pfam) are linked on the UProC homepage: http://uproc.gobics.de/.
	Contact: peter@gobics.de.
	Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Coalescent-based simulation software for genomic sequences allows the efficient in silico generation of short- and medium-sized genetic sequences.
	However, the simulation of genome-size datasets as produced by next-generation sequencing is currently only possible using fairly crude approximations.
	Results: We present the sequential coalescent with recombination model (SCRM), a new method that efficiently and accurately approximates the coalescent with recombination, closing the gap between current approximations and the exact model.
	We present an efficient implementation and show that it can simulate genomic-scale datasets with an essentially correct linkage structure.
	Availability and implementation: The open source implementation scrm is freely available at https://scrm.github.io under the conditions of the GPLv3 license.Contact: staab@bio.lmu.de or gerton.lunter@well.ox.ac.uk.
	Supplementary information: Supplementary data are available at Bioinformatics online.
	Availability: The 'flowType: Phenotyping Multivariate PFC Assays' package is available through Bioconductor.
	Additional documentation and examples are available at: www.terryfoxlab.ca/ flowsite/flowType/ Supplementary information: Supplementary data are available at Bioinformatics online.
	Contact: rbrinkman@bccrc.ca
	Summary: Microbial communities have an important role in natural ecosystems and have an impact on animal and human health.
	Intuitive graphic and analytical tools that can facilitate the study of these communities are in short supply.
	This article introduces Microbial Community Analysis GUI, a graphical user interface (GUI) for the R-programming language (R Development Core Team, 2010).
	With this application, researchers can input aligned and clustered sequence data to create custom abundance tables and perform analyses specific to their needs.
	This GUI provides a flexible modular platform, expandable to include other statistical tools for microbial community analysis in the future.
	Availability: The mcaGUI package and source are freely available as part of Bionconductor at http://www.bioconductor.org/packages/release/bioc/html/mcaGUI.html Contact: wade@kingcopeland.com; zabdo@uidaho.edu Supplementary Information: Supplementary data and figures are available at Bioinformatics online.
	Motivation: In neuroscience, as in many other scientific domains, the primary form of knowledge dissemination is through published articles.
	One challenge for modern neuroinformatics is finding methods to make the knowledge from the tremendous backlog of publications accessible for search, analysis and the integration of such data into computational models.
	A key example of this is metascale brain connectivity, where results are not reported in a normalized repository.
	Instead, these experimental results are published in natural language, scattered among individual scientific publications.
	This lack of normalization and centralization hinders the large-scale integration of brain connectivity results.
	In this article, we present text-mining models to extract and aggregate brain connectivity results from 13.2 million PubMed abstracts and 630 216 full-text publications related to neuroscience.
	The brain regions are identified with three different named entity recognizers (NERs) and then normalized against two atlases: the Allen Brain Atlas (ABA) and the atlas from the Brain Architecture Management System (BAMS).
	We then use three different extractors to assess inter-region connectivity.
	Results: NERs and connectivity extractors are evaluated against a manually annotated corpus.
	The complete in litero extraction models are also evaluated against in vivo connectivity data from ABA with an estimated precision of 78%.
	The resulting database contains over 4 million brain region mentions and over 100 000 (ABA) and 122 000 (BAMS) potential brain region connections.
	This database drastically accelerates connectivity literature review, by providing a centralized repository of connectivity data to neuroscientists.
	Availability and implementation: The resulting models are publicly available at github.com/ BlueBrain/bluima.
	Contact: renaud.richardet@epfl.ch Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Heterogeneity and latent variables are now widely recognized as major sources of bias and variability in high-throughput experiments.
	The most well-known source of latent variation in genomic experiments are batch effects-when samples are processed on different days, in different groups or by different people.
	However, there are also a large number of other variables that may have a major impact on high-throughput measurements.
	Here we describe the sva package for identifying, estimating and removing unwanted sources of variation in high-throughput experiments.
	The sva package supports surrogate variable estimation with the sva function, direct adjustment for known batch effects with the ComBat function and adjustment for batch and latent variables in prediction problems with the fsva function.
	Availability: The R package sva is freely available from http://www .bioconductor.org.
	Contact: jleek@jhsph.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The repetitive nature of plant disease resistance genes encoding for nucleotidebinding leucine-rich repeat (NLR) proteins hampers their prediction with standard gene annotation software.
	Motif alignment and search tool (MAST) has previously been reported as a tool to support annotation of NLR-encoding genes.
	However, the decision if a motif combination represents an NLR protein was entirely manual.
	Results: The NLR-parser pipeline is designed to use the MAST output from six-frame translated amino acid sequences and filters for predefined biologically curated motif compositions.
	Input reads can be derived from, for example, raw long-read sequencing data or contigs and scaffolds coming from plant genome projects.
	The output is a tab-separated file with information on start and frame of the first NLR specific motif, whether the identified sequence is a TNL or CNL, potentially full or fragmented.
	In addition, the output of the NB-ARC domain sequence can directly be used for phylogenetic analyses.
	In comparison to other prediction software, the highly complex NB-ARC domain is described in detail using several individual motifs.
	Availability and implementation: The NLR-parser tool can be downloaded from Git-Hub (github.com/steuernb/NLR-Parser).
	It requires a valid Java installation as well as MAST as part of the MEME Suite.
	The tool is run from the command line.
	Contact: burkhard.steuernagel@jic.ac.uk; fjupe@salk.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Functional Gene Networks (FGNet) is an R/Bioconductor package that generates gene networks derived from the results of functional enrichment analysis (FEA) and annotation clustering.
	The sets of genes enriched with specific biological terms (obtained from a FEA platform) are transformed into a network by establishing links between genes based on common functional annotations and common clusters.
	The network provides a new view of FEA results revealing gene modules with similar functions and genes that are related to multiple functions.
	In addition to building the functional network, FGNet analyses the similarity between the groups of genes and provides a distance heatmap and a bipartite network of functionally overlapping genes.
	The application includes an interface to directly perform FEA queries using different external tools: DAVID, GeneTerm Linker, TopGO or GAGE; and a graphical interface to facilitate the use.
	Availability and implementation: FGNet is available in Bioconductor, including a tutorial.
	URL: http://bioconductor.org/packages/release/bioc/html/FGNet.html Contact: jrivas@usal.es Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Genome-wide mapping of chromatin states is essential for defining regulatory elements and inferring their activities in eukaryotic genomes.
	A number of hidden Markov model (HMM)-based methods have been developed to infer chromatin state maps from genome-wide histone modification data for an individual genome.
	To perform a principled comparison of evolutionarily distant epigenomes, we must consider species-specific biases such as differences in genome size, strength of signal enrichment and co-occurrence patterns of histone modifications.
	Results: Here, we present a new Bayesian non-parametric method called hierarchically linked infinite HMM (hiHMM) to jointly infer chromatin state maps in multiple genomes (different species, cell types and developmental stages) using genome-wide histone modification data.
	This flexible framework provides a new way to learn a consistent definition of chromatin states across multiple genomes, thus facilitating a direct comparison among them.
	We demonstrate the utility of this method using synthetic data as well as multiple modENCODE ChIP-seq datasets.
	Conclusion: The hierarchical and Bayesian non-parametric formulation in our approach is an important extension to the current set of methodologies for comparative chromatin landscape analysis.
	Availability and implementation: Source codes are available at https://github.com/kasohn/hiHMM.Chromatin data are available at http://encode-x.med.harvard.edu/data_sets/chromatin/.Contact: peter_park@harvard.edu or juhan@snu.ac.kr Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Recent advances in high-throughput sequencing (HTS) have made it possible to monitor genomes in great detail.
	New experiments not only use HTS to measure genomic features at one time point but also monitor them changing over time with the aim of identifying significant changes in their abundance.
	In population genetics, for example, allele frequencies are monitored over time to detect significant frequency changes that indicate selection pressures.
	Previous attempts at analyzing data from HTS experiments have been limited as they could not simultaneously include data at intermediate time points, replicate experiments and sources of uncertainty specific to HTS such as sequencing depth.
	Results: We present the beta-binomial Gaussian process model for ranking features with significant non-random variation in abundance over time.
	The features are assumed to represent proportions, such as proportion of an alternative allele in a population.
	We use the beta-binomial model to capture the uncertainty arising from finite sequencing depth and combine it with a Gaussian process model over the time series.
	In simulations that mimic the features of experimental evolution data, the proposed method clearly outperforms classical testing in average precision of finding selected alleles.
	We also present simulations exploring different experimental design choices and results on real data from Drosophila experimental evolution experiment in temperature adaptation.
	Availability and implementation: R software implementing the test is available at https://github.com/handetopa/BBGP.
	Contact: hande.topa@aalto.fi, agnes.jonas@vetmeduni.ac.at, carolin.kosiol@vetmeduni.ac.at, antti.honkela@hiit.fi Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Model selection and parameter inference are complex problems of long-standing interest in systems biology.
	Selecting between competing models arises commonly as underlying biochemical mechanisms are often not fully known, hence alternative models must be considered.
	Parameter inference yields important information on the extent to which the data and the model constrain parameter values.
	Results: We report Dizzy-Beats, a graphical Java Bayesian evidence analysis tool implementing nested sampling - an algorithm yielding an estimate of the log of the Bayesian evidence Z and the moments of model parameters, thus addressing two outstanding challenges in systems modelling.
	A likelihood function based on the L1-norm is adopted as it is generically applicable to replicated time series data.
	Availability and implementation: http://sourceforge.net/p/bayesevidence/home/Home/Contact: s.aitken@ed.ac.uk
	Motivation: We present a novel method and corresponding application, MetAmp, to combine amplicon data from multiple genomic markers into Operational Taxonomic Units (OTUs) for microbial community analysis, calibrating the markers using data from known microbial genomes.
	When amplicons for multiple markers such as the 16S rRNA gene hypervariable regions are available, MetAmp improves the accuracy of OTU-based methods for characterizing bacterial composition and community structure.
	MetAmp works best with at least three markers, and is applicable to non-bacterial analyses and to non 16S markers.
	Our application and testing have been limited to 16S analysis of microbial communities.
	Results: We clustered standard test sequences derived from the Human Microbiome Mock Community test sets and compared MetAmp and other tools with respect to their ability to recover OTUs for these benchmark bacterial communities.
	MetAmp compared favorably to QIIME, UPARSE and Mothur using amplicons from one, two, and three markers.
	Availability and implementation: MetAmp is available at http://izhbannikov.github.io/MetAmp/Contact: ilyaz@uidaho.edu, foster@uidaho.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Interactive modules for Data Exploration and Visualization (imDEV) is a Microsoft Excel spreadsheet embedded application providing an integrated environment for the analysis of omics data through a user-friendly interface.
	Individual modules enables interactive and dynamic analyses of large data by interfacing R's multivariate statistics and highly customizable visualizations with the spreadsheet environment, aiding robust inferences and generating information-rich data visualizations.
	This tool provides access to multiple comparisons with false discovery correction, hierarchical clustering, principal and independent component analyses, partial least squares regression and discriminant analysis, through an intuitive interface for creating high-quality two- and a three-dimensional visualizations including scatter plot matrices, distribution plots, dendrograms, heat maps, biplots, trellis biplots and correlation networks.
	Availability and implementation: Freely available for download at http://sourceforge.net/projects/imdev/.
	Implemented in R and VBA and supported by Microsoft Excel (2003, 2007 and 2010).
	Contact: John.Newman@ars.usda.gov Supplementary Information: Installation instructions, tutorials and users manual are available at http://sourceforge.net/projects/imdev/.
	Summary: The FSelector package contains a comprehensive list of feature selection algorithms for supporting bioinformatics and machine learning research.
	FSelector primarily collects and implements the filter type of feature selection techniques, which are computationally efficient for mining large datasets.
	In particular, FSelector allows ensemble feature selection that takes advantage of multiple feature selection algorithms to yield more robust results.
	FSelector also provides many useful auxiliary tools, including normalization, discretization and missing data imputation.
	Availability: FSelector, written in the Ruby programming language, is free and open-source software that runs on all Ruby supporting platforms, including Windows, Linux and Mac OS X. FSelector is available from https://rubygems.org/gems/fselector and can be installed like a breeze via the command gem install fselector.
	The source code is available (https://github.com/need47/fselector) and is fully documented (http://rubydoc.info/gems/fselector/frames).Contact: ywang@ncbi.nlm.nih.gov or bryant@ncbi.nlm.nih.gov Supplementary Information: Supplementary data are available at Bioinformatics online.
	Summary: DNA methylation is an important mechanism regulating gene transcription, and its role in carcinogenesis has been extensively studied.
	Hyper and hypomethylation of genes is an alternative mechanism to deregulate gene expression in a wide range of diseases.
	At the same time, high-throughput DNA methylation assays have been developed generating vast amounts of genome wide DNA methylation measurements.
	Yet, few tools exist that can formally identify hypo and hypermethylated genes that are predictive of transcription and thus functionally relevant for a particular disease.
	To accommodate this lack of tools, we developed MethylMix, an algorithm implemented in R to identify disease specific hyper and hypomethylated genes.
	MethylMix is based on a beta mixture model to identify methylation states and compares them with the normal DNA methylation state.
	MethylMix introduces a novel metric, the 'Differential Methylation value' or DM-value defined as the difference of a methylation state with the normal methylation state.
	Finally, matched gene expression data are used to identify, besides differential, transcriptionally predictive methylation states by focusing on methylation changes that effect gene expression.
	Availability and implementation: MethylMix was implemented as an R package and is available in bioconductor.
	Contact: olivier.gevaert@stanford.edu
	Summary: The R/Bioconductor package HiTC facilitates the exploration of high-throughput 3C-based data.
	It allows users to import and export 'C' data, to transform, normalize, annotate and visualize interaction maps.
	The package operates within the Bioconductor framework and thus offers new opportunities for future development in this field.
	Availability and implementation: The R package HiTC is available from the Bioconductor website.
	A detailed vignette provides additional documentation and help for using the package.
	Contact: nicolas.servant@curie.fr Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Recent advances in flow cytometry enable simultaneous single-cell measurement of 30Ã¾ surface and intracellular proteins.
	CytoSPADE is a high-performance implementation of an interface for the Spanning-tree Progression Analysis of Density-normalized Events algorithm for tree-based analysis and visualization of this high-dimensional cytometry data.
	Availability: Source code and binaries are freely available at http://cytospade.org and via Bioconductor version 2.10 onwards for Linux, OSX and Windows.
	CytoSPADE is implemented in R, CÃ¾Ã¾ and Java.
	Contact: michael.linderman@mssm.edu Supplementary Information: Additional documentation available at http://cytospade.org.
	Motivation: An accurate genome assembly from short read sequencing data is critical for downstream analysis, for example allowing investigation of variants within a sequenced population.
	However, assembling sequencing data from virus samples, especially RNA viruses, into a genome sequence is challenging due to the combination of viral population diversity and extremely uneven read depth caused by amplification bias in the inevitable reverse transcription and polymerase chain reaction amplification process of current methods.
	Results: We developed a new de novo assembler called IVA (Iterative Virus Assembler) designed specifically for read pairs sequenced at highly variable depth from RNA virus samples.
	We tested IVA on datasets from 140 sequenced samples from human immunodeficiency virus-1 or influenzavirus-infected people and demonstrated that IVA outperforms all other virus de novo assemblers.
	Availability and implementation: The software runs under Linux, has the GPLv3 licence and is freely available from http://sanger-pathogens.github.io/iva Contact: iva@sanger.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Structural variations (SVs) are large genomic rearrangements that vary significantly in size, making them challenging to detect with the relatively short reads from next-generation sequencing (NGS).
	Different SV detection methods have been developed; however, each is limited to specific kinds of SVs with varying accuracy and resolution.
	Previous works have attempted to combine different methods, but they still suffer from poor accuracy particularly for insertions.
	We propose MetaSV, an integrated SV caller which leverages multiple orthogonal SV signals for high accuracy and resolution.
	MetaSV proceeds by merging SVs from multiple tools for all types of SVs.
	It also analyzes soft-clipped reads from alignment to detect insertions accurately since existing tools underestimate insertion SVs.
	Local assembly in combination with dynamic programming is used to improve breakpoint resolution.
	Paired-end and coverage information is used to predict SV genotypes.
	Using simulation and experimental data, we demonstrate the effectiveness of MetaSV across various SV types and sizes.
	Availability and implementation: Code in Python is at http://bioinform.github.io/metasv/.Contact: rd@bina.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Gene blocks are genes co-located on the chromosome.
	In many cases, gene blocks are conserved between bacterial species, sometimes as operons, when genes are co-transcribed.
	The conservation is rarely absolute: gene loss, gain, duplication, block splitting and block fusion are frequently observed.
	An open question in bacterial molecular evolution is that of the formation and breakup of gene blocks, for which several models have been proposed.
	These models, however, are not generally applicable to all types of gene blocks, and consequently cannot be used to broadly compare and study gene block evolution.
	To address this problem, we introduce an eventbased method for tracking gene block evolution in bacteria.
	Results: We show here that the evolution of gene blocks in proteobacteria can be described by a small set of events.
	Those include the insertion of genes into, or the splitting of genes out of a gene block, gene loss, and gene duplication.
	We show how the event-based method of gene block evolution allows us to determine the evolutionary rateand may be used to trace the ancestral states of their formation.
	We conclude that the event-based method can be used to help us understand the formation of these important bacterial genomic structures.
	Availability and implementation: The software is available under GPLv3 license on http://github.com/reamdc1/gene_block_evolution.git.
	Supplementary online material: http://iddo-friedberg.net/operon-evolution Contact: i.friedberg@miamioh.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The high throughput sequencing (HTS) platforms generate unprecedented amounts of data that introduce challenges for the computational infrastructure.
	Data management, storage and analysis have become major logistical obstacles for those adopting the new platforms.
	The requirement for large investment for this purpose almost signalled the end of the Sequence Read Archive hosted at the National Center for Biotechnology Information (NCBI), which holds most of the sequence data generated world wide.
	Currently, most HTS data are compressed through general purpose algorithms such as gzip.
	These algorithms are not designed for compressing data generated by the HTS platforms; for example, they do not take advantage of the specific nature of genomic sequence data, that is, limited alphabet size and high similarity among reads.
	Fast and efficient compression algorithms designed specifically for HTS data should be able to address some of the issues in data management, storage and communication.
	Such algorithms would also help with analysis provided they offer additional capabilities such as random access to any read and indexing for efficient sequence similarity search.
	Here we present SCALCE, a 'boosting' scheme based on Locally Consistent Parsing technique, which reorganizes the reads in a way that results in a higher compression speed and compression rate, independent of the compression algorithm in use and without using a reference genome.
	Results: Our tests indicate that SCALCE can improve the compression rate achieved through gzip by a factor of 4.19-when the goal is to compress the reads alone.
	In fact, on SCALCE reordered reads, gzip running time can improve by a factor of 15.06 on a standard PC with a single core and 6 GB memory.
	Interestingly even the running time of SCALCE Ã¾ gzip improves that of gzip alone by a factor of 2.09.
	When compared with the recently published BEETL, which aims to sort the (inverted) reads in lexicographic order for improving bzip2, SCALCE Ã¾ gzip provides up to 2.01 times better compression while improving the running time by a factor of 5.17.
	SCALCE also provides the option to compress the quality scores as well as the read names, in addition to the reads themselves.
	This is achieved by compressing the quality scores through order-3 Arithmetic Coding (AC) and the read names through gzip through the reordering SCALCE provides on the reads.
	This way, in comparison with gzip compression of the unordered FASTQ files (including reads, read names and quality scores), SCALCE (together with gzip and arithmetic encoding) can provide up to 3.34 improvement in the compression rate and 1.26 improvement in running time.
	Cardinal is an R package for statistical analysis of mass spectrometry-based imaging (MSI) experiments of biological samples such as tissues.
	Cardinal supports both Matrix-Assisted Laser Desorption/Ionization (MALDI) and Desorption Electrospray Ionization-based MSI workflows, and experiments with multiple tissues and complex designs.
	The main analytical functionalities include (1) image segmentation, which partitions a tissue into regions of homogeneous chemical composition, selects the number of segments and the subset of informative ions, and characterizes the associated uncertainty and (2) image classification, which assigns locations on the tissue to predefined classes, selects the subset of informative ions, and estimates the resulting classification error by (cross-) validation.
	The statistical methods are based on mixture modeling and regularization.
	Contact: o.vitek@neu.edu Availability and implementation: The code, the documentation, and examples are available opensource at www.cardinalmsi.org under the Artistic-2.0 license.
	The package is available at www.
	bioconductor.org.
	Summary: The integration between BioDAS ProServer and Automated Sequence Annotation Pipeline (ASAP) provides an interface for querying diverse annotation sources, chaining and linking results, and standardizing the output using the Distributed Annotation System (DAS) protocol.
	This interface allows pipeline plans in ASAP to be integrated into any system using HTTP and also allows the information returned by ASAP to be included in the DAS registry for use in any DAS-aware system.
	Three example implementations have been developed: the first accesses TRANSFAC information to automatically create gene sets for the Coordinated Gene Activity in Pattern Sets (CoGAPS) algorithm; the second integrates annotations from multiple array platforms and provides unified annotations in an R environment; and the third wraps the UniProt database for integration with the SPICE DAS client.
	Availability: Source code for ASAP 2.7 and the DAS 1.6 interface is available under the GNU public license.
	Proserver 2.20 is free software available from SourceForge.
	Scripts for installation and configuration on Linux are provided at our website: http://www.rits.onc.jhmi.edu/dbb/custom/A6/ Contact: Speier@mii.ucla.edu or mfo@jhu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: comb-p is a command-line tool and a python library that manipulates BED files of possibly irregularly spaced P-values and (1) calculates auto-correlation, (2) combines adjacent P-values, (3) performs false discovery adjustment, (4) finds regions of enrichment (i.e.
	series of adjacent low P-values) and (5) assigns significance to those regions.
	In addition, tools are provided for visualization and assessment.
	We provide validation and example uses on bisulfite-seq with P-values from Fisher's exact test, tiled methylation probes using a linear model and Dam-ID for chromatin binding using moderated t-statistics.
	Because the library accepts input in a simple, standardized format and is unaffected by the origin of the P-values, it can be used for a wide variety of applications.
	Availability: comb-p is maintained under the BSD license.
	The docu mentation and implementation are available at https://github.com/brentp/combined-pvalues.
	Contact: bpederse@gmail.com
	Summary: R/EBcoexpress implements the approach of Dawson and Kendziorski using R, a freely available, open source statistical programming language.
	The approach identifies differential coexpression (DC) by examining the correlations among gene pairs using an empirical Bayesian approach, producing a false discovery rate controlled list of DC pairs.
	This interrogation of DC gene pairs complements but is distinct from differential expression analyses, under the general goal of understanding differential regulation across biological conditions.
	Availability and implementation: R/EBcoexpress is freely available and hosted on Bioconductor; a source file and vignette may be found at http://www.bioconductor.org/packages/release/bioc/html/EBcoexpress.html Contact: DrJADawson@hotmail.com or kendzior@wisc.edu
	Motivation: With improvements in next-generation sequencing technologies and reductions in price, ordered RNA-seq experiments are becoming common.
	Of primary interest in these experiments is identifying genes that are changing over time or space, for example, and then characterizing the specific expression changes.
	A number of robust statistical methods are available to identify genes showing differential expression among multiple conditions, but most assume conditions are exchangeable and thereby sacrifice power and precision when applied to ordered data.
	Results: We propose an empirical Bayes mixture modeling approach called EBSeq-HMM.
	In EBSeq-HMM, an auto-regressive hidden Markov model is implemented to accommodate dependence in gene expression across ordered conditions.
	As demonstrated in simulation and case studies, the output proves useful in identifying differentially expressed genes and in specifying gene-specific expression paths.
	EBSeq-HMM may also be used for inference regarding isoform expression.
	Availability and implementation: An R package containing examples and sample datasets is available at Bioconductor.
	Contact: kendzior@biostat.wisc.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Markov networks are undirected graphical models that are widely used to infer relations between genes from experimental data.
	Their state-of-the-art inference procedures assume the data arise from a Gaussian distribution.
	High-throughput omics data, such as that from next generation sequencing, often violates this assumption.
	Furthermore, when collected data arise from multiple related but otherwise nonidentical distributions, their underlying networks are likely to have common features.
	New principled statistical approaches are needed that can deal with different data distributions and jointly consider collections of datasets.
	Results: We present FUSENET, a Markov network formulation that infers networks from a collection of nonidentically distributed datasets.
	Our approach is computationally efficient and general: given any number of distributions from an exponential family, FUSENET represents model parameters through shared latent factors that define neighborhoods of network nodes.
	In a simulation study, we demonstrate good predictive performance of FUSENET in comparison to several popular graphical models.
	We show its effectiveness in an application to breast cancer RNA-sequencing and somatic mutation data, a novel application of graphical models.
	Fusion of datasets offers substantial gains relative to inference of separate networks for each dataset.
	Our results demonstrate that network inference methods for non-Gaussian data can help in accurate modeling of the data generated by emergent high-throughput technologies.
	Availability and implementation: Source code is at https://github.com/marinkaz/fusenet.Contact: blaz.zupan@fri.uni-lj.si Supplementary information: Supplementary information is available at Bioinformatics online.
	Motivation: Systematically predicting gene (or protein) function based on molecular interaction networks has become an important tool in refining and enhancing the existing annotation catalogs, such as the Gene Ontology (GO) database.
	However, functional labels with only a few (<10) annotated genes, which constitute about half of the GO terms in yeast, mouse and human, pose a unique challenge in that any prediction algorithm that independently considers each label faces a paucity of information and thus is prone to capture non-generalizable patterns in the data, resulting in poor predictive performance.
	There exist a variety of algorithms for function prediction, but none properly address this 'overfitting' issue of sparsely annotated functions, or do so in a manner scalable to tens of thousands of functions in the human catalog.
	Results: We propose a novel function prediction algorithm, clusDCA, which transfers information between similar functional labels to alleviate the overfitting problem for sparsely annotated functions.
	Our method is scalable to datasets with a large number of annotations.
	In a cross-validation experiment in yeast, mouse and human, our method greatly outperformed previous state-of-theart function prediction algorithms in predicting sparsely annotated functions, without sacrificing the performance on labels with sufficient information.
	Furthermore, we show that our method can accurately predict genes that will be assigned a functional label that has no known annotations, based only on the ontology graph structure and genes associated with other labels, which further suggests that our method effectively utilizes the similarity between gene functions.
	Availability and implementation: https://github.com/wangshenguiuc/clusDCA.Contact: jianpeng@illinois.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: CYP2D6 is highly polymorphic gene which encodes the (CYP2D6) enzyme, involved in the metabolism of 20-25% of all clinically prescribed drugs and other xenobiotics in the human body.
	CYP2D6 genotyping is recommended prior to treatment decisions involving one or more of the numerous drugs sensitive to CYP2D6 allelic composition.
	In this context, high-throughput sequencing (HTS) technologies provide a promising time-efficient and cost-effective alternative to currently used genotyping techniques.
	To achieve accurate interpretation of HTS data, however, one needs to overcome several obstacles such as high sequence similarity and genetic recombinations between CYP2D6 and evolutionarily related pseudogenes CYP2D7 and CYP2D8, high copy number variation among individuals and short read lengths generated by HTS technologies.
	Results: In this work, we present the first algorithm to computationally infer CYP2D6 genotype at basepair resolution from HTS data.
	Our algorithm is able to resolve complex genotypes, including alleles that are the products of duplication, deletion and fusion events involving CYP2D6 and its evolutionarily related cousin CYP2D7.
	Through extensive experiments using simulated and real datasets, we show that our algorithm accurately solves this important problem with potential clinical implications.
	Availability and implementation: Cypiripi is available at http://sfu-compbio.github.io/cypiripi.Contact: cenk@sfu.ca.
	Summary: The ms-data-core-api is a free, open-source library for developing computational proteomics tools and pipelines.
	The Application Programming Interface, written in Java, enables rapid tool creation by providing a robust, pluggable programming interface and common data model.
	The data model is based on controlled vocabularies/ontologies and captures the whole range of data types included in common proteomics experimental workflows, going from spectra to peptide/protein identifications to quantitative results.
	The library contains readers for three of the most used Proteomics Standards Initiative standard file formats: mzML, mzIdentML, and mzTab.
	In addition to mzML, it also supports other common mass spectra data formats: dta, ms2, mgf, pkl, apl (text-based), mzXML and mzData (XML-based).
	Also, it can be used to read PRIDE XML, the original format used by the PRIDE database, one of the world-leading proteomics resources.
	Finally, we present a set of algorithms and tools whose implementation illustrates the simplicity of developing applications using the library.
	Availability and implementation: The software is freely available at https://github.com/PRIDEUtilities/ms-data-core-api.
	Supplementary information: Supplementary data are available at Bioinformatics online Contact: juan@ebi.ac.uk
	Summary: GWASTools is an R/Bioconductor package for quality control and analysis of genome-wide association studies (GWAS).
	GWASTools brings the interactive capability and extensive statistical libraries of R to GWAS.
	Data are stored in NetCDF format to accommodate extremely large datasets that cannot fit within R's memory limits.
	The documentation includes instructions for converting data from multiple formats, including variants called from sequencing.
	GWASTools provides a convenient interface for linking genotypes and intensity data with sample and single nucleotide polymorphism annotation.
	Availability and implementation: GWASTools is implemented in R and is available from Bioconductor (http://www.bioconductor.org).An extensive vignette detailing a recommended work flow is included.
	Contact: sdmorris@uw.edu
	Motivation: Very large studies are required to provide sufficiently big sample sizes for adequately powered association analyses.
	This can be an expensive undertaking and it is important that an accurate sample size is identified.
	For more realistic sample size calculation and power analysis, the impact of unmeasured aetiological determinants and the quality of measurement of both outcome and explanatory variables should be taken into account.
	Conventional methods to analyse power use closed-form solutions that are not flexible enough to cater for all of these elements easily.
	They often result in a potentially substantial overestimation of the actual power.
	Results: In this article, we describe the Estimating Sample-size and Power in R by Exploring Simulated Study Outcomes tool that allows assessment errors in power calculation under various biomedical scenarios to be incorporated.
	We also report a real world analysis where we used this tool to answer an important strategic question for an existing cohort.
	Availability and implementation: The software is available for online calculation and downloads at http://espresso-research.org.
	The code is freely available at https://github.com/ESPRESSOresearch.
	Contact: louqman@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Galaxy is a software application supporting highthroughput biology analyses and work flows, available as a free on-line service or as source code for local deployment.
	New tools can be written to extend Galaxy, and these can be shared using public Galaxy Tool Shed (GTS) repositories, but converting even simple scripts into tools requires effort from a skilled developer.
	Results: The Tool Factory is a novel Galaxy tool that automates the generation of all code needed to execute user-supplied scripts, and wraps them into new Galaxy tools for upload to a GTS, ready for review and installation through the Galaxy administrative interface.
	Availability and implementation: The Galaxy administrative interface supports automated installation from the main GTS.
	Source code and support are available at the project website, https://bitbucket.org/fubar/galaxytoolfactory.
	The Tool Factory is implemented as an installable Galaxy tool.
	Contact: ross.lazarus@channing.harvard.edu
	Motivation: The comparison of diverse genomic datasets is fundamental to understand genome biology.
	Researchers must explore many large datasets of genome intervals (e.g.
	genes, sequence alignments) to place their experimental results in a broader context and to make new discoveries.
	Relationships between genomic datasets are typically measured by identifying intervals that intersect, that is, they overlap and thus share a common genome interval.
	Given the continued advances in DNA sequencing technologies, efficient methods for measuring statistically significant relationships between many sets of genomic features are crucial for future discovery.
	Results: We introduce the Binary Interval Search (BITS) algorithm, a novel and scalable approach to interval set intersection.
	We demonstrate that BITS outperforms existing methods at counting interval intersections.
	Moreover, we show that BITS is intrinsically suited to parallel computing architectures, such as graphics processing units by illustrating its utility for efficient Monte Carlo simulations measuring the significance of relationships between sets of genomic intervals.
	Availability: https://github.com/arq5x/bits.Contact: arq5x@virginia.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Approaches to identifying new risk loci, training risk prediction models, imputing untyped variants and fine-mapping causal variants from summary statistics of genome-wide association studies are playing an increasingly important role in the human genetics community.
	Current summary statistics-based methods rely on global 'best guess' reference panels to model the genetic correlation structure of the dataset being studied.
	This approach, especially in admixed populations, has the potential to produce misleading results, ignores variation in local structure and is not feasible when appropriate reference panels are missing or small.
	Here, we develop a method, Adapt-Mix, that combines information across all available reference panels to produce estimates of local genetic correlation structure for summary statistics-based methods in arbitrary populations.
	Results: We applied Adapt-Mix to estimate the genetic correlation structure of both admixed and non-admixed individuals using simulated and real data.
	We evaluated our method by measuring the performance of two summary statistics-based methods: imputation and joint-testing.
	When using our method as opposed to the current standard of 'best guess' reference panels, we observed a 28% decrease in mean-squared error for imputation and a 73.7% decrease in meansquared error for joint-testing.
	Availability and implementation: Our method is publicly available in a software package called ADAPT-Mix available at https://github.com/dpark27/adapt_mix.Contact: noah.zaitlen@ucsf.edu
	Summary: Seq2pathway is an R/Python wrapper for pathway (or functional gene-set) analysis of genomic loci, adapted for advances in genome research.
	Seq2pathway associates the biological significance of genomic loci with their target transcripts and then summarizes the quantified values on the gene-level into pathway scores.
	It is designed to isolate systematic disturbances and common biological underpinnings from next-generation sequencing (NGS) data.
	Seq2pathway offers Bioconductor users enhanced capability in discovering collective pathway effects caused by both coding genes and cis-regulation of non-coding elements.
	Availability and implementation: The package is freely available at http://www.bioconductor.org/packages/release/bioc/html/seq2pathway.html.
	Contact: xyang2@uchicago.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We have developed a software package, Cortex, designed for the analysis of genetic variation by de novo assembly of multiple samples.
	This allows direct comparison of samples without using a reference genome as intermediate and incorporates discovery and genotyping of single-nucleotide polymorphisms, indels and larger events in a single framework.
	We introduce pipelines which simplify the analysis of microbial samples and increase discovery power; these also enable the construction of a graph of known sequence and variation in a species, against which new samples can be compared rapidly.
	We demonstrate the ease-of-use and power by reproducing the results of studies using both long and short reads.
	Availability: http://cortexassembler.sourceforge.net (GPLv3 license).Contact: zam@well.ox.ac.uk, mcvean@well.ox.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Copy number abnormalities (CNAs) such as somatically-acquired chromosomal deletions and duplications drive the development of cancer.
	As individual tumor genomes can contain tens or even hundreds of large and/or focal CNAs, a major difficulty is differentiating between important, recurrent pathogenic changes and benign changes unrelated to the subject's phenotype.
	Here we present Copy Number Explorer, an interactive tool for mining large copy number datasets.
	Copy Number Explorer facilitates rapid visual and statistical identification of recurrent regions of gain or loss, identifies the genes most likely to drive CNA formation using the cghMCR method and identifies recurrently broken genes that may be disrupted or fused.
	The software also allows users to identify recurrent CNA regions that may be associated with differential survival.
	Availability and Implementation: Copy Number Explorer is available under the GNU public license (GPL-3).
	Source code is available at: https://sourceforge.net/projects/copynumberexplorer/Contact: scott.newman@emory.edu
	Summary: Systems glycobiology studies the interaction of various pathways that regulate glycan biosynthesis and function.
	Software tools for the construction and analysis of such pathways are not yet available.
	We present GNAT, a platform-independent, user-extensible MATLAB-based toolbox that provides an integrated computational environment to construct, manipulate and simulate glycans and their networks.
	It enables integration of XML-based glycan structure data into SBML (Systems Biology Markup Language) files that describe glycosylation reaction networks.
	Curation and manipulation of networks is facilitated using class definitions and glycomics database query tools.
	High quality visualization of networks and their steady-state and dynamic simulation are also supported.
	Availability: The software package including source code, help documentation and demonstrations are available at http://sourceforge.net/projects/gnatmatlab/files/.
	Contact: neel@buffalo.edu or gangliu@buffalo.edu
	Motivation: Phylogenetic estimates from published studies can be archived using general platforms like Dryad (Vision, 2010) or TreeBASE (Sanderson et al., 1994).
	Such services fulfill a crucial role in ensuring transparency and reproducibility in phylogenetic research.
	However, digital tree data files often require some editing (e.g.
	rerooting) to improve the accuracy and reusability of the phylogenetic statements.
	Furthermore, establishing the mapping between tip labels used in a tree and taxa in a single common taxonomy dramatically improves the ability of other researchers to reuse phylogenetic estimates.
	As the process of curating a published phylogenetic estimate is not error-free, retaining a full record of the provenance of edits to a tree is crucial for openness, allowing editors to receive credit for their work and making errors introduced during curation easier to correct.
	Results: Here, we report the development of software infrastructure to support the open curation of phylogenetic data by the community of biologists.
	The backend of the system provides an interface for the standard database operations of creating, reading, updating and deleting records by making commits to a git repository.
	The record of the history of edits to a tree is preserved by git's version control features.
	Hosting this data store on GitHub (http://github.com/) provides open access to the data store using tools familiar to many developers.
	We have deployed a server running the 'phylesystem-api', which wraps the interactions with git and GitHub.
	The Open Tree of Life project has also developed and deployed a JavaScript application that uses the phylesystem-api and other web services to enable input and curation of published phylogenetic statements.
	Availability and implementation: Source code for the web service layer is available at https://github.com/OpenTreeOfLife/phylesystem-api.
	The data store can be cloned from: https://github.com/OpenTreeOfLife/phylesystem.
	A web application that uses the phylesystem web services is deployed at http://tree.opentreeoflife.org/curator.
	Code for that tool is available from https://github.com/OpenTreeOfLife/opentree.
	Contact: mtholder@gmail.com
	Summary: The execution of a software application or pipeline using various combinations of parameters and inputs is a common task in bioinformatics.
	In the absence of a specialized tool to organize, streamline and formalize this process, scientists must write frequently complex scripts to perform these tasks.
	We present nestly, a Python package to facilitate running tools with nested combinations of parameters and inputs.
	nestly provides three components.
	First, a module to build nested directory structures corresponding to choices of parameters.
	Second, the nestrun script to run a given command using each set of parameter choices.
	Third, the nestagg script to aggregate results of the individual runs into a CSV file, as well as support for more complex aggregation.
	We also include a module for easily specifying nested dependencies for the SCons build tool, enabling incremental builds.
	Availability: Source, documentation and tutorial examples are available at http://github.com/fhcrc/nestly.
	nestly can be installed from the Python Package Index via pip; it is open source (MIT license).
	Contact: cmccoy@fhcrc.org or matsen@fhcrc.org The Author 2012.
	Published by Oxford University Press.
	All rights reserved.
	For Permissions, please email: journals.permissions@oup.com
	COREGNET is an R/Bioconductor package to analyze large-scale transcriptomic data by highlighting sets of co-regulators.
	Based on a transcriptomic dataset, COREGNET can be used to: reconstruct a large-scale co-regulatory network, integrate regulation evidences such as transcription factor binding sites and ChIP data, estimate sample-specific regulator activity, identify cooperative transcription factors and analyze the sample-specific combinations of active regulators through an interactive visualization tool.
	In this study COREGNET was used to identify driver regulators of bladder cancer.
	Availability: COREGNET is available at http://bioconductor.org/packages/CoRegNet Contact: remy.nicolle@issb.genopole.fr or mohamed.elati@issb.genopole.fr Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: The R/Bioconductor package RamiGO is an R interface to AmiGO that enables visualization of Gene Ontology (GO) trees.
	Given a list of GO terms, RamiGO uses the AmiGO visualize API to import Graphviz-DOT format files into R, and export these either as images (SVG, PNG) or into Cytoscape for extended network analyses.
	RamiGO provides easy customization of annotation, highlighting of specific GO terms, colouring of terms by P-value or export of a simplified summary GO tree.
	We illustrate RamiGO functionalities in a genome-wide gene set analysis of prognostic genes in breast cancer.
	Availability and implementation: RamiGO is provided in R/Bioconductor, is open source under the Artistic-2.0 License and is available with a user manual containing installation, operating instructions and tutorials.
	It requires R version 2.15.0 or higher.
	URL: http://bioconduc tor.org/packages/release/bioc/html/RamiGO.html Contact: markus.schroeder@ucdconnect.ie Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The secondary structure of RNA is integral to the variety of functions it carries out in the cell and its depiction allows researchers to develop hypotheses about which nucleotides and base pairs are functionally relevant.
	Current approaches to visualizing secondary structure provide an adequate platform for the conversion of static text-based representations to 2D images, but are limited in their offer of interactivity as well as their ability to display larger structures, multiple structures and pseudoknotted structures.
	Results: In this article, we present forna, a web-based tool for displaying RNA secondary structure which allows users to easily convert sequences and secondary structures to clean, concise and customizable visualizations.
	It supports, among other features, the simultaneous visualization of multiple structures, the display of pseudoknotted structures, the interactive editing of the displayed structures, and the automatic generation of secondary structure diagrams from PDB files.
	It requires no software installation apart from a modern web browser.
	Availability and implementation: The web interface of forna is available at http://rna.tbi.univie.ac.at/forna while the source code is available on github at www.github.com/pkerpedjiev/forna.
	Contact: pkerp@tbi.univie.ac.at Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We present DisVis, a Python package and command line tool to calculate the reduced accessible interaction space of distance-restrained binary protein complexes, allowing for direct visualization and quantification of the information content of the distance restraints.
	The approach is general and can also be used as a knowledge-based distance energy term in FFT-based docking directly during the sampling stage.
	Availability and implementation: The source code with documentation is freely available from https://github.com/haddocking/disvis.Contact: a.m.j.j.bonvin@uu.nl Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Next-generation sequencing is producing vast amounts of sequence information from natural and engineered ecosystems.
	Although this data deluge has an enormous potential to transform our lives, knowledge creation and translation need software applications that scale with increasing data processing and analysis requirements.
	Here, we present improvements to MetaPathways, an annotation and analysis pipeline for environmental sequence information that expedites this transformation.
	We specifically address pathway prediction hazards through integration of a weighted taxonomic distance and enable quantitative comparison of assembled annotations through a normalized read-mapping measure.
	Additionally, we improve LAST homology searches through BLAST-equivalent E-values and output formats that are natively compatible with prevailing software applications.
	Finally, an updated graphical user interface allows for keyword annotation query and projection onto user-defined functional gene hierarchies, including the Carbohydrate-Active Enzyme database.
	Availability and implementation: MetaPathways v2.5 is available on GitHub: http://github.com/hallamlab/metapathways2.
	Contact: shallam@mail.ubc.ca Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Multiply correlated datasets have become increasingly common in genome-wide location analysis of regulatory proteins and epigenetic modifications.
	Their correlation can be directly incorporated into a statistical model to capture underlying biological interactions, but such modeling quickly becomes computationally intractable.
	Results: We present sparsely correlated hidden Markov models (scHMM), a novel method for performing simultaneous hidden Markov model (HMM) inference for multiple genomic datasets.
	In scHMM, a single HMM is assumed for each series, but the transition probability in each series depends on not only its own hidden states but also the hidden states of other related series.
	For each series, scHMM uses penalized regression to select a subset of the other data series and estimate their effects on the odds of each transition in the given series.
	Following this, hidden states are inferred using a standard forward-backward algorithm, with the transition probabilities adjusted by the model at each position, which helps retain the order of computation close to fitting independent HMMs (iHMM).
	Hence, scHMM is a collection of inter-dependent non-homogeneous HMMs, capable of giving a close approximation to a fully multivariate HMM fit.
	A simulation study shows that scHMM achieves comparable sensitivity to the multivariate HMM fit at a much lower computational cost.
	The method was demonstrated in the joint analysis of 39 histone modifications, CTCF and RNA polymerase II in human CD4Ã¾ T cells.
	scHMM reported fewer high-confidence regions than iHMM in this dataset, but scHMM could recover previously characterized histone modifications in relevant genomic regions better than iHMM.
	In addition, the resulting combinatorial patterns from scHMM could be better mapped to the 51 states reported by the multivariate HMM method of Ernst and Kellis.
	Availability: The scHMM package can be freely downloaded from http://sourceforge.net/p/schmm/ and is recommended for use in a linux environment.
	Contact: ghoshd@psu.edu or zhaohui.qin@emory.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Cell differentiation processes are achieved through a continuum of hierarchical intermediate cell states that might be captured by single-cell RNA seq.
	Existing computational approaches for the assessment of cell-state hierarchies from single-cell data can be formalized under a general framework composed of (i) a metric to assess cell-to-cell similarities (with or without a dimensionality reduction step) and (ii) a graph-building algorithm (optionally making use of a cell clustering step).
	The Sincell R package implements a methodological toolbox allowing flexible workflows under such a framework.
	Furthermore, Sincell contributes new algorithms to provide cell-state hierarchies with statistical support while accounting for stochastic factors in single-cell RNA seq.
	Graphical representations and functional association tests are provided to interpret hierarchies.
	The functionalities of Sincell are illustrated in a real case study, which demonstrates its ability to discriminate noisy from stable cell-state hierarchies.
	Availability and implementation: Sincell is an open-source R/Bioconductor package available at http://bioconductor.org/packages/sincell.
	A detailed manual and a vignette are provided with the package.
	Contact: antonio.rausell@isb-sib.ch Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: A simple static image of genomes and associated metadata is very limiting, as researchers expect rich, interactive tools similar to the web applications found in the post-Web 2.0 world.
	GenomeD3Plot is a light weight visualization library written in javascript using the D3 library.
	GenomeD3Plot provides a rich API to allow the rapid visualization of complex genomic data using a convenient standards based JSON configuration file.
	When integrated into existing web services GenomeD3Plot allows researchers to interact with data, dynamically alter the view, or even resize or reposition the visualization in their browser window.
	In addition GenomeD3Plot has built in functionality to export any resulting genome visualization in PNG or SVG format for easy inclusion in manuscripts or presentations.
	Results: GenomeD3Plot is being utilized in the recently released Islandviewer 3 (www.pathogenomics.sfu.ca/islandviewer/) to visualize predicted genomic islands with other genome annotation data.
	However, its features enable it to be more widely applicable for dynamic visualization of genomic data in general.
	Availability and implementation: GenomeD3Plot is licensed under the GNU-GPL v3 at https://github.com/brinkmanlab/GenomeD3Plot/.
	Contact: brinkman@sfu.ca
	Summary: A significant proportion of eukaryote genomes consist of transposable element (TE)-derived sequence.
	These elements are known to have the capacity to modulate gene function and genome evolution.
	We have developed RetroSeq for detecting non-reference TE insertions from Illumina paired-end whole-genome sequencing data.
	We evaluate RetroSeq on a human trio from the 1000 Genomes Project, showing that it produces highly accurate TE calls.
	Availabilty: RetroSeq is open-source and available from https://github.com/tk2/RetroSeq.
	Contact: tk2@sanger.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Functional annotation represents a key step toward the understanding and interpretation of germline and somatic variation as revealed by genome-wide association studies (GWAS) and The Cancer Genome Atlas (TCGA), respectively.
	GWAS have revealed numerous genetic risk variants residing in non-coding DNA associated with complex diseases.
	For sequences that lie within enhancers or promoters of transcription, it is not straightforward to assess the effects of variants on likely transcription factor binding sites.
	Consequently we introduce motifbreakR, which allows the biologist to judge whether the sequence surrounding a polymorphism or mutation is a good match, and how much information is gained or lost in one allele of the polymorphism or mutation relative to the other.
	MotifbreakR is flexible, giving a choice of algorithms for interrogation of genomes with motifs from many public sources that users can choose from.
	MotifbreakR can predict effects for novel or previously described variants in public databases, making it suitable for tasks beyond the scope of its original design.
	Lastly, it can be used to interrogate any genome curated within bioconductor.
	Availability and implementation: https://github.com/Simon-Coetzee/MotifBreakR, www.bioconductor.org.
	Contact: dennis.hazelett@cshs.org
	Summary: High-throughput sequencing technologies survey genetic variation at genome scale and are increasingly used to study the contribution of rare and low-frequency genetic variants to human traits.
	As part of the Cohorts arm of the UK10K project, genetic variants called from lowread depth (average 7 ) whole genome sequencing of 3621 cohort individuals were analysed for statistical associations with 64 different phenotypic traits of biomedical importance.
	Here, we describe a novel genome browser based on the Biodalliance platform developed to provide interactive access to the association results of the project.
	Availability and implementation: The browser is available at http://www.uk10k.org/dalliance.html.Source code for the Biodalliance platform is available under a BSD license from http://github.com/dasmoth/dalliance, and for the LD-display plugin and backend from http://github.com/dasmoth/ldserv.
	Contact: ns6@sanger.ac.uk or thomas@biodalliance.org Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: DamID is a powerful technique for identifying regions of the genome bound by a DNAbinding (or DNA-associated) protein.
	Currently, no method exists for automatically processing next-generation sequencing DamID (DamID-seq) data, and the use of DamID-seq datasets with normalization based on read-counts alone can lead to high background and the loss of bound signal.
	DamID-seq thus presents novel challenges in terms of normalization and background minimization.
	We describe here damidseq_pipeline, a software pipeline that performs automatic normalization and background reduction on multiple DamID-seq FASTQ datasets.
	Availability and implementation: Open-source and freely available from http://owenjm.github.io/damidseq_pipeline.
	The damidseq_pipeline is implemented in Perl and is compatible with any Unix-based operating system (e.g.
	Linux, Mac OSX).
	Contact: o.marshall@gurdon.cam.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Robust conversion between microarray platforms is needed to leverage the wide variety of microarray expression studies that have been conducted to date.
	Currently available conversion methods rely on manufacturer annotations, which are often incomplete, or on direct alignment of probes from different platforms, which often fail to yield acceptable genewise correlation.
	Here, we describe aRrayLasso, which uses the Lasso-penalized generalized linear model to model the relationships between individual probes in different probe sets.
	We have implemented aRrayLasso in a set of five open-source R functions that allow the user to acquire data from public sources such as Gene Expression Omnibus, train a set of Lasso models on that data and directly map one microarray platform to another.
	aRrayLasso significantly predicts expression levels with similar fidelity to technical replicates of the same RNA pool, demonstrating its utility in the integration of datasets from different platforms.
	Availability and implementation: All functions are available, along with descriptions, at https://github.com/adam-sam-brown/aRrayLasso.
	Contact: chirag_patel@hms.harvard.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We developed cyNeo4j, a Cytoscape App to link Cytoscape and Neo4j databases to utilize the performance and storage capacities Neo4j offers.
	We implemented a Neo4j NetworkAnalyzer, ForceAtlas2 layout and Cypher component to demonstrate the possibilities a distributed setup of Cytoscape and Neo4j have.
	Availability and implementation: The app is available from the Cytoscape App Store at http://apps.cytoscape.org/apps/cyneo4j, the Neo4j plugins at www.github.com/gsummer/cyneo4j-parent and the community and commercial editions of Neo4j can be found at http://www.neo4j.com.Contact: georg.summer@gmail.com
	Summary: Sodium bisulfite conversion followed by sequencing (BS-Seq, such as whole genome bisulfite sequencing or reduced representation bisulfite sequencing) has become popular for studying human epigenetic profiles.
	Identifying single nucleotide polymorphisms (SNPs) is important for quantification of methylation levels and for study of allele-specific epigenetic events such as imprinting.
	However, SNP calling in such data is complex and time consuming.
	Here, we present an ultrafast and memory-efficient package named BS-SNPer for the exploration of SNP sites from BS-Seq data.
	Compared with Bis-SNP, a popular BS-Seq specific SNP caller, BS-SNPer is over 100 times faster and uses less memory.
	BS-SNPer also offers higher sensitivity and specificity compared with existing methods.
	Availability and implementation: BS-SNPer is written in CÃ¾Ã¾ and Perl, and is freely available at https://github.com/hellbelly/BS-Snper.Contact: bolund@biomed.au.dk, kdso@clin.au.dk or orntoft@ki.au.dk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: High-throughput genotyping and sequencing technologies facilitate studies of complex genetic traits and provide new research opportunities.
	The increasing popularity of genome-wide association studies (GWAS) leads to the discovery of new associated loci and a better understanding of the genetic architecture underlying not only diseases, but also other monogenic and complex phenotypes.
	Several softwares are available for performing GWAS analyses, R environment being one of them.
	Results: We present cgmisc, an R package that enables enhanced data analysis and visualization of results from GWAS.
	The package contains several utilities and modules that complement and enhance the functionality of the existing software.
	It also provides several tools for advanced visualization of genomic data and utilizes the power of the R language to aid in preparation of publication-quality figures.
	Some of the package functions are specific for the domestic dog (Canis familiaris) data.
	Availability and implementation: The package is operating system-independent and is available from: https://github.com/cgmisc-team/cgmisc Contact: marcin.kierczak@imbim.uu.se Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Although de novo assembly graphs contain assembled contigs (nodes), the connections between those contigs (edges) are difficult for users to access.
	Bandage (a Bioinformatics Application for Navigating De novo Assembly Graphs Easily) is a tool for visualizing assembly graphs with connections.
	Users can zoom in to specific areas of the graph and interact with it by moving nodes, adding labels, changing colors and extracting sequences.
	BLAST searches can be performed within the Bandage graphical user interface and the hits are displayed as highlights in the graph.
	By displaying connections between contigs, Bandage presents new possibilities for analyzing de novo assemblies that are not possible through investigation of contigs alone.
	Availability and implementation: Source code and binaries are freely available at https://github.com/rrwick/Bandage.
	Bandage is implemented in CÃ¾Ã¾ and supported on Linux, OS X and Windows.
	A full feature list and screenshots are available at http://rrwick.github.io/Bandage.Contact: rrwick@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Gene fusions are being discovered at an increasing rate using massively parallel sequencing technologies.
	Prioritization of cancer fusion drivers for validation cannot be performed using traditional single-gene based methods because fusions involve portions of two partner genes.
	To address this problem, we propose a novel network analysis method called fusion centrality that is specifically tailored for prioritizing gene fusions.
	We first propose a domain-based fusion model built on the theory of exon/domain shuffling.
	The model leads to a hypothesis that a fusion is more likely to be an oncogenic driver if its partner genes act like hubs in a network because the fusion mutation can deregulate normal functions of many other genes and their pathways.
	The hypothesis is supported by the observation that for most known cancer fusion genes, at least one of the fusion partners appears to be a hub in a network, and even for many fusions both partners appear to be hubs.
	Based on this model, we construct fusion centrality, a multi-gene-based network metric, and use it to score fusion drivers.
	We show that the fusion centrality outperforms other single gene-based methods.
	Specifically, the method successfully predicts most of 38 newly discovered fusions that had validated oncogenic importance.
	To our best knowledge, this is the first networkbased approach for identifying fusion drivers.
	Availability: Matlab code implementing the fusion centrality method is available upon request from the corresponding authors.
	Contact: perwu777@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Chemical mapping experiments allow for nucleotide resolution assessment of RNA structure.
	We demonstrate that different strategies of integrating probing data with thermodynamics-based RNA secondary structure prediction algorithms can be implemented by means of soft constraints.
	This amounts to incorporating suitable pseudo-energies into the standard energy model for RNA secondary structures.
	As a showcase application for this new feature of the ViennaRNA Package we compare three distinct, previously published strategies to utilize SHAPE reactivities for structure prediction.
	The new tool is benchmarked on a set of RNAs with known reference structure.
	Availability and implementation: The capability for SHAPE directed RNA folding is part of the upcoming release of the ViennaRNA Package 2.2, for which a preliminary release is already freely available at http://www.tbi.univie.ac.at/RNA.Contact: michael.wolfinger@univie.ac.at Supplementary information: Supplementary data are available at Bioinformatics online.
	We describe MUSCLE, a new computer program for creating multiple alignments of protein sequences.
	Elements of the algorithm include fast distance estimation using kmer counting, progressive alignment using a new proÂ®le function we call the logexpectation score, and reÂ®nement using treedependent restricted partitioning.
	The speed and accuracy of MUSCLE are compared with T-Coffee, MAFFT and CLUSTALW on four test sets of reference alignments: BAliBASE, SABmark, SMART and a new benchmark, PREFAB.
	MUSCLE achieves the highest, or joint highest, rank in accuracy on each of these sets.
	Without reÂ®nement, MUSCLE achieves average accuracy statistically indistinguishable from T-Coffee and MAFFT, and is the fastest of the tested methods for large numbers of sequences, aligning 5000 sequences of average length 350 in 7 min on a current desktop computer.
	The MUSCLE program, source code and PREFAB test data are freely available at http://www.drive5.com/muscle.
	Motivation: Pairing between the target sequence and the 6-8 nt long seed sequence of the miRNA presents the most important feature for miRNA target site prediction.
	Novel high-throughput technologies such as Argonaute HITS-CLIP afford meanwhile a detailed study of miRNA:mRNA duplices.
	These interaction maps enable a first discrimination between functional and non-functional target sites in a bulky fashion.
	Prediction algorithms apply different seed paradigms to identify miRNA target sites.
	Therefore, a quantitative assessment of miRNA target site prediction is of major interest.
	Results: We identified a set of canonical seed types based on a transcriptome wide analysis of experimentally verified functional target sites.
	We confirmed the specificity of long seeds but we found that the majority of functional target sites are formed by less specific seeds of only 6 nt indicating a crucial role of this type.
	A substantial fraction of genuine target sites are non-conserved.
	Moreover, the majority of functional sites remain uncovered by common prediction methods.
	Contact: florian.buettner@helmholtz-muenchen.de; v.stuempflen@helmholtz-muenchen.de Supplementary Information: Supplementary data are available at Bioinformatics online.
	Motivation: The ability to accurately measure structural similarities among small molecules is important for many analysis routines in drug discovery and chemical genomics.
	Algorithms used for this purpose include fragment-based fingerprint and graph-based maximum common substructure (MCS) methods.
	MCS approaches provide one of the most accurate similarity measures.
	However, their rigid matching policies limit them to the identification of perfect MCSs.
	To eliminate this restriction, we introduce a new mismatch tolerant search method for identifying flexible MCSs (FMCSs) containing a user-definable number of atom and/or bond mismatches.
	Results: The fmcsR package provides an R interface, with the timeconsuming steps of the FMCS algorithm implemented in CÃ¾Ã¾.
	It includes utilities for pairwise compound comparisons, structure similarity searching, clustering and visualization of MCSs.
	In comparison with an existing MCS tool, fmcsR shows better time performance over a wide range of compound sizes.
	When mismatching of atoms or bonds is turned on, the compute times increase as expected, and the resulting FMCSs are often substantially larger than their strict MCS counterparts.
	Based on extensive virtual screening (VS) tests, the flexible matching feature enhances the enrichment of active structures at the top of MCS-based similarity search results.
	With respect to overall and early enrichment performance, FMCS outperforms most of the seven other VS methods considered in these tests.
	Availability: fmcsR is freely available for all common operating systems from the Bioconductor site (http://www.bioconductor.org/packages/devel/bioc/html/fmcsR.html).
	Contact: thomas.girke@ucr.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	The analysis of concentrations of circulating antibodies in serum (antibody repertoire) is a fundamental, yet poorly studied, problem in immunoinformatics.
	The two current approaches to the analysis of antibody repertoires [next generation sequencing (NGS) and mass spectrometry (MS)] present difficult computational challenges since antibodies are not directly encoded in the germline but are extensively diversified by somatic recombination and hypermutations.
	Therefore, the protein database required for the interpretation of spectra from circulating antibodies is custom for each individual.
	Although such a database can be constructed via NGS, the reads generated by NGS are error-prone and even a single nucleotide error precludes identification of a peptide by the standard proteomics tools.
	Here, we present the IGREPERTOIRECONSTRUCTOR algorithm that performs error-correction of immunosequencing reads and uses mass spectra to validate the constructed antibody repertoires.
	Availability and implementation: IGREPERTOIRECONSTRUCTOR is open source and freely available as a CÃ¾Ã¾ and Python program running on all Unix-compatible platforms.
	The source code is available from http://bioinf.spbau.ru/igtools.Contact: ppevzner@ucsd.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: In the systems biology era, high-throughput omics technologies have enabled the unraveling of the interplay of some biological entities on a large scale (e.g.
	genes, proteins, metabolites or RNAs).
	Huge biological networks have emerged, where nodes correspond to these entities and edges between them model their relations.
	Protein-protein interaction networks, for instance, show the physical interactions of proteins in an organism.
	The comparison of such networks promises additional insights into protein and cell function as well as knowledge-transfer across species.
	Several computational approaches have been developed previously to solve the network alignment (NA) problem, but only a few concentrate on the usability of the implemented tools for the evaluation of protein-protein interactions by the end users (biologists and medical researchers).
	Results: We have created CytoGEDEVO, a Cytoscape app for visual and user-assisted NA.
	It extends the previous GEDEVO methodology for global pairwise NAs with new graphical and functional features.
	Our main focus was on the usability, even by non-programmers and the interpretability of the NA results with Cytoscape.
	Availability and implementation: CytoGEDEVO is publicly available from the Cytoscape app store at http://apps.cytoscape.org/apps/cytogedevo.
	In addition, we provide stand-alone command line executables, source code, documentation and step-by-step user instructions at http://cytogedevo.compbio.sdu.dk.
	Contact: malek@tugraz.at Supplementary information: Supplementary data are available at Bioinformatics online.
	Since 2004 the European Bioinformatics Institute (EMBL-EBI) has provided access to a wide range of databases and analysis tools via Web Services interfaces.
	This comprises services to search across the databases available from the EMBL-EBI and to explore the network of cross-references present in the data (e.g.
	EB-eye), services to retrieve entry data in various data formats and to access the data in specific fields (e.g.
	dbfetch), and analysis tool services, for example, sequence similarity search (e.g.
	FASTA and NCBI BLAST), multiple sequence alignment (e.g.
	Clustal Omega and MUSCLE), pairwise sequence alignment and protein functional analysis (e.g.
	InterProScan and Phobius).
	The REST/SOAP Web Services (http://www.ebi.ac.uk/Tools/webservices/) interfaces to these databases and tools allow their integration into other tools, applications, web sites, pipeline processes and analytical workflows.
	To get users started using the Web Services, sample clients are provided covering a range of programming languages and popular Web Service tool kits, and a brief guide to Web Services technologies, including a set of tutorials, is available for those wishing to learn more and develop their own clients.
	Users of the Web Services are informed of improvements and updates via a range of methods.
	Summary: DaliLite is a program for pairwise structure comparison and for structure database searching.
	It is a standalone version of the search engine of the popular Dali server.
	A web interface is provided to view the results, multiple alignments and 3D superimpositions of structures.
	Availability: DaliLite has been ported to the Linux and Irix operating systems and can be compiled in many other UNIX operating systems.
	It is found at http:// www.embl-ebi.ac.uk/ dali/ DaliLite.
	Contact: holm@embl-ebi.ac.uk
	Motivation: Biological system behaviors are often the outcome of complex interactions among a large number of cells and their biotic and abiotic environment.
	Computational biologists attempt to understand, predict and manipulate biological system behavior through mathematical modeling and computer simulation.
	Discrete agentbased modeling (in combination with high-resolution grids to model the extracellular environment) is a popular approach for building biological system models.
	However, the computational complexity of this approach forces computational biologists to resort to coarser resolution approaches to simulate large biological systems.
	Highperformance parallel computers have the potential to address the computing challenge, but writing efficient software for parallel computers is difficult and time-consuming.
	Results: We have developed Biocellion, a high-performance software framework, to solve this computing challenge using parallel computers.
	To support a wide range of multicellular biological system models, Biocellion asks users to provide their model specifics by filling the function body of pre-defined model routines.
	Using Biocellion, modelers without parallel computing expertise can efficiently exploit parallel computers with less effort than writing sequential programs from scratch.
	We simulate cell sorting, microbial patterning and a bacterial system in soil aggregate as case studies.
	Availability and implementation: Biocellion runs on x86 compatible systems with the 64 bit Linux operating system and is freely available for academic use.
	Visit http://biocellion.com for additional information.Contact: seunghwa.kang@pnnl.gov
	Summary: DivBayes is a program to estimate diversification rates from species richness and ages of a set of clades.
	SubT estimates diversification rates from node heights within a clade.
	Both programs implement Bayesian statistics and provide the ability to account for uncertainty in the ages of taxa in the underlying data, an improvement over more commonly used maximum likelihood methods.
	Availability: DivBayes and SubT are released as C++ source code under the GNU GPL v. 3 software license in Supplementary information 1 and 2, respectively, and at http://web.utk.edu/~kryberg/.
	They have been successfully compiled on various Linux, MacOS X and Windows systems.
	Contact: kryberg@utk.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Rapid advances of next-generation sequencing technology have led to the integration of genetic information with clinical care.
	Genetic basis of diseases and response to drugs provide new ways of disease diagnosis and safer drug usage.
	This integration reveals the urgent need for effective and accurate tools to analyze genetic variants.
	Due to the number and diversity of sources for annotation, automating variant analysis is a challenging task.
	Here, we present database.bio, a web application that combines variant annotation, prioritization and visualization so as to support insight into the individual genetic characteristics.
	It enhances annotation speed by preprocessing data on a supercomputer, and reduces database space via a unified database representation with compressed fields.
	Availability and implementation: Freely available at https://database.bio Contact: rb@l3-bioinfo.com or twlam@cs.hku.hk Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Protein-protein interactions are central to almost all biological functions, and the atomic details of such interactions can yield insights into the mechanisms that underlie these functions.
	We present a web server that wraps and extends the SwarmDock flexible proteinprotein docking algorithm.
	After uploading PDB files of the binding partners, the server generates low energy conformations and returns a ranked list of clustered docking poses and their corresponding structures.
	The user can perform full global docking, or focus on particular residues that are implicated in binding.
	The server is validated in the CAPRI blind docking experiment, against the most current docking benchmark, and against the ClusPro docking server, the highest performing server currently available.
	Availability: The server is freely available and can be accessed at: http://bmm.cancerresearchuk.org/%7ESwarmDock/.Contact: Paul.Bates@cancer.org.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Metabolite databases provide a unique window into metabolome research allowing the most commonly searched biomarkers to be catalogued.
	Omic scale metabolite profiling, or metabolomics, is finding increased utility in biomarker discovery largely driven by improvements in analytical technologies and the concurrent developments in bioinformatics.
	However, the successful translation of biomarkers into clinical or biologically relevant indicators is limited.
	Results: With the aim of improving the discovery of translatable metabolite biomarkers, we present search analytics for over one million METLIN metabolite database queries.
	The most common metabolites found in METLIN were cross-correlated against XCMS Online, the widely used cloudbased data processing and pathway analysis platform.
	Analysis of the METLIN and XCMS common metabolite data has two primary implications: these metabolites, might indicate a conserved metabolic response to stressors and, this data may be used to gauge the relative uniqueness of potential biomarkers.
	Availability and implementation.
	METLIN can be accessed by logging on to: https://metlin.scripps.edu Contact: siuzdak@scripps.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Fig.
	1.
	The growth of supervised machine learning methods in PubMed.
	Fig.
	2.
	Heatmap showing the co-occurrence of machine learning techniques within articles.
	Motivation: Tumorigenesis is an evolutionary process by which tumor cells acquire sequences of mutations leading to increased growth, invasiveness and eventually metastasis.
	It is hoped that by identifying the common patterns of mutations underlying major cancer sub-types, we can better understand the molecular basis of tumor development and identify new diagnostics and therapeutic targets.
	This goal has motivated several attempts to apply evolutionary tree reconstruction methods to assays of tumor state.
	Inference of tumor evolution is in principle aided by the fact that tumors are heterogeneous, retaining remnant populations of different stages along their development along with contaminating healthy cell populations.
	In practice, though, this heterogeneity complicates interpretation of tumor data because distinct cell types are conflated by common methods for assaying the tumor state.
	We previously proposed a method to computationally infer cell populations from measures of tumor-wide gene expression through a geometric interpretation of mixture type separation, but this approach deals poorly with noisy and outlier data.
	Results: In the present work, we propose a new method to perform tumor mixture separation efficiently and robustly to an experimental error.
	The method builds on the prior geometric approach but uses a novel objective function allowing for robust fits that greatly reduces the sensitivity to noise and outliers.
	We further develop an efficient gradient optimization method to optimize this 'soft geometric unmixing' objective for measurements of tumor DNA copy numbers assessed by array comparative genomic hybridization (aCGH) data.
	We show, on a combination of semi-synthetic and real data, that the method yields fast and accurate separation of tumor states.
	Conclusions: We have shown a novel objective function and optimization method for the robust separation of tumor sub-types from aCGH data and have shown that the method provides fast, accurate reconstruction of tumor states from mixed samples.
	Better solutions to this problem can be expected to improve our ability to accurately identify genetic abnormalities in primary tumor samples and to infer patterns of tumor evolution.
	Contact: tolliver@cs.cmu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: MicroRNA (miRNA) expression has been found to be deregulated in human cancer, contributing, in part, to the interest of the research community in using miRNAs as alternative therapeutic targets.
	Although miRNAs could be potential targets, identifying which miRNAs to target for a particular type of cancer has been difficult due to the limited knowledge on their regulatory roles in cancer.
	We address this challenge by integrating miRNA-target prediction, metabolic modeling and context-specific gene expression data to predict therapeutic miRNAs that could reduce the growth of cancer.
	Results: We developed a novel approach to simulate a conditionspecific metabolic system for human hepatocellular carcinoma (HCC) wherein overexpression of each miRNA was simulated to predict their ability to reduce cancer cell growth.
	Our approach achieved 480% accuracy in predicting the miRNAs that could suppress metastasis and progression of liver cancer based on various experimental evidences in the literature.
	This condition-specific metabolic system provides a framework to explore the mechanisms by which miRNAs modulate metabolic functions to affect cancer growth.
	To the best of our knowledge, this is the first computational approach implemented to predict therapeutic miRNAs for human cancer based on their functional role in cancer metabolism.
	Analyzing the metabolic functions altered by the miRNA-identified metabolic genes essential for cell growth and proliferation that are targeted by the miRNAs.
	Availability and implementation: See supplementary protocols and http://www.egr.msu.edu/changroup/Protocols%20Index.html.Contact: krischan@egr.msu.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Mobile technologies provide unique opportunities for ubiquitous distribution of scientific information through user-friendly interfaces.
	Therefore, we have developed a new FlyExpress mobile application that makes available a growing collection (4100 000) of standardized in situ hybridization images containing spatial patterns of gene expression from Drosophila melanogaster (fruit fly) embryogenesis.
	Using this application, scientists can visualize and compare expression patterns of 44000 developmentally relevant genes.
	The FlyExpress app displays the expression patterns of the selected gene for different visual projections (e.g.
	lateral) and displays them according to their developmental stages, which shows a gene's progression of spatial expression over developmental time.
	Ultimately, we envision the use of FlyExpress app in the laboratory where scientists may wish to immediately conduct a visual comparison of a known expression pattern with the one observed on the bench top or to display expression patterns of interest during scientific discussions at large.
	Availability: Search ''FlyExpress'' on the Apple iTunes store Contact: s.kumar@asu.edu
	Motivation: Considerable attention has been focused on predicting RNA-RNA interaction since it is a key to identifying possible targets of non-coding small RNAs that regulate gene expression posttranscriptionally.
	A number of computational studies have so far been devoted to predicting joint secondary structures or binding sites under a specific class of interactions.
	In general, there is a tradeoff between range of interaction type and efficiency of a prediction algorithm, and thus efficient computational methods for predicting comprehensive type of interaction are still awaited.
	Results: We present RactIP, a fast and accurate prediction method for RNA-RNA interaction of general type using integer programming.
	RactIP can integrate approximate information on an ensemble of equilibrium joint structures into the objective function of integer programming using posterior internal and external base-paring probabilities.
	Experimental results on real interaction data show that prediction accuracy of RactIP is at least comparable to that of several state-of-the-art methods for RNA-RNA interaction prediction.
	Moreover, we demonstrate that RactIP can run incomparably faster than competitive methods for predicting joint secondary structures.
	Availability: RactIP is implemented in C++, and the source code is available at http://www.ncrna.org/software/ractip/Contact: ykato@kuicr.kyoto-u.ac.jp; satoken@k.u-tokyo.ac.jp Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: MASS is a command-line program to perform meta-analysis of sequencing studies by combining the score statistics from multiple studies.
	It implements three types of multivariate tests that encompass all commonly used association tests for rare variants.
	The input files can be generated from the accompanying software SCORESeq.
	This bundle of programs allows analysis of large sequencing studies in a time and memory efficient manner.
	Availability and implementation: MASS and SCORE-Seq, including documentations and executables, are available at http://dlin.web.unc.edu/software/.
	Contact: lin@bios.unc.edu
	Motivation: Recognition of poly(A) signals in mRNA is relatively straightforward due to the presence of easily recognizable polyadenylic acid tail.
	However, the task of identifying poly(A) motifs in the primary genomic DNA sequence that correspond to poly(A) signals in mRNA is a far more challenging problem.
	Recognition of poly(A) signals is important for better gene annotation and understanding of the gene regulation mechanisms.
	In this work, we present one such poly(A) motif prediction method based on properties of human genomic DNA sequence surrounding a poly(A) motif.
	These properties include thermodynamic, physico-chemical and statistical characteristics.
	For predictions, we developed Artificial Neural Network and Random Forest models.
	These models are trained to recognize 12 most common poly(A) motifs in human DNA.
	Our predictors are available as a free web-based tool accessible at http://cbrc.kaust.edu.sa/dps.
	Compared with other reported predictors, our models achieve higher sensitivity and specificity and furthermore provide a consistent level of accuracy for 12 poly(A) motif variants.
	Contact: vladimir.bajic@kaust.edu.sa Supplementary information: Supplementary data are available at Bioinformatics online.
	Understanding the complex mechanisms regulating gene expression at the transcriptional and posttranscriptional levels is one of the greatest challenges of the post-genomic era.
	The MoD (MOtif Discovery) Tools web server comprises a set of tools for the discovery of novel conserved sequence and structure motifs in nucleotide sequences, motifs that in turn are good candidates for regulatory activity.
	The server includes the following programs: Weeder, for the discovery of conserved transcription factor binding sites (TFBSs) in nucleotide sequences from co-regulated genes; WeederH, for the discovery of conserved TFBSs and distal regulatory modules in sequences from homologous genes; RNAProfile, for the discovery of conserved secondary structure motifs in unaligned RNA sequences whose secondary structure is not known.
	In this way, a given gene can be compared with other co-regulated genes or with its homologs, or its mRNA can be analyzed for conserved motifs regulating its post-transcriptional fate.
	The web server thus provides researchers with different strategies and methods to investigate the regulation of gene expression, at both the transcriptional and post-transcriptional levels.
	Available at http://www.pesolelab.it/modtools/ and http://www.beacon.unimi.it/modtools/.
	The HemaExplorer (http://servers.binf.ku.dk/hemaexplorer) is a curated database of processed mRNA Gene expression profiles (GEPs) that provides an easy display of gene expression in haematopoietic cells.
	HemaExplorer contains GEPs derived from mouse/human haematopoietic stem and progenitor cells as well as from more differentiated cell types.
	Moreover, data from distinct subtypes of human acute myeloid leukemia is included in the database allowing researchers to directly compare gene expression of leukemic cells with those of their closest normal counterpart.
	Normalization and batch correction lead to full integrity of the data in the database.
	The HemaExplorer has comprehensive visualization interface that can make it useful as a daily tool for biologists and cancer researchers to assess the expression patterns of genes encountered in research or literature.
	HemaExplorer is relevant for all research within the fields of leukemia, immunology, cell differentiation and the biology of the haematopoietic system.
	Summary: While many tools exist for performing enrichment analysis of transcriptomic and proteomic data in order to interpret them in biological terms, almost no equivalent tools exist for metabolomic data.
	We present Metabolite Biological Role (MBRole), a web server for carrying out over-representation analysis of biological and chemical annotations in arbitrary sets of metabolites (small chemical compounds) coming from metabolomic data of any organism or sample.
	Availability and Implementation: The web server is freely available at http://csbg.cnb.csic.es/mbrole.
	It was tested in the main web browsers.
	Contact: monica.chagoyen@cnb.csic.es
	and full-text test datasets (Task 1), we obtain results with F-scores of 52.34 and 53.34, respectively, which are comparable to the state-of-the-art systems.
	Furthermore, our system achieves superior performance in terms of computational efficiency.
	Availability: Our source code is available for academic use at http://dl .dropbox.com/u/10256952/BioEvent.zip Contact: bqchinh@gmail.com
	Summary: Over past decades, constraint-based modelling has emerged as an important approach to obtain referential information about mechanisms behind biological phenotypes and identify physiological and perturbed metabolic states at genome-scale.
	However, application of this novel approach to systems biology in biotechnology is still hindered by the functionalities of the existing modelling software.
	To augment the usability of the constraint-based approach for various use scenarios, we present ORCA, a Matlab package, which extends the scope of established Constraint-Based Reconstruction and Analysis metabolic modelling and includes three unique functionalities: (i) a framework method integrating three analyses of multi-objective optimization, robustness analysis and fractional benefit analysis, (ii) metabolic pathways identification with futile loop elimination and (iii) a dynamic flux balance analysis framework incorporating kinetic constraints.
	Availability and implementation: ORCA is freely available to academic users and is downloadable from https://sourceforge.net/projects/exorca/; a mini-tutorial is supplied in the package for training purposes as well as a software manual.
	Contact: Longfei.mao@lincolnuni.ac.nz Supplementary information: Supplementary data are available at Bioinformatics online.
	CPHmodels-3.0 is a web server predicting protein 3D structure by use of single template homology modeling.
	The server employs a hybrid of the scoring functions of CPHmodels-2.0 and a novel remote homology-modeling algorithm.
	A query sequence is first attempted modeled using the fast CPHmodels-2.0 profile-profile scoring function suitable for close homology modeling.
	The new computational costly remote homology-modeling algorithm is only engaged provided that no suitable PDB template is identified in the initial search.
	CPHmodels-3.0 was benchmarked in the CASP8 competition and produced models for 94% of the targets (117 out of 128), 74% were predicted as high reliability models (87 out of 117).
	These achieved an average RMSD of 4.6 AËš when superimposed to the 3D structure.
	The remaining 26% low reliably models (30 out of 117) could superimpose to the true 3D structure with an average RMSD of 9.3 AËš .
	These performance values place the CPHmodels-3.0 method in the group of high performing 3D prediction tools.
	Beside its accuracy, one of the important features of the method is its speed.
	For most queries, the response time of the server is <20 min.
	The web server is available at http://www.cbs.dtu.dk/services/CPHmodels/.
	Summary: Genetic correlations are the genome-wide aggregate effects of causal variants affecting multiple traits.
	Traditionally, genetic correlations between complex traits are estimated from pedigree studies, but such estimates can be confounded by shared environmental factors.
	Moreover, for diseases, low prevalence rates imply that even if the true genetic correlation between disorders was high, co-aggregation of disorders in families might not occur or could not be distinguished from chance.
	We have developed and implemented statistical methods based on linear mixed models to obtain unbiased estimates of the genetic correlation between pairs of quantitative traits or pairs of binary traits of complex diseases using population-based case-control studies with genome-wide single-nucleotide polymorphism data.
	The method is validated in a simulation study and applied to estimate genetic correlation between various diseases from Wellcome Trust Case Control Consortium data in a series of bivariate analyses.
	We estimate a significant positive genetic correlation between risk of Type 2 diabetes and hypertension of 0.31 (SE 0.14, P Â¼ 0.024).
	Availability: Our methods, appropriate for both quantitative and binary traits, are implemented in the freely available software GCTA (http://www.complextraitgenomics.com/software/gcta/reml_bivar.html).
	Contact: hong.lee@uq.edu.au Supplementary Information: Supplementary data are available at Bioinformatics online.
	Motivation: Hodgkin lymphoma (HL) is a type of B-cell lymphoma.
	To diagnose the subtypes, biopsies are taken and immunostained.
	The slides are scanned to produce high-resolution digital whole slide images (WSI).
	Pathologists manually inspect the spatial distribution of cells, but little is known on the statistical properties of cell distributions in WSIs.
	Such properties would give valuable information for the construction of theoretical models that describe the invasion of malignant cells in the lymph node and the intercellular interactions.
	Results: In this work, we define and discuss HL cell graphs.
	We identify CD30Ã¾ cells in HL WSIs, bringing together the fields of digital imaging and network analysis.
	We define special graphs based on the positions of the immunostained cells.
	We present an automatic analysis of complete WSIs to determine significant morphological and immunohistochemical features of HL cells and their spatial distribution in the lymph node tissue under three different medical conditions: lymphadenitis (LA) and two types of HL.
	We analyze the vertex degree distributions of CD30 cell graphs and compare them to a null model.
	CD30 cell graphs show higher vertex degrees than expected by a random unit disk graph, suggesting clustering of the cells.
	We found that a gamma distribution is suitable to model the vertex degree distributions of CD30 cell graphs, meaning that they are not scale-free.
	Moreover, we compare the graphs for LA and two subtypes of HL.
	LA and classical HL showed different vertex degree distributions.
	The vertex degree distributions of the two HL subtypes NScHL and mixed cellularity HL (MXcHL) were similar.
	Availability and implementation: The CellProfiler pipeline used for cell detection is available at https://sourceforge.net/projects/cellgraphs/.Contact: ina.koch@bioinformatik.uni-frankfurt.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Next-generation sequencing and other high-throughput technology advances have promoted great interest in detecting associations between complex traits and genetic variants.
	Phenotype selection, quality control (QC) and control of confounders are crucial and can have a great impact on the ability to detect associations.
	Although there are programs to perform association analyses, e.g.
	PLINK and GenABEL, they cannot be used for comprehensive management and QC of phenotype data.
	To address this need PhenoMan was developed: to select individuals based on multiple phenotype criteria or population membership; control for missing covariate data; remove related individuals, duplicate samples and individuals with incorrect sex specification; recode primary traits and covariates; transform data; remove or winsorize outliers; select covariates for analysis; and create residuals.
	To ensure consistency and harmonization between analyses, a report is generated for every dataset.
	Summary statistics are also provided in graphical or text format.
	PhenoMan can be used for selection and manipulation of quantitative, disease and control data.
	Summary: Phenoman is freeware that provides approaches for efficient exploration and management of phenotype data.
	Proper QC of phenotypes before proceeding to the association analysis is critical to ensure control of type I and II errors, reliable effect estimates and consistent results between studies.
	PhenoMan is highly beneficial for the preparation of qualitative and quantitative trait data for association studies using new datasets as well as those obtained from public repositories.
	Availability and implementation: code.google.com/p/phenoman Contact: sleal@bcm.edu
	Grass seeds are complex organs composed by multiple tissues and cell types that develop coordinately to produce a viable embryo.
	The identification of genes involved in seed development is of great interest, but systematic spatial analyses of gene expression on maize seeds at the cell level have not yet been performed.
	MASISH is an online database holding information for gene expression spatial patterns in maize seeds based on in situ hybridization experiments.
	The web-based query interface allows the execution of gene queries and provides hybridization images, published references and information of the analyzed genes.
	Availability: http://masish.uab.cat/.Contact: cvsgmp@cid.csic.es
	Motivation: Analysis of protein-protein interaction networks (PPINs) at the system level has become increasingly important in understanding biological processes.
	Comparison of the interactomes of different species not only provides a better understanding of species evolution but also helps with detecting conserved functional components and in function prediction.
	Method and Results: Here we report a PPIN alignment method, called PINALOG, which combines information from protein sequence, function and network topology.
	Alignment of human and yeast PPINs reveals several conserved subnetworks between them that participate in similar biological processes, notably the proteasome and transcription related processes.
	PINALOG has been tested for its power in protein complex prediction as well as function prediction.
	Comparison with PSI-BLAST in predicting protein function in the twilight zone also shows that PINALOG is valuable in predicting protein function.
	Availability and implementation: The PINALOG web-server is freely available from http://www.sbg.bio.ic.ac.uk/âˆ¼pinalog.
	The PINALOG program and associated data are available from the Download section of the web-server.
	Contact: m.sternberg@imperial.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: This article presents libRoadRunner, an extensible, high-performance, cross-platform, open-source software library for the simulation and analysis of models expressed using Systems Biology Markup Language (SBML).
	SBML is the most widely used standard for representing dynamic networks, especially biochemical networks.
	libRoadRunner is fast enough to support largescale problems such as tissue models, studies that require large numbers of repeated runs and interactive simulations.
	Results: libRoadRunner is a self-contained library, able to run both as a component inside other tools via its CÃ¾Ã¾ and C bindings, and interactively through its Python interface.
	Its Python Application Programming Interface (API) is similar to the APIs of MATLAB (www.mathworks.com) and SciPy (http://www.scipy.org/), making it fast and easy to learn.
	libRoadRunner uses a custom Just-In-Time (JIT) compiler built on the widely used LLVM JIT compiler framework.
	It compiles SBML-specified models directly into native machine code for a variety of processors, making it appropriate for solving extremely large models or repeated runs.
	libRoadRunner is flexible, supporting the bulk of the SBML specification (except for delay and non-linear algebraic equations) including several SBML extensions (composition and distributions).
	It offers multiple deterministic and stochastic integrators, as well as tools for steady-state analysis, stability analysis and structural analysis of the stoichiometric matrix.
	Availability and implementation: libRoadRunner binary distributions are available for Mac OS X, Linux and Windows.
	The library is licensed under Apache License Version 2.0. libRoadRunner is also available for ARM-based computers such as the Raspberry Pi.
	http://www.libroadrunner.org provides online documentation, full build instructions, binaries and a git source repository.
	Contacts: hsauro@u.washington.edu or somogyie@indiana.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: The anisotropic network model (ANM) is one of the simplest yet powerful tools for exploring protein dynamics.
	Its main utility is to predict and visualize the collective motions of large complexes and assemblies near their equilibrium structures.
	The ANM server, introduced by us in 2006 helped making this tool more accessible to non-sophisticated users.
	We now provide a new version (ANM 2.0), which allows inclusion of nucleic acids and ligands in the network model and thus enables the investigation of the collective motions of protein-DNA/RNA and -ligand systems.
	The new version offers the flexibility of defining the system nodes and the interaction types and cutoffs.
	It also includes extensive improvements in hardware, software and graphical interfaces.
	Availability and implementation: ANM 2.0 is available at http://anm.csb.pitt.edu Contact: eran.eyal@sheba.health.gov.il, eyal.eran@gmail.com
	Summary: The Biological General Repository for Interaction Datasets (BioGRID) representational state transfer (REST) service allows full URL-based access to curated protein and genetic interaction data at the BioGRID database.
	Appending URL parameters allows filtering of data by various attributes including gene names and identifiers, PubMed ID and evidence type.
	We also describe two visualization tools that interface with the REST service, the BiogridPlugin2 for Cytoscape and the BioGRID WebGraph.
	Availability and implementation: BioGRID data and applications are completely free for commercial and non-commercial use.
	http://webservice.thebiogrid.org/resources/interactions (REST Service), http://wiki.thebiogrid.org/doku.php/biogridrest(REST Service parameter list and help), http://webservice.thebiogrid.org/resources/application.wadl(REST Service WADL), http://thebiogrid .org/download.php (BiogridPlugin2, v2.1 download), http://wiki .thebiogrid.org/doku.php/biogridplugin2 (BiogridPlugin2 help) and http://tyerslab.bio.ed.ac.uk/tools/BioGRID_webgraph.php(BioGRID WebGraph).
	Contact: andrew.winter@ed.ac.uk, m.tyers@ed.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Targeted 'deep' sequencing of specific genes or regions is of great interest in clinical cancer diagnostics where some sequence variants, particularly translocations and indels, have known prognostic or diagnostic significance.
	In this setting, it is unnecessary to sequence an entire genome, and target capture methods can be applied to limit sequencing to important regions, thereby reducing costs and the time required to complete testing.
	Existing 'nextgen' sequencing analysis packages are optimized for efficiency in whole-genome studies and are unable to benefit from the particular structure of targeted sequence data.
	Results: We developed SLOPE to detect structural variants from targeted short-DNA reads.
	We use both real and simulated data to demonstrate SLOPE's ability to rapidly detect insertion/deletion events of various sizes as well as translocations and viral integration sites with high sensitivity and low false discovery rate.
	Availability: Binary code available at http://www-genepi.med.utah .edu/suppl/SLOPE/index.html Contact: haley@genepi.med.utah.edu
	Motivation: Abrupt reduction/resumption of thermal fluctuations of a force probe has been used to identify association/dissociation events of protein-ligand bonds.
	We show that off-rate of molecular dissociation can be estimated by the analysis of the bond lifetime, while the on-rate of molecular association can be estimated by the analysis of the waiting time between two neighboring bond events.
	However, the analysis relies heavily on subjective judgments and is time-consuming.
	To automate the process of mapping out bond events from thermal fluctuation data, we develop a hidden Markov model (HMM)-based method.
	Results: The HMM method represents the bond state by a hidden variable with two values: bound and unbound.
	The bond association/ dissociation is visualized and pinpointed.
	We apply the method to analyze a key receptor-ligand interaction in the early stage of hemostasis and thrombosis: the von Willebrand factor (VWF) binding to platelet glycoprotein Ib (GPIb ).
	The numbers of bond lifetime and waiting time events estimated by the HMM are much more than those estimated by a descriptive statistical method from the same set of raw data.
	The kinetic parameters estimated by the HMM are in excellent agreement with those by a descriptive statistical analysis, but have much smaller errors for both wild-type and two mutant VWF-A1 domains.
	Thus, the computerized analysis allows us to speed up the analysis and improve the quality of estimates of receptor-ligand binding kinetics.
	Contact: jeffwu@isye.gatech.edu or cheng.zhu@bme.gatech.edu The Author 2013.
	Published by Oxford University Press.
	All rights reserved.
	For Permissions, please email: journals.permissions@oup.com
	Motivation: Genetic studies focus on increasingly larger genomic regions of both extant and ancient DNA, and there is a need for simulation software to match these technological advances.
	We present here a new coalescent-based simulation program fastsimcoal, which is able to quickly simulate a variety of genetic markers scattered over very long genomic regions with arbitrary recombination patterns under complex evolutionary scenarios.
	Availability and Implementation: fastsimcoal is a C++ program compiled for Windows, MacOsX and Linux platforms.
	It is freely available at cmpg.unibe.ch/software/fastsimcoal/, together with its detailed user manual and example input files.
	Contact: laurent.excoffier@iee.unibe.ch Supplementary Information: Supplementary data are available at Bioinformatics online.
	Motivation: Sequences and protein interaction data are of significance to understand the underlying molecular mechanism of organisms.
	Local network alignment is one of key systematic ways for predicting protein functions, identifying functional modules and understanding the phylogeny from these data.
	Most of currently existing tools, however, encounter their limitations, which are mainly concerned with scoring scheme, speed and scalability.
	Therefore, there are growing demands for sophisticated network evolution models and efficient local alignment algorithms.
	Results: We developed a fast and scalable local network alignment tool called LocalAli for the identification of functionally conserved modules in multiple networks.
	In this algorithm, we firstly proposed a new framework to reconstruct the evolution history of conserved modules based on a maximum-parsimony evolutionary model.
	By relying on this model, LocalAli facilitates interpretation of resulting local alignments in terms of conserved modules, which have been evolved from a common ancestral module through a series of evolutionary events.
	A meta-heuristic method simulated annealing was used to search for the optimal or near-optimal inner nodes (i.e.
	ancestral modules) of the evolutionary tree.
	To evaluate the performance and the statistical significance, LocalAli were tested on 26 real datasets and 1040 randomly generated datasets.
	The results suggest that LocalAli outperforms all existing algorithms in terms of coverage, consistency and scalability, meanwhile retains a high precision in the identification of functionally coherent subnetworks.
	Availability: The source code and test datasets are freely available for download under the GNU GPL v3 license at https://code.google.com/p/localali/.
	Contact: jialu.hu@fu-berlin.de or knut.reinert@fu-berlin.de.
	Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: We introduce here a novel acquisition and processing methodology for cross-polarization based 1D rotating-frame relaxation dispersion NMR experiments.
	This easy-to-use protocol greatly facilitates the screening, acquisition, processing and model fitting of large on- and off-resonance R1q relaxation dispersion NMR datasets in an automated manner for the analysis of chemical exchange phenomena in biomolecules.
	Availability and Implementation: The Amaterasu package including the spreadsheet, Bruker pulse programs and analysis software is available at www.moleng.kyoto-u.ac.jp/ moleng_01/ amaterasu.
	Contact: sugase@moleng.kyoto-u.ac.jp
	Motivation: Homology detection enables grouping proteins into families and prediction of their structure and function.
	The range of application of homology-based predictions can be significantly extended by using sequence profiles and incorporation of local structural features.
	However, incorporation of the latter terms varies a lot between existing methods, and together with many examples of distant relations not recognized even by the best methods, suggests that further improvements are still possible.
	Results: Here we describe recent improvements to the fold and function assignment system (FFAS) method, including adding optimized structural features (experimental or predicted), 'symmetrical' Z-score calculation and re-ranking the templates with a neural network.
	The alignment accuracy in the new FFAS-3D is now 11% higher than the original and comparable with the most accurate templatebased structure prediction algorithms.
	At the same time, FFAS-3D has high success rate at the Structural Classification of Proteins (SCOP) family, superfamily and fold levels.
	Importantly, FFAS-3D results are not highly correlated with other programs suggesting that it may significantly improve meta-predictions.
	FFAS-3D does not require 3D structures of the templates, as using predicted features instead of structure-derived does not lead to the decrease of accuracy.
	Because of that, FFAS-3D can be used for databases other than Protein Data Bank (PDB) such as Protein families database or Clusters of orthologous groups thus extending its applications to functional annotations of genomes and protein families.
	Availability and implementation: FFAS-3D is available at http://ffas.godziklab.org.
	Contact: adam@godziklab.org Supplementary Information: Supplementary data are available at Bioinformatics online.
	Motivation: 30 end processing is important for transcription termination, mRNA stability and regulation of gene expression.
	To identify 30 ends, most techniques use an oligo-dT primer to construct deep sequencing libraries.
	However, this approach can lead to identification of artifactual polyadenylation sites due to internal priming in homopolymeric stretches of adenines.
	Although heuristic filters have been applied in these cases, they typically result in a high proportion of both false-positive and -negative classifications.
	Therefore, there is a need to develop improved algorithms to better identify mis-priming events in oligo-dT primed sequences.
	Results: By analyzing sequence features flanking 30 ends derived from oligo-dT-based sequencing, we developed a naÄ±Â¨ve Bayes classifier to classify them as true or false/internally primed.
	The resulting algorithm is highly accurate, outperforms previous heuristic filters and facilitates identification of novel polyadenylation sites.
	Contact: nathan.lawson@umassmed.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: The composition of immune-cell subsets is key to the understanding of major diseases and pathologies.
	Computational deconvolution methods enable researchers to investigate immune cell quantities in complex tissues based on transcriptome data.
	Here we present ImmQuant, a software tool allowing immunologists to upload transcription profiles of multiple tissue samples, apply deconvolution methodology to predict differences in cell-type quantities between the samples, and then inspect the inferred cell-type alterations using convenient visualization tools.
	ImmQuant builds on the DCQ deconvolution algorithm and allows a user-friendly utilization of this method by non-bioinformatician researchers.
	Specifically, it enables investigation of hundreds of immune cell subsets in mouse tissues, as well as a few dozen cell types in human samples.
	Availability and implementation: ImmQuant is available for download at http://csgi.tau.ac.il/ImmQuant/.Contact: iritgv@post.tau.ac.il Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Prediction of protein residue contacts, even at the coarsegrain level, can help in finding solutions to the protein structure prediction problem.
	Unlike a-helices that are locally stabilized, b-sheets result from pairwise hydrogen bonding of two or more disjoint regions of the protein backbone.
	The problem of predicting contacts among b-strands in proteins has been addressed by several supervised computational approaches.
	Recently, prediction of residue contacts based on correlated mutations has been greatly improved and finally allows the prediction of 3D structures of the proteins.
	Results: In this article, we describe BCov, which is the first unsupervised method to predict the b-sheet topology starting from the protein sequence and its secondary structure.
	BCov takes advantage of the sparse inverse covariance estimation to define b-strand partner scores.
	Then an optimization based on integer programming is carried out to predict the b-sheet connectivity.
	When tested on the prediction of b-strand pairing, BCov scores with average values of Matthews Correlation Coefficient (MCC) and F1 equal to 0.56 and 0.61, respectively, on a non-redundant dataset of 916 protein chains known with atomic resolution.
	Our approach well compares with the state-of-theart methods trained so far for this specific task.
	Availability and implementation: The method is freely available under General Public License at http://biocomp.unibo.it/savojard/bcov/bcov-1.0.tar.gz.
	The new dataset BetaSheet1452 can be downloaded at http://biocomp.unibo.it/savojard/bcov/BetaSheet1452.dat.Contact: piero.fariselli@unibo.it Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: The popularity of using NMR spectroscopy in metabolomics and natural products has driven the development of an array of NMR spectral analysis tools and databases.
	Particularly, web applications are well used recently because they are platform-independent and easy to extend through reusable web components.
	Currently available web applications provide the analysis of NMR spectra.
	However, they still lack the necessary processing and interactive visualization functionalities.
	To overcome these limitations, we present NMRPro, a web component that can be easily incorporated into current web applications, enabling easy-to-use online interactive processing and visualization.
	NMRPro integrates server-side processing with client-side interactive visualization through three parts: a python package to efficiently process large NMR datasets on the serverside, a Django App managing server-client interaction, and SpecdrawJS for client-side interactive visualization.
	Availability and implementation: Demo and installation instructions are available at http://mamitsu kalab.org/tools/nmrpro/ Contact: mohamed@kuicr.kyoto-u.ac.jp Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Metabolomic publications and databases use different database identifiers or even trivial names which disable queries across databases or between studies.
	The best way to annotate metabolites is by chemical structures, encoded by the International Chemical Identifier code (InChI) or InChIKey.
	We have implemented a web-based Chemical Translation Service that performs batch conversions of the most common compound identifiers, including CAS, CHEBI, compound formulas, Human Metabolome Database HMDB, InChI, InChIKey, IUPAC name, KEGG, LipidMaps, PubChem CID+SID, SMILES and chemical synonym names.
	Batch conversion downloads of 1410 CIDs are performed in 2.5 min.
	Structures are automatically displayed.
	Implementation: The software was implemented in Groovy and JAVA, the web frontend was implemented in GRAILS and the database used was PostgreSQL.
	Availability: The source code and an online web interface are freely available.
	Chemical Translation Service (CTS): http://cts.fiehnlab.ucdavis.edu Contact: ofiehn@ucdavis.edu
	Motivation: Biological pathways play a key role in most cellular functions.
	To better understand these functions, diverse computational and cell biology researchers use biological pathway data for various analysis and modeling purposes.
	For specifying these biological pathways, a community of researchers has defined BioPAX and provided various tools for creating, validating and visualizing BioPAX models.
	However, a generic software framework for simulating BioPAX models is missing.
	Here, we attempt to fill this gap by introducing a generic simulation framework for BioPAX.
	The framework explicitly separates the execution model from the model structure as provided by BioPAX, with the advantage that the modelling process becomes more reproducible and intrinsically more modular; this ensures natural biological constraints are satisfied upon execution.
	The framework is based on the principles of discrete event systems and multi-agent systems, and is capable of automatically generating a hierarchical multi-agent system for a given BioPAX model.
	Results: To demonstrate the applicability of the framework, we simulated two types of biological network models: a gene regulatory network modeling the haematopoietic stem cell regulators and a signal transduction network modeling the Wnt/b-catenin signaling pathway.
	We observed that the results of the simulations performed using our framework were entirely consistent with the simulation results reported by the researchers who developed the original models in a proprietary language.
	Availability and Implementation: The framework, implemented in Java, is open source and its source code, documentation and tutorial are available at http://www.ibi.vu.nl/programs/BioASF.Contact: j.heringa@vu.nl
	Motivation: Cell fate decisions have a strong stochastic component.
	The identification of the underlying mechanisms therefore requires a rigorous statistical analysis of large ensembles of single cells that were tracked and phenotyped over time.
	Results: We introduce a probabilistic framework for testing elementary hypotheses on dynamic cell behavior using time-lapse cell-imaging data.
	Factor graphs, probabilistic graphical models, are used to properly account for cell lineage and cell phenotype information.
	Our model is applied to time-lapse movies of murine granulocyte-macrophage progenitor (GMP) cells.
	It decides between competing hypotheses on the mechanisms of their differentiation.
	Our results theoretically substantiate previous experimental observations that lineage instruction, not selection is the cause for the differentiation of GMP cells into mature monocytes or neutrophil granulocytes.
	Availability and implementation: The Matlab source code is available at http://treschgroup.de/Genealogies.html Contact: failmezger@mpipz.mpg.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Warp2D is a novel time alignment approach, which uses the overlapping peak volume of the reference and sample peak lists to correct misleading peak shifts.
	Here, we present an easyto-use web interface for high-throughput Warp2D batch processing time alignment service using the Dutch Life Science Grid, reducing processing time from days to hours.
	This service provides the warping function, the sample chromatogram peak list with adjusted retention times and normalized quality scores based on the sum of overlapping peak volume of all peaks.
	Heat maps before and after time alignment are created from the arithmetic mean of the sum of overlapping peak area rearranged with hierarchical clustering, allowing the quality control of the time alignment procedure.
	Taverna workflow and command line tool are provided for remote processing of local user data.
	Availability: online data processing service is available at http://www.nbpp.nl/warp2d.html.
	Taverna workflow is available at myExperiment with title '2D Time Alignment-Webservice and Workflow' at http://www.myexperiment.org/workflows/.html.Command line tool is available at http://www.nbpp.nl/Warp2D_ commandline.zip.
	Contact: p.l.horvatovich@rug.nl Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Proteins can adopt a variety of conformations.
	We present a simple server for scoring the agreement between 3D atomic structures and experimental envelopes obtained by atomic force microscopy.
	Three different structures of immunoglobulins (IgG) or blood coagulation factor V activated were tested and their agreement with several topographical surfaces was computed.
	This approach can be used to test structural variability within a family of proteins.
	Availability and implementation: DockAFM is available at http://biodev.cea.fr/dockafm.
	Contact: chaves.rui.c@gmail.com or jlpellequer@cea.fr Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Molecular representation for small molecules has been routinely used in QSAR/SAR, virtual screening, database search, ranking, drug ADME/T prediction and other drug discovery processes.
	To facilitate extensive studies of drug molecules, we developed a freely available, open-source python package called chemoinformatics in python (ChemoPy) for calculating the commonly used structural and physicochemical features.
	It computes 16 drug feature groups composed of 19 descriptors that include 1135 descriptor values.
	In addition, it provides seven types of molecular fingerprint systems for drug molecules, including topological fingerprints, electro-topological state (E-state) fingerprints, MACCS keys, FP4 keys, atom pairs fingerprints, topological torsion fingerprints and Morgan/circular fingerprints.
	By applying a semi-empirical quantum chemistry program MOPAC, ChemoPy can also compute a large number of 3D molecular descriptors conveniently.
	Availability: The python package, ChemoPy, is freely available via http://code.google.com/p/pychem/downloads/list, and it runs on Linux and MS-Windows.
	Contact: yizeng_liang@263.net Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: There is growing recognition that estimating haplotypes from high coverage sequencing of single samples in clinical settings is an important problem.
	At the same time very large datasets consisting of tens and hundreds of thousands of high-coverage sequenced samples will soon be available.
	We describe a method that takes advantage of these huge human genetic variation resources and rare variant sharing patterns to estimate haplotypes on single sequenced samples.
	Sharing rare variants between two individuals is more likely to arise from a recent common ancestor and, hence, also more likely to indicate similar shared haplotypes over a substantial flanking region of sequence.
	Results: Our method exploits this idea to select a small set of highly informative copying states within a Hidden Markov Model (HMM) phasing algorithm.
	Using rare variants in this way allows us to avoid iterative MCMC methods to infer haplotypes.
	Compared to other approaches that do not explicitly use rare variants we obtain significant gains in phasing accuracy, less variation over phasing runs and improvements in speed.
	For example, using a reference panel of 7420 haplotypes from the UK10K project, we are able to reduce switch error rates by up to 50% when phasing samples sequenced at high-coverage.
	In addition, a single step rephasing of the UK10K panel, using rare variant information, has a downstream impact on phasing performance.
	These results represent a proof of concept that rare variant sharing patterns can be utilized to phase large high-coverage sequencing studies such as the 100 000 Genomes Project dataset.
	Availability and implementation: A webserver that includes an implementation of this new method and allows phasing of high-coverage clinical samples is available at https://phasingserver.stats.ox.ac.uk/.Contact: marchini@stats.ox.ac.uk Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Epigenetic landscapes in the regulatory regions reflect binding condition of transcription factors and their co-factors.
	Identifying epigenetic condition and its variation is important in understanding condition-specific gene regulation.
	Computational approaches to explore complex multi-dimensional landscapes are needed.
	Results: To study epigenomic condition for gene regulation, we developed a method, AWNFR, to classify epigenomic landscapes based on the detected epigenomic landscapes.
	Assuming mixture of Gaussians for a nucleosome, the proposed method captures the shape of histone modification and identifies potential regulatory regions in the wavelet domain.
	For accuracy estimation as well as enhanced computational speed, we developed a novel algorithm based on downsampling operation and footprint in wavelet.
	We showed the algorithmic advantages of AWNFR using the simulated data.
	AWNFR identified regulatory regions more effectively and accurately than the previous approaches with the epigenome data in mouse embryonic stem cells and human lung fibroblast cells (IMR90).
	Based on the detected epigenomic landscapes, AWNFR classified epigenomic status and studied epigenomic codes.
	We studied co-occurring histone marks and showed that AWNFR captures the epigenomic variation across time.
	Availability and implementation: The source code and supplemental document of AWNFR are available at http://wonk.med.upenn.edu/AWNFR.
	Contact: wonk@mail.med.upenn.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Structure-based computational protein design (SCPR) is an important topic in protein engineering.
	Under the assumption of a rigid backbone and a finite set of discrete conformations of sidechains, various methods have been proposed to address this problem.
	A popular method is to combine the dead-end elimination (DEE) and A* tree search algorithms, which provably finds the global minimum energy conformation (GMEC) solution.
	Results: In this article, we improve the efficiency of computing A* heuristic functions for protein design and propose a variant of A* algorithm in which the search process can be performed on a single GPU in a massively parallel fashion.
	In addition, we make some efforts to address the memory exceeding problem in A* search.
	As a result, our enhancements can achieve a significant speedup of the A*-based protein design algorithm by four orders of magnitude on large-scale test data through pre-computation and parallelization, while still maintaining an acceptable memory overhead.
	We also show that our parallel A* search algorithm could be successfully combined with iMinDEE, a state-of-the-art DEE criterion, for rotamer pruning to further improve SCPR with the consideration of continuous side-chain flexibility.
	Availability: Our software is available and distributed open-source under the GNU Lesser General License Version 2.1 (GNU, February 1999).
	The source code can be downloaded from http://www.cs.duke.edu/donaldlab/osprey.php or http://iiis.tsinghua.edu.cn/ compbio/software.html.
	Contact: zengjy321@tsinghua.edu.cn Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Segmental duplications >1 kb in length with â‰¥ 90% sequence identity between copies comprise nearly 5% of the human genome.
	They are frequently found in large, contiguous regions known as duplication blocks that can contain mosaic patterns of thousands of segmental duplications.
	Reconstructing the evolutionary history of these complex genomic regions is a non-trivial, but important task.
	Results: We introduce parsimony and likelihood techniques to analyze the evolutionary relationships between duplication blocks.
	Both techniques rely on a generic model of duplication in which long, contiguous substrings are copied and reinserted over large physical distances, allowing for a duplication block to be constructed by aggregating substrings of other blocks.
	For the likelihood method, we give an efficient dynamic programming algorithm to compute the weighted ensemble of all duplication scenarios that account for the construction of a duplication block.
	Using this ensemble, we derive the probabilities of various duplication scenarios.
	We formalize the task of reconstructing the evolutionary history of segmental duplications as an optimization problem on the space of directed acyclic graphs.
	We use a simulated annealing heuristic to solve the problem for a set of segmental duplications in the human genome in both parsimony and likelihood settings.
	Availability: Supplementary information is available at http://www.cs.brown.edu/people/braphael/supplements/.Contact: clkahn@cs.brown.edu; braphael@cs.brown.edu.
	Summary: Retroviral integration has been implicated in several biomedical applications, including identification of cancerassociated genes and malignant transformation in gene therapy clinical trials.
	We introduce an efficient and scalable method for fast identification of viral vector integration sites from long read high-throughput sequencing.
	Individual sequence reads are masked to remove non-genomic sequence, aligned to the host genome and assembled into contiguous fragments used to pinpoint the position of integration.
	Availability and Implementation: The method is implemented in a publicly accessible web server platform, SeqMap 2.0, containing analysis tools and both private and shared lab workspaces that facilitate collaboration among researchers.
	Available at http://seqmap.compbio.iupui.edu/.Contact: troyhawk@iupui.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Today many non-coding RNAs are known to play an active role in various important biological processes.
	Since RNA's functionality is correlated with specific structural motifs that are often conserved in phylogenetically related molecules, computational prediction of RNA structure should ideally be based on a set of homologous primary structures.
	But many available RNA secondary structure prediction programs that use sequence alignments do not consider pseudoknots or their estimations consist on a single structure without information on uncertainty.
	Results: In this article we present a method that takes advantage of the evolutionary history of a group of aligned RNA sequences for sampling consensus secondary structures, including pseudoknots, according to their approximate posterior probability.
	We investigate the benefit of using evolutionary history and demonstrate the competitiveness of our method compared with similar methods based on RNase P RNA sequences and simulated data.
	Availability: PhyloQFold, a C++ implementation of our method, is freely available from http://evol.bio.lmu.de/_statgen/software/phyloqfold/ Contact: gero@bioinf.uni-leipzig.de, metzler@bio.lmu.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Most biological processes are mediated by the proteinprotein interactions.
	Determination of the protein-protein structures and insight into their interactions are vital to understand the mechanisms of protein functions.
	Currently, compared with the isolated protein structures, only a small fraction of protein-protein structures are experimentally solved.
	Therefore, the computational docking methods play an increasing role in predicting the structures and interactions of protein-protein complexes.
	The scoring function of protein-protein interactions is the key responsible for the accuracy of the computational docking.
	Previous scoring functions were mostly developed by optimizing the binding affinity which determines the stability of the protein-protein complex, but they are often lack of the consideration of specificity which determines the discrimination of native proteinprotein complex against competitive ones.
	Results: We developed a scoring function (named as SPA-PP, specificity and affinity of the protein-protein interactions) by incorporating both the specificity and affinity into the optimization strategy.
	The testing results and comparisons with other scoring functions show that SPA-PP performs remarkably on both predictions of binding pose and binding affinity.
	Thus, SPA-PP is a promising quantification of protein-protein interactions, which can be implemented into the protein docking tools and applied for the predictions of protein-protein structure and affinity.
	Availability: The algorithm is implemented in C language, and the code can be downloaded from http://dl.dropbox.com/u/1865642/Optimization.cpp.
	Contact: jin.wang.1@stonybrook.edu Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: The simulation of morphogenetic problems requires the simultaneous and coupled simulation of signalling and tissue dynamics.
	A cellular resolution of the tissue domain is important to adequately describe the impact of cell-based events, such as cell division, cell-cell interactions and spatially restricted signalling events.
	A tightly coupled cell-based mechano-regulatory simulation tool is therefore required.
	Results: We developed an open-source software framework for morphogenetic problems.
	The environment offers core functionalities for the tissue and signalling models.
	In addition, the software offers great flexibility to add custom extensions and biologically motivated processes.
	Cells are represented as highly resolved, massless elastic polygons; the viscous properties of the tissue are modelled by a Newtonian fluid.
	The Immersed Boundary method is used to model the interaction between the viscous and elastic properties of the cells, thus extending on the IBCell model.
	The fluid and signalling processes are solved using the Lattice Boltzmann method.
	As application examples we simulate signalling-dependent tissue dynamics.
	Availability and implementation: The documentation and source code are available on http://tanakas.bitbucket.org/lbibcell/index.html Contact: simon.tanaka@bsse.ethz.ch or dagmar.iber@bsse.ethz.ch Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: UPDtool is a computational tool for detection and classification of uniparental disomy (UPD) in trio SNP-microarray experiments.
	UPDs are rare events of chromosomal malsegregation and describe the condition of two homologous chromosomes or homologous chromosomal segments that were inherited from one parent.
	The occurrence of UPD can be of major clinical relevance.
	Though highthroughput molecular screening techniques are widely used, detection of UPDs and especially the subclassification remains complex.
	We developed UPDtool to detect and classify UPDs from SNP microarray data of parent-child trios.
	The algorithm was tested using five positive controls including both iso- and heterodisomic segmental UPDs and 30 trios from the HapMap project as negative controls.
	With UPDtool, we were able to correctly identify all occurrences of non-mosaic UPD within our positive controls, whereas no occurrence of UPD was found within our negative controls.
	In addition, the chromosomal breakage points could be determined more precisely than by microsatellite analysis.
	Our results were compared with both the gold standard, microsatellite analysis and SNPtrio, another program available for UPD detection.
	UPDtool is platform independent, light weight and flexible.
	Because of its simple input format, UPDtool may also be used with other high-throughput technologies (e.g.
	next-generation sequencing).
	Availability and implementation: UPDtool executables, documentation and examples can be downloaded from http://www.uni-tuebin gen.de/uni/thk/de/f-genomik-software.html.
	Contact: christopher.schroeder@med.uni-tuebingen.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: Cancer cell genomes acquire several genetic alterations during somatic evolution from a normal cell type.
	The relative order in which these mutations accumulate and contribute to cell fitness is affected by epistatic interactions.
	Inferring their evolutionary history is challenging because of the large number of mutations acquired by cancer cells as well as the presence of unknown epistatic interactions.
	Results: We developed Bayesian Mutation Landscape (BML), a probabilistic approach for reconstructing ancestral genotypes from tumor samples for much larger sets of genes than previously feasible.
	BML infers the likely sequence of mutation accumulation for any set of genes that is recurrently mutated in tumor samples.
	When applied to tumor samples from colorectal, glioblastoma, lung and ovarian cancer patients, BML identifies the diverse evolutionary scenarios involved in tumor initiation and progression in greater detail, but broadly in agreement with prior results.
	Availability and implementation: Source code and all datasets are freely available at bml.molgen.mpg.de Contact: misra@molgen.mpg.de Supplementary information: Supplementary data are available at Bioinformatics online.
	Motivation: A major problem in protein structure prediction is the correct location of disulfide bridges in cysteine-rich proteins.
	In protein-folding prediction, the location of disulfide bridges can strongly reduce the search in the conformational space.
	Therefore the correct prediction of the disulfide connectivity starting from the protein residue sequence may also help in predicting its 3D structure.
	Results: In this paper we equate the problem of predicting the disulfide connectivity in proteins to a problem of finding the graph matching with the maximum weight.
	The graph vertices are the residues of cysteine-forming disulfide bridges, and the weight edges are contact potentials.
	In order to solve this problem we develop and test different residue contact potentials.
	The best performing one, based on the Edmonds-Gabow algorithm and Monte-Carlo simulated annealing reaches an accuracy significantly higher than that obtained with a general mean force contact potential.
	Significantly, in the case of proteins with four disulfide bonds in the structure, the accuracy is 17 times higher than that of a random predictor.
	The method presented here can be used to locate putative disulfide bridges in protein-folding.
	Availability: The program is available upon request from the authors.
	Contact: Casadio@alma.unibo.it; Piero@biocomp.unibo.it
	Summary: CytoscapeRPC is a plugin for Cytoscape which allows users to create, query and modify Cytoscape networks from any programming language which supports XML-RPC.
	This enables them to access Cytoscape functionality and visualize their data interactively without leaving the programming environment with which they are familiar.
	Availability: Install through the Cytoscape plugin manager or visit the web page: http://wiki.nbic.nl/index.php/CytoscapeRPC for the user tutorial and download.
	Contact: j.j.bot@tudelft.nl
	Motivation: Insertion/deletion (indel) and amino acid substitution are two common events that lead to the evolution of and variations in protein sequences.
	Further, many of the human diseases and functional divergence between homologous proteins are more related to indel mutations, even though they occur less often than the substitution mutations do.
	A reliable identification of indels and their flanking regions is a major challenge in research related to protein evolution, structures and functions.
	Results: In this article, we propose a novel scheme to predict indel flanking regions in a protein sequence for a given protein fold, based on a variable-order Markov model.
	The proposed indel flanking region (IndelFR) predictors are designed based on prediction by partial match (PPM) and probabilistic suffix tree (PST), which are referred to as the PPM IndelFR and PST IndelFR predictors, respectively.
	The overall performance evaluation results show that the proposed predictors are able to predict IndelFRs in the protein sequences with a high accuracy and F1 measure.
	In addition, the results show that if one is interested only in predicting IndelFRs in protein sequences, it would be preferable to use the proposed predictors instead of HMMER 3.0 in view of the substantially superior performance of the former.
	Contact: m_alshat@ece.concordia.ca or omair@ece.concordia.ca or swamy@ece.concordia.ca.
	Supplementary information: Supplementary data are available at Bioinformatics online.
	Summary: Herein we introduce flowFit, a Bioconductor package designed to perform quantitative analysis of cell proliferation in tracking dye-based experiments.
	The software, distributed as an R Bioconductor library, is based on a mathematical model that takes into account the height of each peak, the size and position of the parental population (labeled but not proliferating) and the estimated distance between the brightness of a cell and the brightness of its daughter (in which the dye is assumed to undergo a 2-fold dilution).
	Although the algorithm does not make any inference on cell types, rates of cell divisions or rates of cell death, it deconvolutes the actual collected data into a set of peaks, whereby each peak corresponds to a subpopulation of cells that have divided N times.
	We validated flowFit by retrospective analysis of published proliferationtracking experiments and demonstrated that the algorithm predicts the same percentage of cells/generation either in samples with discernible peaks (in which the peaks are visible in the collected raw data) or in samples with non-discernible peaks (in which the peaks are fused together).
	To the best of our knowledge, flowFit represents the first open-source algorithm in its category and might be applied to numerous areas of cell biology in which quantitative deconvolution of tracking dye-based experiments is desired, including stem cell research.
	Availability and implementation: http://www.bioconductor.org/packages/devel/bioc/html/flowFit.html (Bioconductor software page).
	http://www.bioconductor.org/packages/2.13/bioc/vignettes/flowFit/inst/doc/HowTo-flowFit.pdf (package vignette).
	http://rpubs.com/tucano/flowFit (online tutorial).Contact: pierpaolo.difiore@ifom.eu or davide.rambaldi@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.
